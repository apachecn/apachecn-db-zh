# 10.最佳化

Abstract

一位不知名的 Twitter 用户半开玩笑地说:“如果一个 MongoDB 查询运行时间超过 0 毫秒，那么一定有问题。”这是该产品在 2009 年首次亮相时的典型反响。

一位不知名的 Twitter 用户半开玩笑地说:“如果一个 MongoDB 查询运行时间超过 0 毫秒，那么一定有问题。”这是该产品在 2009 年首次亮相时的典型反响。

现实情况是 MongoDB 速度非常快。但是如果您给它错误的数据结构，或者您没有用正确的索引设置集合，MongoDB 可能会像任何数据存储系统一样显著变慢。

MongoDB 还包含一些高级特性，这些特性需要一些调整才能以最佳效率运行。

数据模式的设计也会对性能产生很大的影响；在这一章中，我们将研究一些技术来将您的数据塑造成一种最大限度地利用 MongoDB 的优势并最小化其劣势的形式。

在我们研究如何提高运行在服务器上的查询的性能或者优化数据结构的方法之前，我们先来看看 MongoDB 如何与运行它的硬件进行交互，以及影响性能的因素。然后我们看一下索引，如何使用它们来提高查询的性能，以及如何分析 MongoDB 实例来确定哪些查询性能不好。

## 优化您的服务器硬件性能

通常，对数据库服务器进行最快速、最便宜的优化是调整运行它的硬件的大小。如果数据库服务器内存太少或使用慢速驱动器，会严重影响数据库性能。虽然这些限制中的一些对于开发环境可能是可接受的，在开发环境中，服务器可能运行在开发人员的本地工作站上，但是它们对于生产应用程序可能是不可接受的，在生产应用程序中，必须小心计算正确的硬件配置以实现最佳性能。

### 了解 MongoDB 如何使用内存

MongoDB 使用内存映射文件 I/O 来访问其底层数据存储。这种文件 I/O 方法有一些您应该知道的特征，因为它们会影响运行它的操作系统(OS)的类型和您安装的内存量。

内存映射文件的第一个显著特征是，在现代 64 位操作系统上，可以管理的最大文件大小在 Linux 上约为 128 TB(Linux 虚拟内存地址限制),在 Windows 上约为 8TB(启用日志记录时为 4TB ),因为它对内存映射文件有限制。在 32 位操作系统上，您只能使用 2GB 的数据，因此不建议您使用 32 位操作系统，除非运行小型开发环境。

第二个显著的特征是，内存映射文件使用操作系统的虚拟内存系统，根据需要将数据库文件的所需部分映射到 RAM 中。这可能会给人留下一种稍微令人担忧的印象，即 MongoDB 正在耗尽系统的所有 RAM。事实并非如此，因为 MongoDB 将与其他应用程序共享虚拟地址空间。并且操作系统将在需要时释放内存给其他进程。使用空闲内存总量作为过度内存消耗的指标并不是一个好的做法，因为一个好的操作系统将确保只有很少或没有“空闲”内存。通过缓存或缓冲磁盘 I/O，所有昂贵的内存都被充分利用。空闲内存是浪费的内存。

通过提供适量的内存，MongoDB 可以将更多需要的数据映射到内存中，从而减少对昂贵的磁盘 I/O 的需求。

一般来说，给 MongoDB 的内存越多，它的运行速度就越快。然而，如果您有一个 2GB 的数据库，那么添加超过 2–3GB 的内存不会有太大的区别，因为整个数据库无论如何都将位于 RAM 中。

### 了解工作集大小

现在，我们需要讨论与 MongoDB 实例的性能调优相关的更复杂的事情之一，即工作集大小。这个大小表示存储在 MongoDB 实例中“在常规使用过程中”将被访问的数据量光是这句话就应该告诉你，这是一个主观的衡量标准，很难得到一个准确的值。

尽管很难量化，但是理解工作集大小的影响将有助于您更好地优化 MongoDB 实例。主要原则是，对于大多数安装，只有一部分数据需要作为常规操作的一部分进行访问。了解您将定期处理的数据部分使您能够正确调整硬件的大小，从而提高性能。

### 选择正确的数据库服务器硬件

普遍存在转向低功耗(能源)系统托管服务的压力。然而，许多低功耗服务器使用膝上型电脑或笔记本电脑组件来实现较低的功耗。不幸的是，质量较低的服务器硬件可以使用特别便宜的磁盘驱动器。这种驱动器不适合重型服务器应用，因为它们的磁盘转速较低，从而降低了与驱动器之间的数据传输速率。此外，请确保使用声誉良好的供应商，即您信任的供应商，来组装针对服务器操作进行了优化的系统。还值得一提的是，固态硬盘等更快、更现代的驱动器已经上市，这将大幅提升性能。如果可以安排的话，MongoDB，Inc .团队建议使用 RAID10 来实现性能和冗余。对于那些在云中的人来说，从 Amazon 获得像预配 IOPS 这样的东西是提高磁盘性能和可靠性的一个很好的方法。

如果您计划使用复制或任何需要通过网络连接进行读取的频繁备份系统，您应该考虑添加一个额外的网卡并形成一个单独的网络，以便服务器可以相互通信。这减少了用于将应用程序连接到服务器的网络接口上传输和接收的数据量，这也会影响应用程序的性能。

购买硬件时最需要注意的可能就是 RAM。因为 MongoDB 使用内存映射文件，所以有足够的空间将必要的数据保存在可以快速访问的地方是确保高性能的一个好方法。这是您可以链接到前面讨论的工作集概念的地方。在考虑购买硬件时，了解需要分配多少数据是关键。最后，记住你不需要出去买 512GB 的 RAM 安装在一台服务器上；您可以使用分片来分散数据负载(在[第 12 章](12.html)中讨论)。

## 评估查询性能

MongoDB 有两个主要的优化查询性能的工具:`explain()`和 MongoDB Profiler(分析器)。profiler 是一个很好的工具，可以用来查找那些性能不佳的查询，并选择候选查询进行进一步的检查，而`explain()`适合于调查单个查询，因此您可以确定它的性能如何。

熟悉 MySQL 的人可能也熟悉慢速查询日志的用法，它可以帮助您找到消耗大量时间的查询；MongoDB 使用分析器来提供这种能力。

### MongoDB 分析器

MongoDB profiler 是一个工具，它记录满足触发条件的每个查询的统计信息和执行计划细节。通过使用`--profile`和`--slowms`选项启动 MongoD 进程，您可以在每个数据库上单独启用该工具，或者为所有数据库启用该工具(稍后将详细介绍这些值的含义)。这些选项也可以添加到你的`mongodb.conf`文件中，如果你是这样开始你的 MongoD 进程的话。

一旦启用了探查器，MongoDB 就会将一个文档插入到一个特殊的称为`system.profile`的有上限的集合中，该文档包含应用程序提交的每个查询的性能和执行细节信息。您可以使用此集合来检查使用标准集合查询命令记录的每个查询的详细信息。

`system.profile`集合被限制为最大 1024KB 的数据，这样探查器就不会用日志记录信息填充磁盘。这个限制应该足以捕获几千个甚至是最复杂的查询的概要文件。

Warning

启用探查器后，它会影响服务器的性能，因此让它在生产服务器上运行并不是一个好主意，除非您正在对一些观察到的问题进行分析。不要试图让它永久运行，以便为最近执行的查询提供一个窗口。

#### 启用和禁用数据库探查器

打开 MongoDB 分析器很简单:

`$mongo`

`>use blog`

`>db.setProfilingLevel(1)`

禁用分析器也同样简单:

`$mongo`

`>use blog`

`>db.setProfilingLevel(0)`

MongoDB 还可以只为超过指定执行时间的查询启用探查器。以下示例只记录执行时间超过半秒的查询:

`$mongo`

`>use blog`

`>db.setProfilingLevel(1,500)`

如此处所示，对于分析级别 1，您可以提供以毫秒(ms)为单位的最大查询执行时间值。如果查询运行的时间超过了这个时间量，就会对其进行分析和记录。否则，它将被忽略。这提供了与 MySQL 的慢速查询日志相同的功能。

最后，通过将探查器级别设置为 2，可以为所有查询启用分析。

`$mongo`

`>use blog`

`>db.setProfilingLevel(2)`

#### 查找慢速查询

`system.profile`集合中的典型记录如下所示:

`> db.system.profile.find()`

`{`

`"op" : "query"`，

`"ns" : "blog.system.profile"`，

`"query" : {`

`}`，

`"ntoreturn" : 0`，

`"ntoskip" : 0`，

`"nscanned" : 1`，

`"keyUpdates" : 0`，

`"numYield" : 0`，

`"lockStats" : {`

`"timeLockedMicros" : {`

`"r" : NumberLong(60)`，

`"w" : NumberLong(0)`

`}`，

`"timeAcquiringMicros" : {`

`"r" : NumberLong(4)`，

`"w" : NumberLong(3)`

`}`

`}`，

`"nreturned" : 1`，

`"responseLength" : 370`，

`"millis" : 12`，

`"ts" : ISODate("2013-05-18T05:40:27.106Z")`，

`"client" : "127.0.0.1"`，

`"user" : ""`

`}`

每个记录都包含字段，下面的列表概述了它们是什么以及它们的作用:

*   `op:`显示操作的类型；它可以是查询、插入、更新、命令或删除。
*   `query:`正在运行的查询。
*   运行此查询的完整名称空间。
*   `ntoreturn`:要返回的单据数量，
*   `nscanned`:扫描返回本文档的索引条目数。
*   `ntoskip`:跳过的文档数。
*   `keyUpdates`:本次查询更新的索引键个数。
*   `numYields`:该查询将其锁让给另一个查询的次数。
*   `lockStats`:获取或读写该数据库的锁所花费的微秒数。
*   `nreturned`:返回的文档数。
*   `responseLength`:响应的字节长度。
*   `millis`:执行查询所用的毫秒数。
*   `ts`:以 UTC 格式显示时间戳，指示查询的执行时间。
*   `client`:运行此查询的客户端的连接详细信息。
*   `user`:运行此操作的用户。

因为`system.profile`集合只是一个普通的集合，所以您可以使用 MongoDB 的查询工具快速找到有问题的查询。

下一个示例查找执行时间超过 10ms 的所有查询。在这种情况下，您可以只在`system.profile`集合中查询`millis >10`的情况，然后按照执行时间降序排列结果:

`> db.system.profile.find({millis:{$gt:10}}).sort({millis:-1})`

`{ "op" : "query", "ns" : "blog.system.profile", "query" : { }, "ntoreturn" : 0, "ntoskip" : 0, "nscanned" : 1, "keyUpdates" : 0, "numYield" : 0, "lockStats" : { "timeLockedMicros" : { "r" : NumberLong(60), "w" : NumberLong(0) }, "timeAcquiringMicros" : { "r" : NumberLong(4), "w" : NumberLong(3) } }, "nreturned" : 1, "responseLength" : 370, "millis" : 12, "ts" : ISODate("2013-05-18T05:40:27.106Z"), "client" : "127.0.0.1", "allUsers" : [ ], "user" : "" }`

如果您还知道您的问题发生在特定的时间范围内，那么您可以使用`ts`字段添加查询词，将范围限制在所需的时间片。

#### 增加配置文件集合的大小

如果您发现由于某种原因您的配置文件集合太小，您可以增加它的大小。

首先，您需要在希望增加其概要文件集合大小的数据库上禁用概要文件分析，以确保在执行此操作时没有任何内容写入其中:

`$mongo`

`>use blog`

`>db.setProfilingLevel(0)`

接下来，您需要删除现有的`system.profile`集合:

`>db.system.profile.drop()`

删除集合后，您现在可以使用`createCollection`命令创建新的 profiler 集合，并指定所需的字节大小。下面的示例创建一个上限为 50MB 的集合。它使用的表示法是将 50 字节转换为千字节，然后再转换为兆字节，每增加一次，就要乘以 1024:

`>db.createCollection( "system.profile", { capped: true, size: 50 * 1024 * 1024 } )`

`{ "ok" : 1 }`

有了新的更大的封顶集合，现在可以重新启用概要分析了:

`>db.setProfilingLevel(2)`

### 使用 explain()分析特定查询

如果您怀疑某个查询的性能不如预期，您可以使用`explain()`修饰符来查看 MongoDB 是如何执行查询的。

当您将`explain()`修饰符添加到查询中时，MongoDB 在执行时会返回一个描述查询如何处理的文档，而不是指向结果的光标。以下查询针对博客文章的数据库运行，表明该查询必须扫描 13，325 条记录，才能形成返回所有文章的游标:

`$mongo`

`>use blog`

`> db.posts.find().explain()`

`{`

`"cursor" : "BasicCursor"`，

`"isMultiKey" : false`，

`"n" : 13235`，

`"nscannedObjects" : 13235`，

`"nscanned" : 13235`，

`"nscannedObjectsAllPlans" : 13235`，

`"nscannedAllPlans" : 13235`，

`"scanAndOrder" : false`，

`"indexOnly" : false`，

`"nYields" : 0`，

`"nChunkSkips" : 0`，

`"millis" : 0`，

`"indexBounds" : {`

`}`，

`"server" : "Pixl.local:27017"`

`}`

您可以看到表[10–1](#Tab1)中列出的`explain()`返回的字段。

表 10–1。

Elements Returned by explain()

<colgroup><col> <col></colgroup> 
| 元素 | 描述 |
| --- | --- |
| `Cursor` | 指示为枚举结果而创建的游标的类型。通常，这是下列之一:`BasicCursor`，自然顺序阅读光标；一个`BtreeCursor`，它是一个索引光标；或者是一个`GeoSearchCursor`，这是一个使用地理空间索引的查询。 |
| `indexBounds` | 指示索引查找中使用的最小/最大值。 |
| `nScanned` | 指示为查找查询中的所有对象而扫描的索引条目数。 |
| `nScannedObjects` | 指示被扫描的实际对象的数量，而不仅仅是它们的索引项。 |
| `n` | 指示光标上的项数(即要返回的项数)。 |
| `millis` | 指示执行查询所用的毫秒数。 |
| `nscannedAllPlans` | 表示所有尝试计划的`nscanned`值。 |
| `nscannedObjectsAllPlans` | 表示所有尝试计划的`nScannedObjects`值。 |
| `scanAndOrder` | 一个 true/false 值，指示文档是否需要阅读才能排序，而不是利用索引。 |
| `indexOnly` | 表示不需要扫描任何文档来返回查询结果；所有被查询和返回的字段都在一个索引上。 |
| `nYields` | 该查询产生其读锁以允许执行写操作的次数。 |
| `nChunkSkips` | 由于活动块迁移而跳过的文档数。 |
| `server` | 执行该查询的服务器。 |

### 使用 Profiler 和 explain()优化查询

现在让我们浏览一个真实的优化场景，看看我们如何使用 MongoDB 的 profiler 和`explain()`工具来修复一个真实应用程序的问题。

本章中讨论的例子是基于一个小的示例博客应用程序。该数据库具有获取与特定标签相关联的帖子的功能；在这种情况下，它是`even`标签。假设您已经注意到这个函数运行缓慢，因此您想确定是否有问题。

让我们从编写一个小程序开始，用数据填充前面提到的数据库，这样我们就可以运行查询，演示优化过程。

`<?php`

`// Get a connection to the database`

`$mongo = new MongoClient();`

`$db=$mongo->blog;`

`// First let's get the first AuthorsID`

`// We are going to use this to fake a author`

`$author = $db->authors->findOne();`

`if(!$author){`

`die("There are no authors in the database");`

`}`

`for( $i = 1; $i < 10000; $i++){`

`$blogpost=array();`

`$blogpost['author'] = $author['_id'];`

`$blogpost['Title'] = "Completely fake blogpost number {$i}";`

`$blogpost['Message'] = "Some fake text to create a database of blog posts";`

`$blogpost['Tags'] = array();`

`if($i%2){`

`// Odd numbered blogs`

`$blogpost['Tags'] = array("blog", "post", "odd", "tag{$i}");`

`} else {`

`// Even numbered blogs`

`$blogpost['Tags'] = array("blog", "post", "even", "tag{$i}");`

`}`

`$db->posts->insert($blogpost);`

`}`

`?>`

这个程序在`blog`数据库的`authors`集合中找到第一个作者，然后假装这个作者非常多产。它以作者的名义创建了 10，000 个虚假的博客帖子，所有这些都是在眨眼之间完成的。帖子读起来没什么意思；然而，它们被交替分配了`odd`和`even`标签。这些标签将用来演示如何优化一个简单的查询。

下一步是将程序保存为`fastblogger.php`，然后使用命令行 PHP 工具运行它:

`$php fastblogger.php`

接下来，您需要启用数据库概要分析器，您将使用它来确定是否可以改进示例的查询:

`$ mongo`

`> use blog`

`switched to db blog`

`> show collections`

`authors`

`posts`

`...`

`system.profile`

`tagcloud`

`...`

`users`

`> db.setProfilingLevel(2)`

`{ "was" : 0, "slowms" : 100, "ok" : 1 }`

现在稍等片刻，让命令生效，打开所需的集合，然后执行其他任务。接下来，您想要模拟让博客网站访问所有带有`even`标签的博客文章。通过执行站点可以用来实现此功能的查询来实现这一点:

`$Mongo`

`use blog`

`$db.posts.find({Tags:"even"})`

`...`

如果您在`profiler`集合中查询超过 5 毫秒的结果，您应该会看到类似这样的内容:

`>db.system.profile.find({millis:{$gt:5}}).sort({millis:-1})`

`{ "op" : "query", "ns" : "blog.posts", "query" : { "tags" : "even" }, "ntoreturn" : 0, "ntoskip" : 0, "nscanned" : 19998, "keyUpdates" : 0, "numYield" : 0, "lockStats" : { "timeLockedMicros" : { "r" : NumberLong(12869), "w" : NumberLong(0) }, "timeAcquiringMicros" : { "r" : NumberLong(5), "w" : NumberLong(3) } }, "nreturned" : 0, "responseLength" : 20, "millis" : 12, "ts" : ISODate("2013-05-18T09:04:32.974Z"), "client" : "127.0.0.1", "allUsers" : [ ], "user" : "" }...`

这里返回的结果显示，一些查询花费的时间超过 0 毫秒(记住本章开头的引文)。

接下来，您希望为第一个(也是性能最差的)查询重建查询，这样您就可以看到返回了什么。前面的输出表明性能差的查询正在查询`blog.posts`，查询词是`{Tags:"even"}`。最后，您可以看到这个查询花费了 15 毫秒来执行。

重建的查询如下所示:

`>db.posts.find({Tags:"even"})`

`{ "_id" : ObjectId("4c727cbd91a01b2a14010000"), "author" : ObjectId("4c637ec8b8642fea02000000"), "Title" : "Completly fake blogpost number 2", "Message" : "Some fake text to create a database of blog posts", "Tags" : [ "blog", "post", "even", "tag2" ] }`

`{ "_id" : ObjectId("4c727cbd91a01b2a14030000"), "author" : ObjectId("4c637ec8b8642fea02000000"), "Title" : "Completly fake blogpost number 4", "Message" : "Some fake text to create a database of blog posts", "Tags" : [ "blog", "post", "even", "tag4" ] }`

`{ "_id" : ObjectId("4c727cbd91a01b2a14050000"), "author" : ObjectId("4c637ec8b8642fea02000000"), "Title" : "Completly fake blogpost number 6", "Message" : "Some fake text to create a database of blog posts", "Tags" : [ "blog", "post", "even", "tag6" ] }`

`...`

这一结果应该不足为奇；创建这个查询的明确目的是演示如何查找和修复一个缓慢的查询。

目标是找出如何让查询运行得更快，所以使用`explain()`函数来确定 MongoDB 如何执行这个查询:

`> db.posts.find({Tags:"even"}).explain()`

`{`

`"cursor" : "BasicCursor"`，

`"isMultiKey" : false`，

`"n" : 14997`，

`"nscannedObjects" : 29997`，

`"nscanned" : 29997`，

`"nscannedObjectsAllPlans" : 29997`，

`"nscannedAllPlans" : 29997`，

`"scanAndOrder" : false`，

`"indexOnly" : false`，

`"nYields" : 0`，

`"nChunkSkips" : 0`，

`"millis" : 27`，

`"indexBounds" : {`

`}`，

`"server" : "Pixl.local:27017"`

`}`

从这里的输出可以看出，查询没有使用任何索引。`explain()`函数显示该查询使用了一个“`BasicCursor`”，这意味着该查询只是对集合的记录进行简单的扫描。具体来说，它正在逐个扫描数据库中的所有记录，以找到标签(全部 9999 个标签)；这个过程需要 27 毫秒。这听起来时间可能不长，但是如果您在网站的热门页面上使用这个查询，将会给磁盘 I/O 带来额外的负载，并给 web 服务器带来巨大的压力。因此，在创建页面时，该查询会导致与 web 浏览器的连接保持更长时间的打开。

Note

如果您看到一个详细的查询说明，显示扫描的记录(`nscanned`)比它返回的记录(`n`)多得多，那么该查询可能是索引的候选。

下一步是确定在`Tags`字段上添加索引是否会提高查询的性能:

`> db.posts.ensureIndex({Tags:1})`

现在再次运行`explain()`函数，查看添加索引的效果:

`> db.posts.find({Tags:"even"}).explain()`

`{`

`"cursor" : "BtreeCursor Tags_1"`，

`"isMultiKey" : true`，

`"n" : 14997`，

`"nscannedObjects" : 14997`，

`"nscanned" : 14997`，

`"nscannedObjectsAllPlans" : 14997`，

`"nscannedAllPlans" : 14997`，

`"scanAndOrder" : false`，

`"indexOnly" : false`，

`"nYields" : 0`，

`"nChunkSkips" : 0`，

`"millis" : 4`，

`"indexBounds" : {`

`"Tags" : [`

`[`

`"even"`，

`"even"`

`]`

`]`

`}`，

`"server" : "Pixl.local:27017"`

`}`

查询的性能有了显著的提高。您可以看到该查询现在使用了由`Tags_1`索引驱动的`BtreeCursor`。扫描的记录数量从 29，997 条减少到了您期望查询返回的 14，997 条，执行时间也减少到了 4 毫秒。

Note

最常见的索引类型，也是 MongoDB 唯一使用的索引类型，是 btree(二叉树)。`BtreeCursor`是一个 MongoDB 数据游标，它使用二叉树索引在文档间导航。Btree 索引在数据库系统中非常常见，因为它们提供了快速的插入和删除，而且在用于遍历或排序数据时还提供了合理的性能。

## 管理索引

您现在已经看到了引入精心选择的索引会产生多大的影响。

正如您在[第 3 章](03.html)中了解到的，MongoDB 的索引既用于查询(`find`、`findOne`)也用于排序。如果您打算在集合中使用很多排序，那么您应该添加符合您的排序规范的索引。如果在排序规范中没有字段索引的集合上使用`sort()`,那么如果超出了内部排序缓冲区的最大大小，可能会得到一条错误消息。因此，为排序创建索引是一个好主意。在接下来的几节中，我们将再次触及基础知识，但也会添加一些与如何管理和操作系统中的索引相关的细节。我们还将介绍这些指数与一些样本的关系。

当您向集合添加索引时，MongoDB 必须维护它，并在您每次执行任何写操作时更新它(例如，`updates`、`inserts`或`deletes`)。如果集合中有太多索引，可能会对写入性能产生负面影响。

索引最适合用于大多数访问是读访问的集合。对于日志记录系统中使用的大量写操作的集合，引入索引会降低每秒钟流入集合的峰值文档数。

Warning

此时，每个集合最多可以有 64 个索引。

### 列出索引

MongoDB 有一个简单的助手函数`getIndexes()`，用于列出给定集合的索引。执行时，它将打印一个 JSON 数组，该数组包含给定集合上每个索引的详细信息，包括它们引用的字段或元素以及您可能在该索引上设置的任何选项。

`$mongo`

`>use blog`

`>db.posts.getIndexes()`

`[`

`{`

`"v" : 1`，

`"key" : {`

`"_id" : 1`

`}`，

`"ns" : "blog.posts"`，

`"name" : "_id_"`

`}`

`]`

MongoDB 在每个数据库中维护一个名为`system.indexes`的特殊集合。该集合跟踪数据库中所有集合上创建的所有索引。

`system.indexes`收藏就像任何普通的收藏一样。您可以列出其内容，对其运行查询，或者执行您可以使用典型集合完成的常规任务。

以下示例列出了简单数据库中的索引:

`$mongo`

`>use blog`

`>db.system.indexes.find()`

`{ "v" : 1, "key" : { "_id" : 1 }, "ns" : "blog.posts", "name" : "_id_" }`

`{ "v" : 1, "key" : { "_id" : 1 }, "ns" : "blog.authors", "name" : "_id_" }`

`blog`数据库没有任何用户定义的索引，但是您可以看到为您的两个集合上的`_id`字段自动创建的两个索引:`posts`和`authors`。您不必做任何事情来创建或删除这些身份索引；每当创建或删除一个集合时，MongoDB 都会创建和删除它们。

当您在元素上定义索引时，MongoDB 将构造一个内部 btree 索引，它将使用该索引来高效地定位文档。如果找不到合适的索引，MongoDB 将扫描集合中的所有文档，以找到满足查询的记录。

### 创建简单索引

MongoDB 提供了用于向集合添加新索引的`ensureIndex()`函数。这个函数首先检查是否已经用相同的规范创建了一个索引。如果有，那么`ensureIndex()`就返回那个索引。这意味着您可以任意多次调用`ensureIndex()`，但这不会导致为您的集合创建大量额外的索引。

以下示例定义了一个简单的索引:

`$mongo`

`>use blog`

`>db.posts.ensureIndex({Tags:1})`

这个例子在`Tags`字段上创建了一个简单的升序 btree 索引。相反，创建一个降序索引只需要一个小小的改动:

`>db.posts.ensureIndex({Tags:-1})`

要索引嵌入文档中的字段，可以使用普通的点标记寻址方案；也就是说，如果您有一个位于`comments`子文档中的`count`字段，您可以使用以下语法对其进行索引:

`>db.posts.ensureIndex({"comments.count":1})`

如果您指定一个数组类型的文档字段，那么索引将包含数组的所有元素作为单独的索引项。这称为多键索引，每个文档都链接到索引中的多个值。如果您回过头来检查我们之前查询的`explain()`输出，您可以看到这里提到了这一点。

MongoDB 有一个特殊的操作符`all`，用于执行希望只选择包含您提供的所有术语的文档的查询。在`blog`数据库示例中，您有一个包含元素`Tags`的`posts`集合。这个元素包含了与文章相关的所有标签。以下查询查找同时具有`sailor`和`moon`标签的所有文章:

`>db.posts.find({Tags:{$all: ['sailor', 'moon']}})`

如果在`Tags`字段上没有多键索引，查询引擎将不得不扫描集合中的每个文档，以查看其中一个术语是否存在，如果存在，则检查两个术语是否都存在。

### 创建复合索引

简单地为任何查询中提到的每个字段创建一个单独的索引可能很有诱惑力。虽然这可以在不需要太多考虑的情况下加快查询速度，但不幸的是，这会对添加和删除数据库中的数据产生重大影响，因为这些索引每次都需要更新。同样重要的是要注意，在 MongoDB 2.4 和更早的版本中，只有一个索引会被用来满足查询的结果，所以添加许多小索引通常不会帮助查询的执行。

复合索引提供了一种减少集合中索引数量的好方法，允许您将多个字段组合成一个索引，因此您应该尽可能使用复合索引。

复合索引主要有两种类型:子文档索引和手动定义的复合索引。

MongoDB 有一些规则允许它对不使用所有组件键的查询使用复合索引。理解这些规则使您能够构建一组复合索引，覆盖您希望对集合执行的所有查询，而不必单独索引每个元素(从而避免前面提到的对插入/更新性能的附带影响)。

复合索引可能没有用的一个方面是在排序中使用索引。排序不擅长使用复合索引，除非术语列表和排序方向与索引结构完全匹配。

当您使用子文档作为索引键时，用于建立多键索引的元素的顺序与它们在子文档的内部 BSON 表示中出现的顺序相匹配。在许多情况下，这并不能让您对创建索引的过程有足够的控制。

要绕过这一限制，同时保证查询使用以所需方式构造的索引，需要确保使用相同的子文档结构来创建形成查询时使用的索引，如下例所示:

`>db.articles.find({author:{name: 'joe', email: 'joe@blogger.com` `'}))`

还可以通过命名索引中要组合的所有字段，然后指定组合它们的顺序，来显式创建复合索引。以下示例说明了如何手动构建复合索引:

`>db.posts.ensureIndex({"author.name":1, "author.email":1})`

## 指定索引选项

创建索引时可以指定几个有趣的选项，比如创建唯一索引或启用后台索引；在接下来的章节中，您将了解更多关于这些选项的信息。您将这些选项指定为`ensureIndex()`函数的附加参数，如下例所示:

`>db.posts.ensureIndex({author:1}, {option1:true, option2:true, ..... })`

### 使用{background:true}在后台创建索引

当您第一次使用`ensureIndex()`函数指示 MongoDB 创建索引时，服务器必须读取集合中的所有数据并创建指定的索引。默认情况下，索引构建在前台完成，在索引操作完成之前，对集合数据库的所有操作都被阻止。

MongoDB 还包含一个特性，允许在后台执行索引的初始构建。在建立索引时，其他连接对该数据库的操作不会被阻止。在索引建立之前，任何查询都不会使用它，但是服务器将允许读写操作继续进行。一旦索引操作完成，所有需要该索引的查询将立即开始使用它。值得注意的是，虽然可以在后台构建索引，但它需要更长的时间才能完成。

因此，您可能希望研究构建索引的其他策略。最好的策略可能是在一个副本集中轮流执行构建。为此，您一次停止一个辅助节点，并在没有其`--replSet`参数的情况下在不同的端口上启动它，暂时使它成为一个独立的节点。然后，您可以放心地在这个辅助服务器上执行索引构建。索引构建完成后，像往常一样启动辅助服务器，让它重新加入副本集并跟上。对所有次要成员重复此过程。最后，停止主服务器，对`--replSet`执行相同的删除，并为它构建一个索引进程，然后像往常一样让它重新加入副本集。通过以这种方式旋转您的副本集，您可以在没有停机或中断的情况下建立索引！

Note

该索引将在后台构建。但是，如果从 MongoDB shell 发出命令，发起请求的连接将被阻塞。在索引操作完成之前，在此连接上发出的命令不会返回。乍一看，这似乎与它是一个背景指数的想法相矛盾。但是，如果您同时打开了另一个 MongoDB shell，您会发现在索引构建过程中，对该集合的查询和更新会不受阻碍地运行。只有发起连接被阻塞。这不同于您看到的简单的`ensureIndex()`命令的行为，该命令不在后台运行，因此第二个 MongoDB shell 上的操作也会被阻塞。

KILLING THE INDEXING PROCESS

如果您认为当前的索引进程已经挂起或者花费了太长时间，您也可以终止它。您可以通过调用`killOp()`函数来实现:

`> db.killOp(<operation id>)`

要运行 killOp，您需要知道操作的操作 ID。通过运行`db.currentOp()`命令，可以获得 MongoDB 实例上当前运行的所有操作的列表。

注意，当您调用`killOp()`命令时，部分索引也将再次被删除。这可以防止数据库中出现不完整或不相关的数据。

### 创建具有唯一键{unique:true}的索引

当您指定`unique`选项时，MongoDB 会创建一个索引，其中所有的键都必须不同。这意味着，如果您试图插入一个索引键与现有文档的键相匹配的文档，MongoDB 将返回一个错误。这对于您希望确保没有两个人拥有相同身份(即相同的`userid`)的领域非常有用。

但是，如果要向已经填充了数据的现有集合添加唯一索引，则必须确保已经对键进行了重复数据删除。在这种情况下，如果任意两个键不唯一，创建索引的尝试将会失败。

`unique`选项适用于简单和复合索引，但不适用于多键值索引，在多键值索引中它们没有多大意义。

如果插入的文档缺少一个被指定为惟一键的字段，那么 MongoDB 将自动插入该字段，但是会将其值设置为`null`。这意味着您只能将一个缺少关键字段的文档插入到这样的集合中；任何额外的`null`值都意味着这个键不是惟一的，正如所要求的那样。

### 使用{dropdups:true}自动删除重复项

如果您想为已知存在重复键的字段创建唯一索引，您可以指定`dropdups`选项。该选项指示 MongoDB 删除会导致索引创建失败的文档。在这种情况下，MongoDB 将保留它在集合的自然排序中找到的第一个文档，但随后丢弃任何其他会导致违反索引约束的文档。

Warning

使用`dropdups`选项时需要非常小心，因为它会导致文档从您的收藏中删除。

在使用此选项之前，您应该非常清楚您的集合中的数据；否则，您可能会得到意想不到的(更不用说不想要的)行为。对希望使键唯一的集合运行组查询是一个非常好的主意；这将使您能够在执行此选项之前确定被视为重复的文档数量。

### 使用{sparse:true}创建稀疏索引

有时，只为包含给定字段条目的文档创建索引是值得的。例如，假设您想要索引电子邮件，并且您知道并非所有电子邮件都有“抄送”或“密件抄送”字段。如果您在 CC 或 BCC 上创建索引，那么所有文档都将添加一个“null”值，除非您指定一个稀疏索引。这是一种节省空间的机制，因为您只对有效文档而不是所有文档进行索引。当然，这对于任何运行和使用稀疏索引的查询都有影响；因为可能存在查询中未评估的文档。

### TTL 索引

在计算术语中，TTL(生存时间)是一种通过指定一个点来赋予特定数据或请求一个生命周期的方式，在该点上它变得无效。这对于存储在 MongoDB 实例中的数据也很有用，因为自动删除旧数据通常很好。为了创建一个 TTL 索引，你必须添加一个`expireAfterSeconds`标志和一个秒值到一个单一的(非复合的)索引。这将表明，当 TTL 删除任务下次执行时，任何索引字段大于给定 TTL 值的文档都将被删除。由于删除任务每 60 秒运行一次，因此在删除旧文档之前可能会有一些延迟。

Warning

被索引的字段必须是 BSON 日期类型；否则不会被评估为删除。如下例所示，当从 shell 中查询时，BSON 日期将显示为`ISODate`。

例如，假设我们想从博客的`comments`集合中自动删除任何内容，该集合的创建时间戳超过了某个年龄。以这个来自`comments`集合的示例文档为例:

`>db.comments.find();`

`{`

`"_id" : ObjectId("519859b32fee8059a95eeace")`，

`"author" : "david"`，

`"body" : "foo"`，

`"ts" : ISODate("2013-05-19T04:48:51.540Z")`，

`"tags" : [ ]`

`}`

假设我们想要删除任何超过 28 天的评论。我们算出 28 天有 2419200 秒长。然后，我们按如下方式创建索引:

`>db.comments.ensureIndex({ts:1},{ expireAfterSeconds: 2419200})`

当此文档比当前系统时间早 2，419，200 秒时，它将被删除。您可以通过使用以下语法创建一个超过 2，419，200 秒的文档来进行测试:

`date = new Date(new Date().getTime()-2419200000);`

`db.comments.insert({ "author" : test", "body" : "foo", "ts" : date, "tags" : [] });`

现在只需等待一分钟，该文件应被删除。

Note

当您设置 TTL 索引时，MongoDB 会在给定的集合上设置`usePowerOf2Sizes`标志。这将使每个文件的存储空间标准化。这允许空间在被删除后被未来的文档更有效地重用。

### 文本搜索索引

MongoDB 2.4 引入了一种新的索引类型——文本索引，它允许您执行全文搜索！[第 8 章](08.html)详细讨论了文本索引特性，但在我们研究优化时，这里有必要快速总结一下。文本搜索一直是 MongoDB 的一个理想特性，因为它允许您在一个大的文本块中搜索特定的单词或文本。文本搜索相关性的最好例子是对博客文章正文的搜索功能。这种搜索允许您在文档的一个文本字段(如正文)或多个文本字段(如正文和注释)中查找单词或短语。因此，为了创建文本索引，我们运行以下命令:

`>db.posts.ensureIndex( { body: "text" } )`

Note

文本搜索不区分大小写，这意味着它将忽略大小写；“mongodb”和“MongoDB”被视为同一文本。

现在我们可以使用文本索引和`text`命令进行搜索。为此，我们使用`runCommand`语法来使用`text`命令，并为其提供一个要搜索的值:

`>db.posts.runCommand( "text", { search: "MongoDB" } )`

您的文本搜索结果将按相关性顺序返回给您。

Warning

MongoDB 文本搜索仍然相对较新，并且正在经历快速发展。

### 删除索引

您可以选择删除集合中的所有索引或仅删除一个特定索引。使用以下函数删除集合中的所有索引:

`>db.posts.dropIndexes()`

要从集合中删除单个索引，可以使用与使用`ensureIndex()`创建索引的语法相对应的语法:

`>db.posts.dropIndex({"author.name":1, "author.email":1});`

### 重新索引收藏

如果您怀疑集合中的索引已损坏，例如，如果您的查询得到不一致的结果，那么您可以强制对受影响的集合重新建立索引。

这将强制 MongoDB 删除并重新创建指定集合上的所有索引(有关如何检测和解决索引问题的更多信息，请参见[第 9 章](09.html))，如下例所示:

`> db.posts.reIndex()`

`{`

`"nIndexesWas" : 2`，

`"msg" : "indexes dropped for collection"`，

`"nIndexes" : 2`，

`"indexes" : [`

`{`

`"key" : {`

`"_id" : 1`

`}`，

`"ns" : "blog.posts"`，

`"name" : "_id_"`

`}`，

`{`

`"key" : {`

`"Tags" : 1`

`}`，

`"ns" : "blog.posts"`，

`"name" : "Tags_1"`

`}`

`]`，

`"ok" : 1`

`}`

输出列出了该命令重新构建的所有索引，包括键。此外，`nIndexWas:`字段显示了在运行命令之前存在多少个索引，而`nIndex:`字段给出了命令完成之后的索引总数。如果两个值不相同，则意味着在重新创建集合中的某些索引时出现了问题。

## MongoDB 如何选择它将使用的索引

当一个数据库系统需要运行一个查询时，它必须组装一个查询计划，查询计划是它执行查询所必须运行的步骤的列表。每个查询可能有多个查询计划，这些计划同样可以产生相同的结果。然而，每个计划都可能包含比其他计划执行起来更昂贵的元素。例如，扫描集合中的所有记录是一项开销很大的操作，任何包含这种方法的计划都会很慢。这些计划还可以包括用于查询和排序操作的备选索引列表。

道路指示很好地说明了这一概念。如果你想从一个拐角到达街区的斜对面，那么“左转，然后右转”和“右转，然后左转”是到达对面拐角的同样有效的计划。然而，如果其中一条路线有两个停车标志，而另一条没有，那么前一种方法是一个更昂贵的方案，而后一种方法是最好的方案。在执行查询时，集合扫描可能会成为潜在的停止标志。

MongoDB 附带了一个名为查询分析器的组件。这个组件接受一个查询和查询目标的集合，然后为 MongoDB 生成一组要执行的计划。本章前面描述的`explain()`函数列出了所使用的计划和为给定查询生成的一组备选计划。

MongoDB 还附带了一个查询优化器组件。该组件的工作是选择最适合运行特定查询的执行计划。在大多数关系数据库系统中，查询优化器使用关于表中键的分布、记录数量、可用索引、先前选择的有效性以及各种加权因子的统计信息来计算每种方法的成本。然后，它选择最便宜的计划来使用。

MongoDB 中的查询优化器比典型的 RDBMS 查询分析器既笨又聪明。例如，它不使用基于成本的方法来选择执行计划；相反，它并行运行所有这些程序，并使用返回结果最快的程序，在获胜者越过终点线后终止所有其他程序。因此，MongoDB 中的查询分析器使用一种简单的机制(dumb)来确保它总是获得最快的结果(smart ),并且这些计划的结果被缓存并在接下来的 1000 次写操作中重用，直到执行解释或在该集合上添加、删除或重新索引任何索引。

## 使用 hint()强制使用特定索引

MongoDB 中的查询优化器从查询的候选索引集中选择最佳索引。它使用刚才概述的方法来尝试将最佳索引或索引集与给定的查询进行匹配。但是，在有些情况下，查询优化器可能没有做出正确的选择，在这种情况下，可能有必要帮助组件。

在这种情况下，您可以向查询优化器提供提示，促使组件做出不同的选择。例如，如果您已经使用了`explain()`来显示您的查询正在使用哪些索引，并且您认为您希望它对给定的查询使用不同的索引，那么您可以强制查询优化器这样做。

让我们看一个例子。假设您有一个名为`author`的子文档的索引，其中有`name`和`email`字段。还假设您有以下定义的索引:

`>db.posts.ensureIndex({author.name:1, author.email:1})`

您可以使用以下提示来强制查询优化器使用定义的索引:

`>db.posts.find({author:{name:'joe', email: 'joe@mongodb.com` `'}}).hint({author.name:1, author.email:1})`

如果出于某种原因，您希望强制查询不使用索引，也就是说，如果您希望使用集合文档扫描作为选择记录的方法，您可以使用以下提示来完成此操作:

`>db.posts.find({author:{name: 'joe', email: 'joe@mongodb.com` `'}}).hint({$natural:1})`

## 优化小对象的存储

索引是加速数据查询的关键。但是影响应用程序性能的另一个因素是它所访问的数据的大小。与具有固定模式的数据库系统不同，MongoDB 将每个记录的所有模式数据存储在记录本身中。因此，对于每个字段具有大量数据内容的大型记录，模式数据与记录数据的比率较低；但是，对于具有小数据值的小记录，这个比率可能会变得惊人地大。

考虑一个 MongoDB 非常适合的应用程序类型中的常见问题:日志记录。MongoDB 非凡的写入速度使得将事件作为小文档流式传输到集合中非常高效。但是，如果您想进一步优化执行该功能的速度，您可以做几件事情。

首先，您可以考虑批量插入。MongoDB 附带了一个多文档`insert()`调用。您可以使用此调用同时将几个事件放入集合中。这导致通过数据库接口 API 的往返次数减少。

其次(也是更重要的)，您可以减少字段名的大小。如果字段名较小，MongoDB 可以在将事件记录刷新到磁盘之前将更多的事件记录打包到内存中。这使得整个系统效率更高。

例如，假设您有一个用于记录三个字段的集合:一个时间戳、一个计数器和一个用于指示数据源的四字符字符串。您的数据的总存储大小如表[10–2](#Tab2)所示。

表 10–2。

The Logging Example Collection Storage Size

<colgroup><col> <col></colgroup> 
| 田 | 大小 |
| --- | --- |
| 时间戳 | 8 字节 |
| 整数 | 4 字节 |
| 线 | 4 字节 |
| 总数 | 16 字节 |

如果您使用`ts`、`n`和`src`作为字段名，那么字段名的总大小是 6 个字节。与数据大小相比，这是一个相对较小的值。但是现在假设您决定将字段命名为`WhenTheEventHappened`、`NumberOfEvents`和`SourceOfEvents`。在这种情况下，字段名的总大小是 48 个字节，是数据本身大小的三倍。如果您将 1TB 的数据写入一个集合，那么您将存储 750GB 的字段名称，但只有 250GB 的实际数据。

这不仅浪费了磁盘空间。它还会影响系统性能的所有其他方面，包括索引大小、数据传输时间，以及(可能更重要的是)使用宝贵的系统 RAM 来缓存数据文件。

在日志应用程序中，您还需要避免在写入记录时在集合上添加索引；如前所述，维护索引需要时间和资源。相反，您应该在开始分析数据之前立即添加索引。

最后，您应该考虑使用将事件流分成多个集合的模式。例如，您可以将每天的事件写入单独的集合。较小的集合需要较少的时间进行索引和分析。

## 摘要

在这一章中，我们研究了一些跟踪 MongoDB 查询中缓慢性能的工具，以及加速由此产生的缓慢查询的潜在解决方案。我们还研究了一些优化数据存储的方法。例如，我们研究了确保充分利用 MongoDB 服务器可用资源的方法。

本章中描述的特定技术使您能够优化数据并调优存储数据的 MongoDB 系统。最佳方法因应用程序而异，取决于许多因素，包括应用程序类型、数据访问模式、读/写比率等。