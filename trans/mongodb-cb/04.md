# 第四章管理

在本章中，我们将看到以下与 MongoDB 管理相关的配方：

*   重命名集合
*   查看集合统计信息
*   查看数据库统计信息
*   手动填充文档
*   mongostat 和 mongotop 公用事业公司
*   获取当前正在执行的操作并杀死它们
*   使用探查器对操作进行探查
*   在 Mongo 中设置用户
*   Mongo 中的进程间安全
*   使用 collMod 命令修改集合行为
*   将 MongoDB 设置为 Windows 服务
*   副本集配置
*   从副本集中作为主副本逐步退出
*   探索副本集的本地数据库
*   理解和分析 oplog
*   构建带标记的副本集
*   为非分片集合配置默认分片
*   块的手动拆分和迁移
*   使用标记的域驱动分片
*   在分片设置中探索配置数据库

# 导言

在本章中，我们将介绍一些管理 MongoDB 的工具和实践。以下方法将帮助您从数据库中收集统计信息、管理用户访问、分析 oplog 以及研究使用副本集的某些方面。

# 重命名集合

您是否曾经遇到过这样一种场景：您在关系数据库中命名了一个表，并且在以后的某个时间点上觉得该名称本可以更好？或者，您所在的组织很晚才意识到表名真的越来越乱，并对表名实施了一些标准？关系数据库确实有一些专有的方法来重命名表，数据库管理员会为您这样做。

但这也提出了一个问题。在 Mongo world 中，集合是表的同义词，有没有办法在创建集合后将其重命名为其他名称？在本食谱中，我们将探索 Mongo 的这一特性，其中我们重命名了包含一些数据的现有集合。

## 准备好了吗

我们需要运行一个 MongoDB 实例来执行这个集合重命名实验。有关如何启动服务器的信息，请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*配方。我们将从 mongo shell 执行操作。

## 怎么做…

1.  一旦服务器启动并假设它正在默认端口`27017`上侦听客户端连接，执行以下命令从 shell 连接到它：

    ```
    > mongo

    ```

2.  连接后，使用默认测试数据库。让我们用一些测试数据创建一个集合。我们将使用的集合名为：

    ```
    sloppyNamedCollection.
    > for(i = 0 ; i < 10 ; i++) { db.sloppyNamedCollection.insert({'i':i}) };

    ```

3.  现在将创建测试数据（我们可以通过查询集合`sloppyNamedCollection`来验证数据）。
4.  将集合重命名为`neatNamedCollection`如下：

    ```
    > db.sloppyNamedCollection.renameCollection('neatNamedCollection')
    { "ok" : 1 }

    ```

5.  通过执行：

    ```
    > show collections

    ```

    验证集合`sloppyNamedCollection`不再存在
6.  最后，查询`neatNamedCollection`集合，验证`sloppyNamedCollection`中的原始数据是否确实存在。只需在 mongo shell 上执行以下操作：

    ```
    > db.neatNamedCollection.find()

    ```

## 它是如何工作的…

重命名集合非常简单。它是通过采用两个参数的`renameCollection`方法完成的。一般情况下，函数签名如下：

```
> db.<collection to rename>.renameCollection('<target name of the collection>', <drop target if exists>)

```

第一个参数是要重命名集合的名称。

我们没有使用的第二个参数是一个布尔值，它告诉命令是否删除目标集合（如果存在）。该值默认为 false，这意味着不要丢弃目标，而是给出一个错误。这是一个合理的默认值，否则，如果我们不小心给出了一个存在的集合名称，并且不希望删除它，那么结果将非常糟糕。但是，如果您知道自己在做什么，并且希望在重命名集合时删除目标，请将第二个参数作为 true 传递。此参数的名称为`dropTarget`。在我们的情况下，电话应该是：

```
> db.sloppyNamedCollection.renameCollection('neatNamedCollection', true)

```

作为练习，再次尝试创建`sloppyNamedCollection`并在不使用第二个参数（或值为 false）的情况下重命名它。您应该看到 mongo 抱怨目标命名空间存在。然后，再次使用第二个参数 true 重命名，现在重命名操作成功执行。

请注意，重命名操作将在同一数据库中保留原始集合和新重命名的集合。此`renameCollection`方法不足以跨另一个数据库移动/重命名集合。在这种情况下，我们需要运行如下所示的`renameCollection`命令：

```
> db.runCommand({ renameCollection: "<source_namespace>", to: "<target_namespace>", dropTarget: <true|false> });

```

假设我们想将集合`sloppyNamedCollection`重命名为`neatNamedCollection`并将其从`test`数据库移动到`newDatabase`，我们可以执行以下命令。注意：使用的开关`dropTarget: true`用于删除现有目标集合（`newDatabase.neatNamedCollection`），如果它存在的话。

```
> db.runCommand({ renameCollection: "test.sloppyNamedCollection ", to: " newDatabase.neatNamedCollection", dropTarget: true });

```

此外，重命名集合操作不适用于分片集合。

# 查看收藏统计信息

当涉及到存储的使用、收集中的文档数量（可能用于估计未来空间）以及基于数据增长的内存需求时，出于管理目的的有趣统计数据中可能有一个是为了获得收集的高级统计数据。

## 准备好了吗

要找到集合的统计信息，我们需要一台服务器启动并运行，而单节点应该是可以的。有关如何启动服务器的信息，请参见[第 1 章](01.html "Chapter 1. Installing and Starting the Server")中的*安装单节点 MongoDB**安装和启动服务器*。我们将要操作的数据需要导入数据库。导入数据的步骤在[第 2 章](02.html "Chapter 2. Command-line Operations and Indexes")*命令行操作和索引*中的*创建测试数据*配方中给出。一旦这些步骤完成，我们都准备好继续这个食谱。

## 怎么做…

1.  我们将使用`postalCodes`集合来查看统计数据。
2.  打开 mongo shell 并连接到正在运行的 MongoDB 实例。如果您已在默认端口上启动 mongo，请执行以下操作：

    ```
    $ mongo

    ```

3.  导入数据后，如果不存在索引，则在`pincode`字段上创建索引：

    ```
    > db.postalCodes.ensureIndex({'pincode':1})

    ```

4.  在 mongo 终端上执行以下操作：

    ```
    > db.postalCodes.stats()

    ```

5.  观察输出并在外壳上执行以下操作：

    ```
    > db.postalCodes.stats(1024)

    ```

6.  再次观察输出。

我们现在将在下一节中看到打印出来的这些值对我们意味着什么。

## 它是如何工作的…

如果我们观察这两个命令的输出，就会发现第二个命令的所有数字都以 KB 为单位，而第一个命令的所有数字都以字节为单位。提供的参数称为比例，所有表示尺寸的数字都除以该比例。在本例中，由于我们给出的值为`1024`，因此我们得到的所有值都以 KB 为单位，而如果`1024 * 1024`被传递为 scale 的值（显示的大小将以 MB 为单位）。对于我们的分析，我们将使用以 KB 为单位显示大小的一个。

```
> db.postalCodes.stats(1024)
{
 "ns" : "test.postalCodes",
 "count" : 39732,
 "size" : 9312,
 "avgObjSize" : 240,
 "numExtents" : 6,
 "storageSize" : 10920,
 "lastExtentSize" : 8192,
 "paddingFactor" : 1,
 "paddingFactorNote" : "paddingFactor is unused and unmaintained in 3.0\. It remains hard coded to 1.0 for compatibility only.",
 "userFlags" : 1,
 "capped" : false,
 "nindexes" : 2,
 "totalIndexSize" : 2243,
 "indexSizes" : {
 "_id_" : 1261,
 "pincode_1" : 982
 },
 "ok" : 1
}

```

下表显示了重要字段的含义：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

领域

 | 

描述

 |
| --- | --- |
| `ns` | 集合的完全限定名，格式为`<database>.<collection name>`。 |
| `count` | 集合中的文档数。 |
| `size` | 集合中文档占用的实际存储大小。对集合中的文档进行添加、删除和更新可以更改此数字。比例参数影响此字段的值，在本例中，此值以 KB 为单位，因为`1024`是比例。此数字不包括填充（如果有）。 |
| `avgObjSize` | 这是集合中文档的平均大小。它只是大小字段除以集合中的文档数（前两个字段）。scale 参数影响该字段的值，在本例中，该值以 KB 为单位，因为`1024`是刻度。 |
| `storageSize` | Mongo 预先分配磁盘上的空间，以确保集合中的文档保持在连续位置，从而提供更好的磁盘访问性能。此预分配使用零填充文件，然后开始为这些插入的文档分配空间。此字段说明此集合使用的存储上的大小。这个数字通常会远远超过集合的实际大小。scale 参数影响该字段的值，在本例中，该值以 KB 为单位，因为`1024`是刻度。 |
| `numExtents` | 正如我们所看到的，mongo 为了提高性能，预先为集合分配了连续的磁盘空间。但是，随着集合的增长，需要分配新的空间。此字段给出此类连续块分配的数量。这个连续块称为区段。 |
| `nindexes` | 此字段提供集合上存在的索引数。即使我们没有在集合上创建索引，该值也将是`1`，因为 mongo 会在字段`_id`上隐式创建索引。 |
| `lastExtentSize` | 最后分配的扩展数据块的大小。scale 参数影响该字段的值，在本例中，该值以 KB 为单位，因为`1024`是刻度。 |
| `paddingFactor` | 自版本 3.0.0 以来，此参数已被弃用，出于向后兼容性原因，已硬编码为`1`。 |
| `totalIndexSize` | 索引也会占用存储空间。此字段给出磁盘上索引占用的总大小。scale 参数影响该字段的值，在本例中，该值以 KB 为单位，因为`1024`是刻度。 |
| `indexSizes` | 此字段是一个文档，其键作为索引的名称，值作为相关索引的大小。在我们的例子中，我们在`pincode`字段上显式地创建了一个索引；因此，我们将索引的名称视为键，将磁盘上索引的大小视为值。所有索引的这些值的总和与前面给出的值相同，`totalIndexSize`。scale 参数影响该字段的值，在本例中，该值以 KB 为单位，因为`1024`是刻度。 |

文件以连续位置放置在存储设备上。如果文档被更新，导致大小增加，Mongo 将不得不重新定位此文档。结果表明，此操作代价高昂，会影响此类更新操作的性能。从 Mongo3.0.0 开始，使用了两种数据分配策略。一个是*2*的幂，其中文档以 2 的幂分配空间（例如，32、64、128 等）。另一种是*无填充*，集合不希望更改文档大小。

## 另见

在本食谱中，我们讨论了查看集合的统计信息。请参阅下一个配方以查看数据库级别的统计信息。

# 查看数据库统计信息

在前面的配方中，我们看到了如何从管理角度查看集合的一些重要统计数据。在这个配方中，我们得到了更高的图片，在数据库级别获得了这些（或大部分）统计数据。

## 准备好了吗

为了找到数据库的统计信息，我们需要一个服务器启动并运行，一个节点就可以了。有关如何启动服务器的信息，请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*配方。我们将要操作的数据需要导入数据库。导入数据的步骤在[第 2 章](02.html "Chapter 2. Command-line Operations and Indexes")*命令行操作和索引*中的*创建测试数据*配方中给出。一旦这些步骤完成，我们都准备好继续这个食谱。如果您需要了解如何在集合级别查看统计信息，请参阅上一个配方。

## 怎么做…

1.  我们将使用`test`数据库来制作此配方。它已经有了`postalCodes`系列。
2.  通过从操作系统终端键入以下命令，使用 mongoshell 连接到服务器。假设服务器正在侦听端口`27017`。

    ```
    $ mongo

    ```

3.  在 shell 上执行以下命令并观察输出：

    ```
    > db.stats()

    ```

4.  在 shell 上，再次执行以下操作，但这次我们添加了 scale 参数。观察输出：

    ```
    > db.stats(1024)

    ```

## 它是如何工作的…

`scale`参数是`stats`函数的一个参数，它将字节数除以给定的刻度值。在本例中，它是`1024`，因此所有值都以 KB 为单位。我们分析以下输出：

```
> db.stats(1024)
{
 "db" : "test",
 "collections" : 3,
 "objects" : 39738,
 "avgObjSize" : 143.32699179626553,
 "dataSize" : 5562,
 "storageSize" : 16388,
 "numExtents" : 8,
 "indexes" : 2,
 "indexSize" : 2243,
 "fileSize" : 196608,
 "nsSizeMB" : 16,
"extentFreeList" : {
 "num" : 4,
 "totalSize" : 2696
 },
"dataFileVersion" : {
 "major" : 4,
 "minor" : 5
 },
 "ok" : 1 
}

```

以下表显示了重要字段的含义：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

领域

 | 

描述

 |
| --- | --- |
| `db` | 这是正在查看其统计信息的数据库的名称。 |
| `collections` | 这是数据库中集合的总数。 |
| `objects` | 这是数据库中所有集合中的文档数。如果我们使用`db.<collection>.stats()`找到一个集合的统计信息，我们将得到集合中文档的数量。此属性是数据库中所有集合的计数之和。 |
| `avgObjectSize` | 这只是数据库中所有集合中所有对象的字节大小除以所有集合中的文档数。该值不受提供的刻度的影响，尽管这是一个`size`字段。 |
| `dataSize` | 这是数据库中所有集合中保存的数据的总大小。此值受提供的刻度影响。 |
| `storageSize` | 这是分配给此数据库中用于存储文档的集合的总存储量。此值受提供的刻度影响。 |
| `numExtents` | 这是数据库中所有集合的所有扩展数据块数的计数。这基本上是此数据库中集合的集合统计信息中的扩展数据块（逻辑容器）数。 |
| `indexes` | 这是数据库中所有集合的索引数之和 |
| `indexSize` | 这是数据库中所有集合的所有索引的大小（以字节为单位）。此值受提供的刻度影响。 |
| `fileSize` | 这是您应该在该数据库的文件系统上找到的所有数据库文件大小的总和。对于测试数据库，这些文件将被命名为`test.0`、`test.1`等等。此值受提供的刻度影响。 |
| `nsSizeMB` | 这是数据库的`.ns`文件的文件大小（MB）。 |
| `extentFreeList.num` | 这是自由列表中的自由扩展数。您可以将区段视为 MongoDB 的内部数据结构。 |
| `extentFreeList.totalSize` | 自由列表上范围的大小。 |

关于这些方面的更多信息，您可以参考*Packt Publishing*（[出版的*Instant MongoDB*等书籍 http://www.packtpub.com/big-data-and-business-inteliigence/instant-mongodb-instant](http://www.packtpub.com/big-data-and-business-inteliigence/instant-mongodb-instant) ）。

## 它是如何工作的…

让我们从开始，看看`collections`字段。如果仔细查看数字并在 mongo shell 上执行 show collections 命令，您会发现统计数据中有一个额外的集合，与执行该命令的集合相比。不同之处在于一个集合是隐藏的。它的名字是`system.namespaces`收藏。您可以通过`db.system.namespaces.find()`查看其内容。

回到数据库上 stats 操作的输出，结果中的 objects 字段也有一个有趣的值。如果我们找到`postalCodes`集合中的文档计数，我们会看到它是`39732`。这里显示的计数是`39738`，这意味着还有六份文件。这六份文件来自`system.namespaces`和`system.indexes`收藏。对这两个集合执行计数查询将对其进行确认。请注意，`test`数据库不包含除`postalCodes`之外的任何其他集合。如果数据库中包含更多包含文档的集合，则这些数字将发生变化。

另一个需要注意的是`avgObjectSize`的值，这个值有点奇怪。与集合统计中的这个字段不同，集合统计中的这个字段受所提供的比例值的影响，而在数据库统计中，这个值总是以字节为单位。这是相当令人困惑的，我不确定为什么不按照提供的比例进行缩放。

# 手工填充文档

MongoDB 使用内存映射文件，这意味着数据存储在文件中的方式与内存中的方式完全相同，它将使用低级操作系统服务将这些页面映射到内存。文档存储在 mongo 数据文件中的连续位置，当文档增长且不再适合空间时，问题就会出现。在这种情况下，mongo 会在收集结束时使用更新的数据重写文档，并清理文档最初放置的空间（请注意，此空间不会作为可用空间释放给操作系统）。

对于那些不希望文档大小增长的应用程序来说，这不是一个大问题。然而，对于那些预见到文档大小在一段时间内会增长的人来说，这是一个巨大的性能打击，并且可能会有很多这样的文档移动。随着 MongoDB 3.0 的发布，2 方法的*幂成为默认的大小分配策略。顾名思义，此方法将文档存储在以 2 的幂分配的空间中。这为文档提供了额外的填充，并更好地重用由于文档的重新定位或删除而产生的可用空间。*

也就是说，如果您仍然希望在策略中引入手动填充，请继续阅读。

## 准备好了吗

这个配方不需要任何东西，除非您计划尝试这个简单的技术，在这种情况下，您需要一个实例来启动和运行。有关如何启动服务器的信息，请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*配方。

## 怎么做…

这种技术的思想是向要插入的文档中添加一些虚拟数据。除了文档中的其他数据外，该虚拟数据的大小与文档的预期大小大致相同。

例如，如果一段时间内文档的平均大小估计约为 1200 字节，并且插入文档时文档中存在 300 字节的数据，则我们将添加一个大小约为 900 字节的虚拟字段，以便总文档大小总计为 1200 字节。

插入文档后，我们将取消设置此虚拟字段，这会在两个连续文档之间的文件中留下一个洞。当文档在一段时间内增长时，将使用此空白空间，以最小化文档移动。空白处也可能被其他文档使用。更简单的方法是仅在使用空间时移除填充物。但是，任何超过预期平均增长的文档都必须由服务器复制到集合的末尾。不用说，文档没有增长到预期大小会浪费磁盘空间。

应用程序可以提出一些智能策略，根据文档的某个特定字段来调整填充字段的大小，以解决这些缺点，但这取决于应用程序开发人员。

现在让我们看一下这种方法的一个示例：

1.  We define a small function that will add a field called `padField` with an array of string values to the document. Its code is as follows:

    ```
    function padDocument(doc) {
      doc.padField = []
      for(i = 0 ; i < 20 ; i++) {
        doc.padField[i] = 'Dummy'
      }
    }
    ```

    它将添加一个名为`padField`的数组，并将一个名为`Dummy`的字符串添加 20 倍。对添加到文档中的类型和添加次数没有任何限制，只要它占用了所需的空间。前面的代码只是一个示例。

2.  下一步是插入文档。我们将定义另一个名为`insert`的函数来实现这一点：

    ```
    function insert(collection, doc) {
       //1\. Pad the document with the padField
      padDocument(doc);
       //2\. Create or store the _id field that would be used later
      if(typeof(doc._id) == 'undefined') {
        _id = ObjectId()
        doc._id = _id
      }
      else {
        _id = doc._id
      }
       //3\. Insert the document with the padded field
      collection.insert(doc)
    //4\. Remove the padded field, use the saved _id to find the document to be updated.
    collection.update({'_id':_id}, {$unset:{'padField':1}})
    }
    ```

3.  我们现在将在集合`testCol`中插入一个文档，如下所示：

    ```
    insert(db.testCol, {i:1})
    ```

4.  您可以使用以下查询查询`testCol`并检查插入的单据是否存在：

    ```
    > db.testCol.findOne({i:1})

    ```

请注意，在查询中，您不会在其中找到`padField`。但是，即使字段未设置，数组所占用的空间仍保留在随后插入的文档之间。

## 它是如何工作的…

`insert`函数是不言自明的，其中包含注释以说明其功能。一个明显的问题是，如果这确实是我们想要做的，我们如何相信。为此，我们将进行如下小活动。为此，我们将制作一个`manualPadTest`系列。在 mongo shell 中，执行以下操作：

```
> db.manualPadTest.drop()
> db.manualPadTest.insert({i:1})
> db.manualPadTest.insert({i:2})
> db.manualPadTest.stats()

```

记下统计中的`avgObjSize`字段。接下来，从 mongo shell 执行以下操作：

```
> db.manualPadTest.drop()
> insert(db.manualPadTest , {i:1})
> insert(db.manualPadTest , {i:2})
> db.manualPadTest.stats()

```

记下统计中的`avgObjSize`字段。这个数字比我们之前看到的没有填充的常规插入要大得多。我们在这两种情况下看到的`paddingFactor`仍然是一个，但后一种情况有更多的缓冲区供文档增长。

我们在这个配方中使用的`insert`函数的一个缺陷是，插入集合和更新文档操作不是原子操作。

# mongostat 和 mongotop 公用事业公司

大多数人可能会发现这些名称类似于两个流行的 Unix命令`iostat`和`top`。对于 MongoDB，`mongostat`和`mongotop`是两个实用程序，它们的工作与这两个 Unix 命令几乎相同，猜测它们用于监视 mongo 实例是没有好处的。

## 准备好了吗

在这个方法中，我们将通过运行一个脚本来模拟独立 mongo 实例上的一些操作，该脚本将试图让您的服务器保持忙碌，然后在另一个终端中，我们将运行这些实用程序来监视`db`实例。

您需要启动一个独立服务器，监听客户端连接的任何端口；在这种情况下，我们将坚持默认的`27017`。如果您不知道如何启动独立服务器，请参阅[第一章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*。我们还需要从 Packt 站点下载脚本`KeepServerBusy.js`，并将其保存在本地驱动器上方便地执行。此外，假定 mongo 安装的`bin`目录存在于操作系统的 path 变量中。如果没有，则需要使用 shell 中可执行文件的绝对路径执行这些命令。这两个公用设施`mongostat`和`mongotop`是 mongo 安装的标准配置。

## 怎么做…

1.  启动MongoDB 服务器，让它监听默认端口进行连接。
2.  在单独的终端中，执行提供的 JavaScript`KeepServerBusy.js`如下：

    ```
    $ mongo KeepServerBusy.js –quiet

    ```

3.  打开一个新的操作系统终端，执行以下命令：

    ```
    $ mongostat

    ```

4.  捕获输出内容一段时间，然后点击*Ctrl*+*C*停止命令捕获更多统计信息。保持终端打开或将统计数据复制到另一个文件。
5.  现在，从终端执行以下命令：

    ```
    $ mongotop

    ```

6.  捕获输出内容一段时间，然后点击*Ctrl*+*C*停止命令捕获更多统计信息。保持终端打开或将统计数据复制到另一个文件。
7.  在执行提供的 JavaScript`KeepServerBusy.js`的 shell 中点击*Ctrl*+*C*，停止让服务器忙碌的操作。

## 它是如何工作的…

让我们看看我们从这两个实用程序中获得了什么。

我们从分析`mongostat`开始。在我的笔记本电脑上，使用`mongostat`进行的捕获如下所示：

```
mongostat
connected to: 127.0.0.1
insert query update delete getmore command flushes mapped vsize   res faults idx miss % qr|qw ar|aw netIn netOut conn     time
 1000     1    950   1000       1     1|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|1  431k   238k    2 08:59:21
 1000     1   1159   1000       1     1|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|0  468k   252k    2 08:59:22
 1000     1    984   1000       1     1|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|1  437k   240k    2 08:59:23
 1000     1   1066   1000       1     1|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|1  452k   246k    2 08:59:24
 1000     1    944   1000       1     2|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|1  431k   237k    2 08:59:25
 1000     1   1149   1000       1     1|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|1  466k   252k    2 08:59:26
 1000     2   1015   1053       2     1|0       0 624.0M  1.4G 50.0M      0          0   0|0   0|0  450k   293k    2 08:59:27

```

您可以选择查看脚本`KeepServerBusy.js`是如何让服务器保持忙碌的。它所做的只是在集合`monitoringTest`中插入 1000 个文档，然后逐个更新，在其中设置一个新的密钥，执行查找并遍历所有文档，最后逐个删除，基本上是一个写密集型操作。

内容包装的输出看起来确实很难看，但是让我们逐个分析字段，看看需要关注哪些字段。

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

专栏

 | 

描述

 |
| --- | --- |
| `insert`、`query`、`update`、`delete` | 前四列为每秒`insert`、`query`、`update`和`delete`操作数。它是每秒，因为捕捉这些数字的时间间隔为 1 秒，由最后一列指示。 |
| `getmore` | 当光标用完查询数据时，它会在服务器上执行一个`getmore`操作，以获得之前执行的查询的更多结果。此列显示在 1 秒的给定时间范围内执行的`getmore`操作数。在我们的例子中，执行的`getmore`操作并不多。 |
| `commands` | 这是在给定的 1 秒时间范围内在服务器上执行的命令数。在我们的例子中，它并不多，而且只是一个。在我们的例子中，`&#124;`后面的数字是`0`，因为这是在独立模式下。尝试执行`mongostat`连接到副本集主副本集和次副本集。你应该会看到稍微不同的数字。 |
| `flushes` | 这是在 1 秒间隔内将数据刷新到磁盘的次数。（`MMAPv1`存储引擎时为`fsync`，`WiredTiger`存储引擎时为轮询间隔间触发的检查点） |
| `mapped`、`virtual`和`resident memory` | Mappedmemory 是 Mongo 进程映射到数据库的内存量。这通常与数据库的大小相同。另一方面，虚拟内存是分配给整个`mongod`进程的内存。这将是映射内存大小的两倍以上，尤其是启用日志记录时。最后，驻留内存是 mongo 实际使用的物理内存。所有这些数字都以 MB 为单位。物理内存的总量可能比 Mongo 使用的内存要多得多，但除非发生大量页面错误（在前面提到的输出中确实发生了），否则这并不重要。 |
| `faults` | 这些是每秒发生的页面错误数。这些数字应该尽可能少。它表示 mongo 必须转到磁盘以获取主内存中缺少的文档/索引的次数。当使用 SSD 进行持久性存储时，这个问题不像使用旋转磁盘驱动器时那么严重。 |
| `locked` | 自版本 2.2 以来，对集合的所有写入操作都会锁定集合所在的数据库，并且不会获取全局级别的锁。此字段显示给定时间间隔内大部分时间被锁定的数据库。在我们的例子中，`test`数据库大部分时间是锁定的。 |
| `idx miss %` | 此字段给出特定索引需要且不存在于内存中的次数。这会导致页面错误，需要访问磁盘才能获取索引。可能还需要另一次磁盘访问才能获取文档。这个数字也应该很低。高比例的索引未命中是需要注意的问题。 |
| `qr``qw` | 这些是排队等待执行的读写操作。如果这个数字上升，则表明数据库正被读写量压得喘不过气来。如果值太高，请密切关注页面错误和数据库锁定百分比，以便更深入地了解增加的队列计数。如果数据集太大，则对集合进行分片可以显著提高性能。 |
| `ar``aw` | 这是活动读卡器和写卡器（客户端）的数量。就我们之前看到的其他统计数据而言，即使是大量数据也不必担心。 |
| `netIn`和`netOut` | 给定时间范围内进出 mongo 服务器的网络流量。数字以位为单位。例如，271k 表示 271 千位。 |
| `conn` | 这表示打开的连接数。一些可以监视的东西，看看它是否会继续升高。 |
| `time` | 这是捕获此样本的时间间隔。 |

如果`mongostat`连接到副本集 primary 或 secondary，则会看到更多字段。作为分配，一旦收集到 stats 或独立实例，启动副本集服务器并执行相同的脚本以保持服务器繁忙。使用`mongostat`连接主实例和次实例，查看捕获的不同统计信息。

除了`mongostat`之外，我们还使用`mongotop`实用程序来捕获统计数据。让我们看看它的输出并从中了解一些道理：

```
$>mongotop
connected to: 127.0.0.1
 ns           total          read         write
2014-01-15T17:55:13
 test.monitoringTest         899ms           1ms         898ms
 test.system.users             0ms           0ms           0ms
 test.system.namespaces           0ms           0ms           0ms
 test.system.js             0ms           0ms           0ms
 test.system.indexes           0ms           0ms           0ms

 ns           total          read         write
2014-01-15T17:55:14
 test.monitoringTest         959ms           0ms         959ms
 test.system.users             0ms           0ms           0ms
 test.system.namespaces           0ms           0ms           0ms
 test.system.js             0ms           0ms           0ms
 test.system.indexes           0ms           0ms           0ms
 ns           total          read         write
2014-01-15T17:55:15
 test.monitoringTest         954ms           1ms         953ms
 test.system.users             0ms           0ms           0ms
 test.system.namespaces           0ms           0ms           0ms
 test.system.js             0ms           0ms           0ms
 test.system.indexes           0ms           0ms           0ms

```

在这个统计数据中没有什么可看的。我们可以看到数据库在给定的 1 秒时间段内忙于读取或写入数据的总时间。总计中给出的值是读写时间之和。如果我们实际比较同一时间片的`mongotop`和`mongostat`，则写入发生的持续时间百分比将非常接近`mongostat`输出中数据库被锁定的百分比时间中给出的数字。

命令`mongotop`接受命令行上的一个参数，如下所示：

```
$ mongotop 5

```

在这种情况下，打印统计数据的时间间隔为 5 秒，而默认值为 1 秒。

### 注

从 MongoDB 3.0 开始，`mongotop`和`mongostat`实用程序都允许使用`--json`选项以 JSON 格式输出。如果要使用依赖于这些实用程序的自定义监视或度量集合脚本，这将非常有用。

## 另见

*   在*获取当前执行操作并杀死它们*的配方中，我们将看到如何从 shell 获取当前执行操作，并在需要时杀死它们
*   在*使用 profiler 评测操作*的配方中，我们将看到如何使用 Mongo 内置的评测功能来记录操作执行时间。

# 获取当前正在执行的操作并杀死它们

在这个配方中，我们将看到如何查看当前正在运行的操作，并终止一些长时间运行的操作。

## 准备好了吗

我们将在一个独立的 mongo 实例上模拟一些操作。我们需要启动一个独立的服务器，监听客户端连接的任何端口；在这种情况下，我们将坚持默认的`27017`。如果您不知道如何启动独立服务器，请参阅[第一章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*。我们还需要启动两个连接到服务器的 shell。一个 shell 用于创建后台索引，另一个 shell 用于监视当前操作，然后将其终止。

## 怎么做…

1.  我们将无法在测试环境中模拟实际的长时间运行操作。我们将尝试创建一个索引，并希望它需要很长时间才能创建。根据您的目标硬件配置，操作可能需要一些时间。
2.  To start with this test, let's execute the following on the mongo shell:

    ```
    > db.currentOpTest.drop()
    > for(i = 1 ; i < 10000000 ; i++) { db.currentOpTest.insert({'i':i})}

    ```

    前面的插入可能需要一些时间才能插入 1000 万个文档。

3.  一旦插入文档，我们将执行一个在后台创建索引的操作。如果您想了解更多关于索引创建的信息，请参考[第 2 章](02.html "Chapter 2. Command-line Operations and Indexes")*命令行操作和索引*中的*在 shell*中创建背景和前景索引的方法，但这不是该方法的先决条件。
4.  在文档中的字段`i`上创建背景索引。这个索引创建操作是我们将从`currentOp`操作中看到的，也是我们将使用 kill 操作试图杀死的。在一个 shell 中执行以下命令以启动后台索引创建操作。这需要相当长的时间，在我的笔记本电脑上花了超过 100 秒。

    ```
    > db.currentOpTest.ensureIndex({i:1}, {background:1})

    ```

5.  在第二个 shell 中，执行以下命令以获取当前正在执行的操作：

    ```
    > db.currentOp().inprog

    ```

6.  记下操作的进度，并找到创建索引所需的操作。在我们的例子中，这是测试机器上唯一正在进行的测试。它将是`system.indexes`上的一个操作，该操作将被插入。输出文档中要查找的键分别为`ns`和`op`。我们需要注意此操作的第一个字段，`opid`。本例中为`11587458`。下一节将给出该命令的示例输出。
7.  使用前面得到的`opid`（操作 ID）使用以下命令从 shell 中终止操作：

    ```
    > db.killOp(11587458)

    ```

## 它是如何工作的…

我们将把解释分为两部分，第一部分是关于当前操作的细节，第二部分是关于终止操作。

在我们的例子中，索引创建过程是我们打算终止的长时间运行的操作。我们创建了一个包含 1000 万文档的大型集合，并启动了后台索引创建过程。

在执行`db.currentOp()`操作时，我们得到一个文档作为结果，其字段`inprog`的值是一个其他文档的数组，每个文档表示当前正在运行的操作。在繁忙的系统上获取大量文档是很常见的。以下是为索引创建操作获取的文档：

```
{
        "desc" : "conn12",
        "threadId" : "0x3be96c0",
        "connectionId" : 12,
        "opid" : 3212789,
        "active" : true,
        "secs_running" : 1,
        "microsecs_running" : NumberLong(729029),
        "op" : "query",
        "ns" : "test.$cmd",
        "query" : {
            "createIndexes" : "currentOpTest",
            "indexes" : [
                {
                    "key" : {
                        "i" : 1
                    },
                    "name" : "i_1",
                    "background" : 1
                }
            ]
        },
        "client" : "127.0.0.1:36542",
        "msg" : "Index Build (background) Index Build (background): 384120/1000000 38%",
        "progress" : {
            "done" : 384120,
            "total" : 1000000
        },
        "numYields" : 3003,
        "locks" : {
            "Global" : "w",
            "MMAPV1Journal" : "w",
            "Database" : "w",
            "Collection" : "W"
  "waitingForLock" : true,
        "lockStats" : {
            "Global" : {
                "acquireCount" : {
                    "w" : NumberLong(3004)
                }
            },
            "MMAPV1Journal" : {
                "acquireCount" : {
                    "w" : NumberLong(387127)
                },
                "acquireWaitCount" : {
                    "w" : NumberLong(9)
                },
                "timeAcquiringMicros" : {
                    "w" : NumberLong(60025)
                }
            },
            "Database" : {
                "acquireCount" : {
                    "w" : NumberLong(3004),
                    "W" : NumberLong(1)
                }
            },
            "Collection" : {
                "acquireCount" : {
                    "W" : NumberLong(3004)
                },
                "acquireWaitCount" : {
                    "W" : NumberLong(1)
                },
                "timeAcquiringMicros" : {
                    "W" : NumberLong(66)
                }
            },
            "Metadata" : {
                "acquireCount" : {
                    "W" : NumberLong(4)
                }
            }
        }
    }
```

我们将在下表中看到这些字段的含义：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

领域

 | 

描述

 |
| --- | --- |
| `opid` | 这是标识操作的唯一操作 ID。这是用于终止操作的 ID。 |
| `active` | 指示操作是否已启动的布尔值，只有在等待获取锁以执行操作时才为 false。该值一旦启动即为真，即使在已产生锁且未执行的时间点也是如此。 |
| `secs_running` | 以秒为单位给出操作正在执行的时间。 |
| `op` | 这是操作的类型。在创建索引的情况下，它被插入到索引的系统集合中。可能的值为`insert`、`query`、`getmore`、`update`、`remove`和`command`。 |
| `ns` | 这是目标的完全限定命名空间。它将以`<database name>.<collection name>`的形式出现。 |
| `insert` | 这是将插入到集合中的文档。 |
| `query` | 这是一个字段，除了`insert`、`getmore`和`command`之外，其他操作都会出现该字段。 |
| `client` | 启动操作的客户端的 ip 地址/主机名和端口。 |
| `desc` | 这是对客户端的描述，主要是客户端连接名称。 |
| `connectionId` | 这是发起请求的客户端连接的标识符。 |
| `locks` | 这是一个包含此操作的锁的文档。该文档显示了为所分析的操作而持有的锁的类型和模式。可能的模式如下：**R**表示共享（S）锁。**W**表示独占（X）锁。**r**表示意向共享（IS）锁。**w**表示意向独占（IX）锁。 |
| `waitingForLock` | 此字段指示操作是否正在等待获取锁。例如，如果前面的索引创建不是后台进程，则此数据库上的其他操作将排队等待获取锁。这些操作的此标志将为真。 |
| `msg` | 这是用于操作的人类可读消息。在本例中，我们确实看到了操作完成的百分比，因为这是一个索引创建操作。 |
| `progress` | 操作的状态，total 表示集合中的文档总数，done 表示到目前为止索引的文档数。在本例中，集合中已有超过 1000 万个文档。完成百分比是根据这些数字计算的。 |
| `numYields` | 这是进程产生锁以允许执行其他操作的次数。因为这是后台索引创建过程，所以随着服务器频繁地让其他操作执行，这个数字将继续增加。如果它是一个前台进程，在操作完成之前，锁永远不会被释放。 |
| `lockStats` | 此文档有更多嵌套文档，提供此操作持有读或写锁的总时间以及等待获取锁的时间的统计信息。 |

### 注

如果您有一个副本集，那么将有更多的 getmore 操作从辅助操作转到主操作。

1.  要查看正在执行的系统操作，我们需要将一个真值作为参数传递给`currentOp`函数调用，如下所示：

    ```
    > db.currentOp(true)

    ```

2.  Next, we will see how to kill the user initiated operation using the `killOp` function. The operation is simply called as follows:

    ```
    > db.killOp(<operation id>)

    ```

    在我们的例子中，索引创建进程的进程 ID 为 11587458，因此它将被终止，如下所示：

    ```
    > db.killOp(11587458)

    ```

    在终止任何操作时，无论给定的操作 ID 是否存在，我们都会在控制台上看到如下消息：

    ```
    { "info" : "attempting to kill op" }

    ```

    因此，看到此消息并不意味着操作被终止。这只意味着将尝试终止该操作（如果存在）。

3.  如果某个操作不能立即终止，并且为其发出了`killOp`命令，`currentOp`中的字段`killPending`将开始显示给定操作。例如，在 shell 上执行以下查询：

    ```
    > db.currentOpTest.find({$where:'sleep(100000)'})

    ```

这不会返回，执行查询的线程将休眠 100 秒。这是一个无法使用`killOp`终止的操作。尝试从另一个 shell 执行命令`currentOp`（不要按*Tab*自动完成，您的 shell 可能会挂起），获取操作 ID，然后使用`killOp`将其杀死。您应该看到，如果执行`currentOp`命令，进程仍将运行，但进程详细信息文档现在将包含一个新的键`killPending`，说明此操作的 kill 已被请求，但仍处于挂起状态。

# 使用探查器对操作进行探查

在本配方中，我们将介绍 mongo 的内置探查器，该探查器将用于分析 mongo 服务器上执行的操作。它是一个用于记录所有或慢速操作的实用程序，可用于分析服务器的性能。

## 准备好了吗

在这个配方中，我们将在一个独立的 mongo 实例上执行一些操作并分析它们。我们需要启动一个独立的服务器，监听客户端连接的任何端口；在这种情况下，我们将坚持默认的`27017`。如果您不知道如何启动独立服务器，请参阅[第一章](01.html "Chapter 1. Installing and Starting the Server")中的*安装单节点 MongoDB*、*安装和启动服务器*。我们还需要启动一个 shell，用于执行查询、启用分析和查看分析操作。

## 怎么做…

1.  一旦服务器启动并且 shell 连接到服务器，执行以下操作以获取当前的分析级别：

    ```
    > db.getProfilingLevel()

    ```

2.  默认级别应为`0`（如果我们之前没有设置，则不进行分析）。
3.  让我们将分析级别设置为`1`（仅记录慢速操作），并记录所有低于`50`ms 的操作。在 shell 上执行以下操作：

    ```
    > db.setProfilingLevel(1, 50)

    ```

4.  现在，让我们对集合执行一个插入操作，然后执行两个查询：

    ```
    > db.profilingTest.insert({i:1})
    > db.profilingTest.find()
    > db.profilingTest.find({$where:'sleep(70)'})

    ```

5.  现在，对以下集合执行查询：

    ```
    > db.system.profile.find().pretty()

    ```

## 它是如何工作的…

分析是默认情况下不会启用的功能。如果您对数据库的性能感到满意，那么没有理由启用探查器。只有当一个人觉得有一些改进的空间，并且想要针对正在进行的一些昂贵的操作时，才会这样做。一个重要的问题是什么将一项操作归类为缓慢？答案是，它取决于不同的应用程序。在 mongo 中，slow 表示超过 100 ms 的任何操作。但是，在设置分析级别时，您可以选择阈值。

分析级别有三个可能的值：

*   `0`：禁用配置文件
*   `1`：为慢速操作启用评测，其中在设置评测级别的同时，调用中提供了要归类为慢速的操作的阈值
*   `2`：配置所有操作

虽然分析所有操作可能不是一个很好的主意，也可能不像我们很快就会看到的那样被广泛使用，但将值设置为`1`并为其提供阈值是监视缓慢操作的一个好方法。

如果我们看一下我们执行的步骤，就会发现我们可以通过执行操作`db.getProfilingLevel()`来获得当前的分析级别。为了获得更多信息，例如，慢操作的阈值是多少，我们可以使用`db.getProfilingStatus()`。这将返回一个具有分析级别和慢速操作阈值的文档。

为了设置评测级别，我们调用`db.setProfilingLevel()`方法。在我们的例子中，我们将其设置为将超过`50`ms 的所有操作记录为`db.setProfilingLevel(1, 50)`。

要禁用评测，只需执行`db.setProfilingLevel(0)`。

接下来，我们执行了三个操作，一个是插入文档，一个是查找所有文档，最后一个是调用 sleep 的 find，其值为`70`ms，以降低速度。

最后一步是查看记录在`system.profile`集合中的这些配置文件操作。我们执行查找以查看记录的操作。对于我的执行，记录了插入和最后一次带有睡眠的`find`操作。

显然，这种分析有一些开销，但可以忽略不计。因此，默认情况下，我们不会启用它，但仅当我们想要评测慢速操作时才启用它。另外，另一个问题是，*在一段时间内，这种分析收集会增加吗？*答案是*否*，因为这是一个上限集合。Capped 集合是固定大小的集合，它保留插入顺序，并充当填充新文档的循环队列，当最旧的文档满时丢弃。对`system.namespaces`的查询应显示统计信息。对于`system.profile`集合，查询执行将显示以下内容：

```
{"name":"test.system.profile", "options":{"capped":true, "size":1048576 }}

```

正如我们所看到的，集合的大小是 1MB，这是难以置信的小。因此，将分析级别设置为`2`将很容易覆盖繁忙系统上的数据。还可以选择显式创建一个名为`system.profile`的集合作为上限集合，如果选择在其中保留更多操作，则可以选择任意大小的集合。要显式创建封顶集合，可以执行以下操作：

```
db.createCollection('system.profile', {capped:1, size: 1048576})

```

显然，选择的大小是任意的，您可以根据数据填充的频率以及在覆盖之前要保留的分析数据的数量，自由地为此集合分配任何大小。

由于这是一个有上限的集合，并且保留了插入顺序，所以使用`sort order {$natural:-1}`的查询将非常好，并且非常有效地以与执行时间相反的顺序查找操作。

最后，我们将查看插入到`system.profile`集合中的文档，并查看它记录的所有操作：

```
{
        "op" : "query",
        "ns" : "test.profilingTest",
        "query" : {
                "$where" : "sleep(70)"
        },
        "ntoreturn" : 0,
        "ntoskip" : 0,
        "nscanned" : 1,
        "keyUpdates" : 0,
        "numYield" : 0,
        "lockStats" : {
                …<<<<snip>>>
       },
        "nreturned" : 0,
        "responseLength" : 20,
        "millis" : 188,
        "ts" : ISODate("2014-01-27T17:37:02.482Z"),
        "client" : "127.0.0.1",
        "allUsers" : [ ],
        "user" : ""
}
```

正如我们在文档中看到的，确实有一些有趣的统计数据。让我们看看下表中的一些。其中一些字段与我们在 shell 中执行`db.currentOp()`操作时看到的字段相同，我们在前面的配方中讨论了这些字段。

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

领域

 | 

描述

 |
| --- | --- |
| `op` | 这是执行的操作；在本例中，它是一个查找，因此在本例中是查询。 |
| `ns` | 这是对其执行操作的集合的完全限定名。其格式为`<database>.<collection name>`。 |
| `query` | 它显示在服务器上执行的查询。 |
| `nscanned` | 这与解释该计划具有类似的含义。它是扫描的文档和索引项的总数。 |
| `numYields` | 这是执行操作时产生锁的次数。较高的收益率可能表明查询需要大量的磁盘访问。这可能是重新查看索引或优化查询本身的良好指示。 |
| `lockStats` | 获取锁所用的时间和持有锁的时间的一些有趣的统计信息。 |
| `nreturned` | 返回的文档的数量。 |
| `responseLength` | 响应的长度（以字节为单位）。 |
| `millis` | 最重要的是，执行操作所用的时间（以毫秒为单位）。这可能是捕获慢速查询的良好起点。 |
| `ts` | 这是执行操作的时间。 |
| `client` | 这是执行操作的客户端的主机名/IP 地址。 |

# 在 Mongo 中设置用户

安全性是任何企业级系统的基石之一。并非您总能在一个完全安全的环境中找到一个允许未经验证的用户访问的系统。除了测试环境外，几乎每个生产环境都需要适当的访问权限，也许还需要对系统访问进行审核。Mongo 安全有多个方面：

*   访问系统的最终用户的访问权限。将有多个角色，如管理员、只读用户和读写非管理用户。
*   对添加到副本集中的节点进行身份验证。在副本集中，只允许添加经过身份验证的系统。如果将任何未经验证的节点添加到副本集中，系统的完整性将受到损害。
*   加密通过复制集节点之间甚至客户端和服务器之间的线路传输的数据（如果是分片设置，则加密 mongos 进程）。

在这个和下一个配方中，我们将看到如何解决这里给出的第一点和第二点。默认情况下，mongo 社区版不支持加密正在传输的数据的第三点，需要在启用`ssl`选项的情况下重建 mongo 数据库。

## 准备好了吗

在此配方中，我们将为独立的 mongo 实例设置用户。我们需要启动一个独立的服务器，监听客户端连接的任何端口；在这种情况下，我们将坚持默认的`27017`。如果您不知道如何启动独立服务器，请参阅[第一章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*。我们还需要启动一个用于此管理操作的 shell。对于副本集，我们将只连接到主服务器并执行这些操作。

## 怎么做…

我们将在此配方中添加一个管理员用户、一个测试数据库的只读用户和一个测试数据库的读写用户。

假设此时：

*   服务器已启动并正在运行，我们已从 shell 连接到服务器。
*   除了在[第 1 章](01.html "Chapter 1. Installing and Starting the Server")、*安装和启动服务器*中提到的参数外，服务器启动时没有任何特殊的命令行参数，以便*使用命令行选项*配方启动单节点实例。因此，任何用户都可以完全访问服务器。

执行以下步骤：

1.  我们要做的第一步是创建一个管理员用户。所有命令都假定您使用的是 MongoDB 3.0 及更高版本。
2.  首先，我们首先在 admin 数据库中创建 admin 用户，如下所示：

    ```
    > use admin
    > db.createUser({
     user:'admin', pwd:'admin',
     customData:{desc:'The admin user for admin db'},
     roles:['readWrite', 'dbAdmin', 'clusterAdmin']
     })

    ```

3.  我们将添加`read_user`和`write_user`到测试数据库中。要添加用户，请从 mongo shell 执行以下操作：

    ```
    > use test
    > db.createUser({
     user:'read_user', pwd:'read_user',
     customData:{desc:'The read only user for test database'},
     roles:['read']
     }
    )
    > db.createUser({
     user:'write_user', pwd:'write_user',
     customData:{desc:'The read write user for test database'}, 
     roles:['readWrite']
     }
    )

    ```

4.  Now shut down the mongo server and the close the shell too. Restart the mongo server but with the `--auth` option on the command line:

    ```
    $ mongod .. <other options as provided earlier> --auth

    ```

    如果您的 mongod 实例正在使用`/etc/mongod.conf`，则在配置文件中添加行`auth = true`并重新启动 mongod 服务。

5.  现在从新打开的 mongo shell 连接到服务器并执行以下操作：

    ```
    > db.testAuth.find()

    ```

6.  集合`testAuth`不需要存在，但您应该看到一个错误，即我们无权查询集合。
7.  我们现在将使用一个`read_user`从 shell 登录，如下所示：

    ```
    > db.auth('read_user', 'read_user')

    ```

8.  我们现在将执行如下相同的`find`操作。它不应该给出错误，并且可能不会返回任何结果，这取决于集合是否存在：

    ```
    > db.testAuth.find()

    ```

9.  现在，我们将尝试插入一个文档，如下所示。我们应该得到一个错误，您无权在此集合中插入数据。

    ```
    > db.testAuth.insert({i:1})

    ```

10.  现在，我们将注销并再次登录，但使用一个 write 用户，如下所示。请注意这次登录方式与前一个实例的不同。我们提供了一个文档作为`auth`函数的参数，与前面的情况一样，我们传递了两个用户名和密码参数：

    ```
    > db.logout()
    > db.auth({user:'write_user', pwd:'write_user'})
    Now to execute the insert again as follows, this time around it should work
    > db.testAuth.insert({i:1})

    ```

11.  现在，在 shell 上执行以下操作。您应该获取未经授权的错误：

    ```
    > db.serverStatus()

    ```

12.  我们现在切换到`admin`数据库。我们目前使用对`test`数据库具有读写权限的`write_user`连接到服务器。在 mongo shell 中，尝试执行以下操作：

    ```
    > use admin
    > show collections

    ```

13.  关闭 mongo 外壳或从操作系统控制台打开新外壳，如下所示。这将直接带我们到管理员数据库：

    ```
    $ mongo -u admin -p admin admin

    ```

14.  现在在 shell 上执行以下操作。它应该向我们显示管理数据库中的集合：

    ```
    > show collections

    ```

15.  尝试并执行以下操作：

    ```
    > db.serverStatus()

    ```

## 它是如何工作的…

我们执行了很多步骤，现在我们将仔细研究它们。

最初，服务器启动时没有`--auth`选项，因此默认情况下不强制执行安全性。我们使用`db.createUser`方法创建一个管理员用户。创建用户的方法的签名为`createUser(user, writeConcern)`。第一个参数是用户，它实际上是一个 JSON 文档，第二个参数是用于用户创建的写关注点。用户的 JSON 文档具有以下格式：

```
{
  'user' : <user name>,
  'pwd' : <password>,
  'customData': {<JSON document providing any user specific data>}
  'roles':[<roles of the user>]
}
```

这里提供的角色可以如下提供，假设创建用户时的当前数据库是在 shell 上测试的：

```
[{'role' : 'read',  'db':'reports'}, 'readWrite']

```

这使得被创建的用户可以读取报告`db`和`readWrite`访问`test`数据库。让我们看看`test`用户的完整用户创建调用：

```
> use test
> db.createUser({
 user:'test', pwd:'test',
 customData:{desc:'read access on reports and readWrite access on test'},
 roles:[
 {role:'read', db : 'reports'},
 'readWrite'
 ]
 }
)

```

write关注点是一个可选参数，可以作为JSON 文档提供。一些示例值为`{w:1}`、`{w:'majority'}`。

回到管理员用户创建，我们在步骤 2 中使用`createUser`方法创建了该用户，并在`admin`数据库中为该用户提供了三个内置角色。

在步骤 3 中，我们使用相同的`createUser`方法在`test`数据库中创建`read`和`read-write`用户。

我们在`admin`、`read`和`read-write`用户创建后关闭 MongoDB 服务器，并使用`--auth`选项重新启动。

再次启动服务器时，我们将在步骤 8 中从 shell 连接到服务器，但未经验证。在这里，我们尝试对测试数据库中的一个集合执行一个`find`查询，但由于我们未经验证而失败。这表示服务器现在需要适当的凭据才能在其上执行操作。在步骤 8 和 9 中，我们使用`read_user`登录，首先执行一个`find`操作（成功），然后执行一个插入操作，因为用户只有读取权限，所以不执行该操作。通过调用 shell`db.auth(<user name>, <password>)`和`db.logout()`对用户进行身份验证的方法，这将注销当前登录的用户。

在步骤 10 到 12 中，我们演示了我们可以使用`write_user`执行`insert`操作，但是像`db.serverStatus()`这样的管理操作无法执行。这是因为这些操作在服务器上执行`admin command`，非管理员用户不允许调用这些操作。同样，当我们将数据库更改为 admin 时，来自`test`数据库的`write_user`不允许执行任何操作，例如获取集合列表或查询`admin`数据库中的集合。

在步骤 14 中，我们使用`admin`用户登录到`admin`数据库。之前，我们使用`auth`方法登录数据库；在本例中，我们使用`-u`和`-p`选项提供用户名和密码。我们还提供了连接到的数据库的名称，在本例中为 admin。在这里，我们可以查看管理数据库上的集合，还可以执行管理操作，如获取服务器状态。执行`db.serverStatus`调用是可能的，因为用户被赋予`clusterAdmin`角色。

最后要注意的一点是，除了向集合写入之外，具有写入权限的用户还可以在具有写入权限的集合上创建索引。

## 还有更多…

在这个配方中，我们了解了如何创建不同的用户，以及他们拥有哪些权限来限制某些操作集。在下面的配方中，我们将看到如何在流程级别完成身份验证。也就是说，一个 mongo 实例如何对添加到副本集中的自身进行身份验证。

## 另见

*   MongoDB 有很多内置用户角色，每个角色都有不同的权限。请参考以下 URL 获取各种内置角色的详细信息：[http://docs.mongodb.org/manual/reference/built-in-roles/](http://docs.mongodb.org/manual/reference/built-in-roles/) 。
*   MongoDB 也支持自定义用户角色。有关定义自定义用户角色的详细信息，请参阅以下 URL:[http://docs.mongodb.org/manual/core/authorization/#user-定义的角色](http://docs.mongodb.org/manual/core/authorization/#user-defined-roles)。

# Mongo 中的进程间安全

在前面的配方中，我们看到了如何在允许对 Mongo 进行任何操作之前，对登录的用户实施身份验证。在这个配方中，我们将研究进程间安全性。通过术语进程间安全性，我们的意思不是加密通信，而是确保添加到副本集中的节点在添加到副本集中之前经过身份验证。

## 准备好了吗

在此配方中，我们将启动多个 mongo 实例作为副本集的一部分，因此如果您不知道如何启动副本集，您可能必须参考[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*中的配方*启动多个实例作为副本集的一部分*，*安装并启动服务器*。除此之外，在这个配方中，我们将研究如何生成要使用的密钥文件，以及将未经验证的节点添加到副本集中时的行为。*

## 怎么做…

首先，我们将启动三个实例，每个实例分别监听端口`27000`、`27001`和`27002`。前两个将通过向其提供密钥文件的路径来启动，第三个不会。稍后，我们将尝试将这三个实例添加到同一副本集中。

1.  让我们先生成密钥文件。生成密钥文件没有什么了不起的。这就像从`base64`字符集中获得一个包含 6 到 1024 个字符的文件一样简单。在 Linux 文件系统上，您可以选择使用`openssl`生成伪随机字节，并将它们编码为`base64`。以下命令将生成 500 个随机字节，然后这些字节将被`base64`编码并写入文件`keyfile`：

    ```
    $ openssl rand –base64 500 > keyfile

    ```

2.  在 Unix 文件系统上，密钥文件不应具有 world 和 group 的权限。因此，我们应该在创建后执行以下操作：

    ```
    $ chmod 400 keyfile

    ```

3.  不向创建者授予写入权限可确保我们不会意外覆盖内容。然而，在 Windows 平台上，`openssl`不是现成的，因此您必须下载它，提取归档文件，并将`bin`文件夹添加到 OS path 变量中。对于 Windows，我们可以从以下 URL 下载：[http://gnuwin32.sourceforge.net/packages/openssl.htm](http://gnuwin32.sourceforge.net/packages/openssl.htm) 。
4.  您甚至可以选择不使用此处提到的方法（使用`openssl`）生成密钥文件，只需从任何文本编辑器或您的选择在密钥文件中键入纯文本即可轻松解决问题。但是，请注意，mongo 删除了字符`\r`、`\n`和空格，剩余的文本被视为键。例如，我们可以创建一个文件，将以下内容添加到密钥文件中。同样，文件名为`keyfile`，内容如下：

    ```
    somecontentaddedtothekeyfilefromtheeditorwithoutspaces
    ```

5.  使用这里提到的任何方法，我们都不能有一个`keyfile`用于配方的下一步。
6.  现在，我们将通过如下方式启动 mongo 实例来保护 mongo 进程。我将在 windows 上启动以下操作，我的密钥文件 ID 名为`keyfile`并放置在`c:\MongoDB`上。三个实例的数据路径分别为`c:\MongoDB\data\c1, c:\MongoDB\data\c2`和`c:\MongoDB\data\c3`。
7.  启动第一个监听端口`27000`的实例如下：

    ```
    C:\>mongod --dbpath c:\MongoDB\data\c1 --port 27000 --auth --keyFile c:\MongoDB\keyfile --replSet secureSet --smallfiles --oplogSize 100

    ```

8.  同样，启动监听端口`27001`的第二台服务器，如下所示：

    ```
    C:\>mongod --dbpath c:\MongoDB\data\c2 --port 27001 --auth --keyFile c:\MongoDB\keyfile --replSet secureSet --smallfiles --oplogSize 100

    ```

9.  第三个实例将启动，但没有监听端口`27002`的`--auth`和`--keyFile`选项，如下所示：

    ```
    C:\>mongod --dbpath c:\MongoDB\data\c3 --port 27002 --replSet secureSet --smallfiles --oplogSize 100

    ```

10.  然后，我们启动一个 mongo shell 并将其连接到端口`27000`，这是第一个启动的实例。在 mongo shell 中，我们键入：

    ```
    > rs.initiate()

    ```

11.  在几秒钟内，副本集中只会有一个实例启动。现在，我们将尝试向该副本集中添加两个新实例。首先，在端口`27001`上添加一个监听端口，如下所示（您需要添加适当的主机名，`Amol-PC`在我的例子中是主机名）：

    ```
    > rs.add({_id:1, host:'Amol-PC:27001'})

    ```

12.  我们将执行`rs.status()`命令来查看复制集的状态。在命令的输出中，我们应该看到新添加的实例。
13.  We will now finally try and add an instance that was started without the `--auth` and the `--keyFile` option as follows:

    ```
    > rs.add({_id:2, host:'Amol-PC:27002'})

    ```

    这会将实例添加到副本集中，但使用`rs.status()`会将实例的状态显示为未知。在`27002`上运行的实例的服务器日志也应该显示一些身份验证错误。

14.  我们最终必须重新启动这个实例；但是，本次我们提供的`--auth`和`--keyFile`选项如下：

    ```
    C:\>mongod --dbpath c:\MongoDB\data\c3 --port 27002 --replSet secureSet --smallfiles --oplogSize 100 --auth --keyFile c:\MongoDB\keyfile

    ```

15.  一旦服务器启动，再次从 shell 连接到它，并在短时间内输入`rs.status()`，它应该作为一个辅助实例出现。

## 还有更多…

在这个配方中，我们看到了进程间安全性，可以防止未经验证的节点被添加到 mongo 副本集中。我们仍然没有通过加密通过网络发送的数据来保护传输。在*附录*中，我们将展示如何从源代码构建 mongo 服务器，以及如何通过网络对内容进行加密。

# 使用 collMod 命令修改收集行为

这是一个用于更改 mongo 中集合行为的命令。它可以被认为是一个*集合修改*操作（官方并未提及）。

对于这个配方的一部分，需要了解 TTL 索引。

## 准备好了吗

在此配方中，我们将对集合执行`collMod`操作。我们需要启动一个独立的服务器，监听客户端连接的任何端口；在这种情况下，我们将坚持默认的`27017`。如果您不知道如何启动独立服务器，请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*安装单节点 MongoDB*。我们还需要启动一个用于本届政府的 shell。强烈建议您在不知道的情况下，使用[第 2 章](02.html "Chapter 2. Command-line Operations and Indexes")、*命令行操作和索引*中的[索引和*在给定时间使用 TTL 索引*查看*定期过期文档的配方。*](02.html "Chapter 2. Command-line Operations and Indexes")

## 它是如何工作的…

此操作可用于执行以下几项操作：

1.  假设我们有一个带有 TTL 索引的集合，正如我们在[第 2 章](02.html "Chapter 2. Command-line Operations and Indexes")、*命令行操作*中看到的，让我们通过执行以下命令来查看列表索引：

    ```
    > db.ttlTest.getIndexes()

    ```

2.  要将到期时间从`300`毫秒更改为`800`毫秒，请执行以下命令：

    ```
    > db.runCommand({collMod: 'ttlTest', index: {keyPattern: {createDate:1}, expireAfterSeconds:800}})

    ```

## 它是如何工作的…

`collMod`命令始终具有以下格式：`{collMod : <name of the collection>, <collmod operation>}`。

我们使用索引操作`collMod`来修改 TTL 索引。如果已经创建了 TTL 索引，并且在创建之后需要更改生存时间，那么我们使用`collMod`命令。该命令的操作特定字段如下所示：

```
{index: {keyPattern: <the field on which the index was originally created>, expireAfterSeconds:<new time to be used for TTL of the index>}}

```

`keyPattern`是集合的字段，在该字段上创建 TTL 索引，`expireAfterSeconds`将包含要更改的新时间。成功执行后，我们应该在 shell 中看到以下内容：

```
{ "expireAfterSeconds_old" : 300, "expireAfterSeconds_new" : 800, "ok" : 1 }

```

# 将 MongoDB 设置为 windows 服务

Windows服务是在后台运行的长时间运行的应用程序，类似于守护进程线程。数据库是此类服务的良好候选对象，在主机启动和停止时，数据库将启动和停止（但是，您可以选择手动启动/停止服务）。许多数据库供应商提供了在服务器上安装数据库时将其作为服务启动的功能。MongoDB 也可以让你做到这一点，这就是我们将在这个食谱中看到的。

## 准备好了吗

有关如何使用外部配置文件启动 MongoDB 服务器的信息，请参考[第 1 章](01.html "Chapter 1. Installing and Starting the Server")中的配置文件中的*安装单节点 MongoDB 的配方*安装和启动服务器*。由于在本例中 mongo 是作为服务运行的，因此不能为它提供类似命令的参数，而从配置文件配置它是唯一的选择。请参阅[第一章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中*安装单节点 MongoDB*配方的先决条件，这就是我们需要的全部配方。*

## 怎么做…

1.  我们将首先创建一个配置文件，其中包含三个配置值：`port`、`dbpath`和`logpath`文件。我们将文件命名为`mongo.conf`并将其保存在`c:\conf\mongo.conf`位置，其中包含以下三个条目（您可以为配置文件位置、数据库和日志选择任何路径）：

    ```
    port = 27000
    dbpath = c:\data\mongo\db
    logpath = c:\logs\mongo.log

    ```

2.  从windows 终端执行以下操作，您可能需要以管理员身份执行。在 Windows 7 上，执行了以下步骤：
    1.  按键盘上的 Windows 键。
    2.  在搜索程序和文件空间中，键入`cmd`。
    3.  在程序中，将看到命令提示符程序；右键点击**以管理员身份运行**。
3.  在 shell 中，执行以下操作：

    ```
    C:\>mongod --config c:\conf\mongo.conf –install

    ```

4.  控制台上打印的日志应确认服务安装正确。
5.  可从控制台按如下方式启动服务：

    ```
    C:\>net start MongoDB

    ```

6.  服务可以按如下方式停止：

    ```
    C:\>net stop MongoDB

    ```

7.  Type in `services.msc` in the Run window (Windows button + *R*). In the management console, search for MongoDB service. We should see it as follows:

    ![How to do it…](graphics/B04831_04_01.jpg)

8.  服务是自动的，也就是说，它将在操作系统启动时启动。右键点击并选择**属性**可将其更改为手动。
9.  要删除服务，我们需要在命令提示符下执行以下操作：

    ```
    C:\>mongod --remove

    ```

10.  有更多可用选项可用于配置服务名称、显示名称、说明以及用于运行服务的用户帐户。这些可以作为命令行参数提供。执行以下操作以查看可能的选项，并查看**Windows 服务控制管理器**选项：

    ```
    C:\> mongod --help

    ```

# 副本集配置

我们在[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*中对什么是复制集进行了很好的讨论，在*配方中*安装和启动服务器*启动多个实例作为复制集*的一部分，我们看到了如何启动一个简单的复制集。在本章 Mongo*中的配方*进程间安全性中，我们看到了如何使用进程间身份验证启动副本集。老实说，这就是我们在设置标准副本集时所做的。有一些配置必须知道，并且应该知道它是如何影响副本集的行为的。请注意，我们在此配方中仍然没有讨论标记感知复制，本章后面将作为单独的配方*构建标记副本集*进行讨论。*

## 准备好了吗

请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*启动多个实例作为副本集*的一部分，了解副本集基础知识。继续，在您的计算机上设置一个简单的三节点副本集，如配方中所述。

在继续进行配置之前，我们将了解复制集中有哪些选举，以及它们是如何从高级别工作的。了解选举很好，因为一些配置选项会影响选举中的投票过程。

### 副本集中的选举

Mongo 副本集有一个主实例和多个辅助实例。所有数据库写入仅通过主实例进行，并复制到辅助实例。根据读取首选项，可以从辅助实例执行读取操作。查询[附录](10.html "Appendix A. Concepts for Reference")中的请参考*了解阅读偏好了解阅读偏好。但是，如果由于某种原因，主服务器停机或无法访问，则副本集将无法进行写入。MongoDB 副本集具有自动故障切换到辅助副本的功能，方法是将其升级到主副本，并使客户端可以使用该副本集执行读写操作。在新的主副本出现之前，副本集在这短暂的一刻内保持不可用。*

这听起来不错，但问题是，谁来决定新的主要实例是谁？选择新的初选是通过选举进行的。每当任何次节点检测到它无法联系到主节点时，它会要求实例中的所有副本集节点选择自己作为新的主节点。

副本集中接收此主节点选择请求的所有其他节点将在对请求选择的次节点投赞成票之前执行某些检查：

1.  他们将首先检查现有的主服务器是否可以访问。这是必要的，因为请求重新选举的次节点可能由于网络分区而无法到达主节点，在这种情况下，不应允许它成为主节点。在这种情况下，接收请求的实例将投反对票。
2.  其次，该实例将与请求选择的次实例一起检查自身的复制状态。如果它发现请求的辅助服务器在复制数据中落后于自己，它将投反对票。
3.  最后，主节点是不可访问的，但某些优先级高于请求重新选举的次节点的实例可以从主节点访问。如果请求重新选举的辅助服务器可能由于网络分区而无法联系到具有更高优先级的辅助服务器，则这是可能的。在这种情况下，接收选举请求的实例将投反对票。

上述检查与连任期间发生的情况基本相同（不一定按照前面提到的顺序）；如果这些检查通过，实例将投票赞成。

即使只有一位候选人投了反对票，选举也是无效的。但是，如果没有一位候选人投了反对票，那么请求选举的二级候选人如果收到大多数候选人的赞成票，将成为新的初选候选人。如果选举无效，将在同一中学或任何其他情况下再次举行选举，要求按照上述程序进行选举，直到选出新的初选为止。

现在我们已经了解了副本集中的选择和术语，让我们看看一些副本集配置。这些选项中很少有与投票相关的，我们首先从这些选项开始。

### 副本集的基本配置

从第一章开始，当我们建立一个副本集时，我们有一个类似于下面的配置。三个成员集的基本副本集配置如下：

```
{
        "_id" : "replSet",
        "members" : [
                {
                        "_id" : 0,
                        "host" : "Amol-PC:27000"
                },
                {
                        "_id" : 1,
                        "host" : "Amol-PC:27001"
                },
                {
                        "_id" : 2,
                        "host" : "Amol-PC:27002"
                }
        ]
}
```

我们不会在以下部分的所有步骤中重复整个配置。我们要提到的所有标志都将添加到 members 数组中某个特定成员的文档中。在前面的示例中，如果将`_id`作为`2`的节点作为仲裁者，我们将在前面显示的配置文档中对其进行以下配置：

```
{
      "_id" : 2,
      "host" : "Amol-PC:27002"
      "arbiterOnly" : true
}
```

通常，重新配置现有副本集的步骤如下：

1.  将配置文档分配给变量。如果已经配置了副本集，则可以使用 shell 的`rs.conf()`调用来获取副本集。

    ```
    > var conf = rs.conf()

    ```

2.  文档中的“成员”字段是副本集中每个成员的文档数组。要向特定成员添加新属性，请执行以下操作。例如，如果我们想要为副本集的第三个成员（数组中的索引 2）添加`votes`键并将其值设置为`2`，我们将执行以下操作：

    ```
    > conf.members[2].votes = 2

    ```

3.  仅仅更改 JSON 文档不会更改副本集。如果副本集已经就位，我们需要重新配置它，如下所示：

    ```
    > rs.reconfig(conf)

    ```

4.  如果是第一次配置，我们会调用以下命令：

    ```
    > rs.initiate (conf)

    ```

对于下面给出的所有步骤，您需要按照前面的步骤重新配置或启动副本集，除非明确提到其他一些步骤。

## 怎么做…

在本配方中，我们将介绍一些可以在副本集中完成的可能配置。与往常一样，在下一节中完成所有解释后，解释将是最小的。

1.  第一个配置是`arbiterOnly`选项。它用于将副本集成员配置为不包含数据但只有投票权的成员。需要将以下密钥添加到将成为仲裁人的成员的配置中：

    ```
    {_id: ... , 'arbiterOnly': true }

    ```

2.  关于此配置，需要记住的一点是，一旦启动了副本集，就不能将任何现有成员从非仲裁器节点更改为仲裁器，反之亦然。但是，我们可以使用 helper 函数`rs.addArb(<hostname>:<port>)`将仲裁器添加到现有副本集中。例如，将侦听端口`27004`的仲裁器添加到现有副本集中。在我的机器上执行以下操作以添加仲裁器：

    ```
    > rs.addArb('Amol-PC:27004')

    ```

3.  当服务器开始监听端口`27004`并且从 mongo shell 执行`rs.status()`时，我们应该看到该成员的`state`和`strState`分别是`7`和`ARBITER`。
4.  下一个选项`votes`影响成员在选举中的投票数。默认情况下，所有成员各有一票，此选项可用于更改特定成员的投票数。可设置如下：

    ```
    {_id: ... , 'votes': <0 or 1>}

    ```

5.  可以更改副本集现有成员的投票，并且可以使用`rs.reconfig()`助手重新配置副本集。
6.  虽然选项`votes`是可用的，它可能会改变投票数以形成多数票，但它通常不会增加太多价值，也不是推荐在生产中使用的选项。
7.  下一个副本集配置选项称为`priority`。它确定副本集成员是否有资格成为主副本集成员（或不成为主副本集成员）。该选项设置如下：

    ```
    {_id: ... , 'priority': <priority number>}

    ```

8.  较高的数字表示更可能成为主副本，主副本将始终是副本集中存在的成员中优先级最高的成员。在已配置的副本集中设置此选项将触发选择。
9.  将优先级设置为`0`将确保成员永远不会成为主要成员。
10.  我们将考虑的下一个选项是`hidden`。将此选项的值设置为 true 可确保副本集成员被隐藏。该选项设置如下：

    ```
    {_id: ... , 'hidden': <true/false>}

    ```

11.  需要记住的一点是，当副本集成员被隐藏时，其优先级也应该被设置为`0`，以确保它不会成为主副本。虽然这似乎是多余的；从当前版本开始，需要显式设置值或优先级。
12.  当编程语言客户端连接到副本集时，它将无法发现隐藏的成员。但是，在 shell 中使用`rs.status()`后，成员的状态将可见。
13.  现在让我们看看`slaveDelay`选项。此选项用于从副本集的主副本设置滞后时间。该选项设置如下：

    ```
    {_id: ... , 'slaveDelay': <number of seconds to lag>}

    ```

14.  与隐藏成员一样，从属延迟成员也应该将优先级设置为`0`，以确保它们永远不会成为主成员。这需要明确设置。
15.  让我们看看最终的配置选项：`buildIndexes`。如果默认情况下未指定该值，则该值为 true，这表示如果在主服务器上创建索引，也需要在辅助服务器上复制该索引。该选项设置如下：

    ```
    {_id: ... , 'buildIndexes': <true/false>}

    ```

16.  使用此选项时，如果将值设置为 false，则优先级将设置为`0`，以确保它们不会成为主选项。这需要明确设置。此外，在副本集启动后，无法设置此选项。与仲裁器节点一样，这需要在创建副本集或向副本集中添加新成员节点时进行设置。

## 它是如何工作的…

在本节中，我们将解释和理解不同类型成员的重要性以及我们在上一节中看到的配置选项。

### 副本集成员作为仲裁者

*仲裁人*一词的英文意思是解决争议的法官。在副本集的情况下，仲裁节点仅用于在选举情况下投票，而不复制任何数据。事实上，这是一个非常常见的场景，因为 Mongo 副本集需要至少有三个实例（最好是奇数个实例，3 个或更多）。许多应用程序不需要维护数据的三个副本，只需要两个实例就可以了，一个是主实例，一个是辅助实例。

考虑只有两个实例存在于副本集中的场景。当初选失败时，第二个实例不能形成适当的多数票，因为它只有 50%的选票（自己的选票），因此不能成为初选。如果大多数次实例停止运行，则主实例将从主实例退出并成为次实例，从而使副本集不可用于写入。因此，两节点副本集是无用的，因为即使在任何实例停止运行时，它也无法保持可用。它违背了设置副本集的目的，因此副本集中至少需要三个实例。

仲裁人在这种情况下很方便。我们设置了一个副本集实例，其中有三个实例，其中只有两个具有数据，一个充当仲裁器。我们不需要同时维护数据的三个副本，我们消除了设置两个实例副本集所面临的问题。

### 副本集成员的优先级

优先级标志可以单独使用，也可以与`hidden`、`slaveDelay`和`buildIndexes`等其他选项结合使用，我们不希望拥有这三个选项之一的会员成为主要会员。我们将很快研究这些选项。

我们永远不希望副本集成为主副本的一些可能的使用情形如下：

*   当一个成员的硬件配置无法处理写入和读取请求时，如果它成为主请求，那么将其放入其中的唯一原因就是复制数据。
*   我们有一个多数据中心设置，其中一个副本集实例存在于另一个数据中心中，以便在地理上分布数据以用于灾难恢复。理想情况下，承载应用程序的应用程序服务器和数据库之间的网络延迟应该最小，以获得最佳性能。如果两台服务器（应用程序服务器和数据库服务器）位于同一个数据中心，则可以实现这一点。如果不更改另一个数据中心中副本集实例的优先级，则该副本集实例同样有资格被选为主副本集实例，从而在其他数据中心中的服务器被选为主副本集实例时影响应用程序的性能。在这种情况下，我们可以将第二个数据中心的服务器的优先级设置为`0`，如果出现紧急情况，管理员需要手动切换到另一个数据中心。

在这里提到的两种场景中，我们还可以隐藏各自的成员，这样应用程序客户端就不会首先看到这些成员。

类似于将优先级设置为`0`以不允许一个成员为主，我们也可以通过将其优先级设置为大于 1 的值来偏向于将一个成员为主，因为优先级的默认值为`1`。

假设出于预算原因，我们有一个场景，其中一个成员将数据存储在 SSD 上，其余成员存储在旋转磁盘上。理想情况下，我们希望具有 SSD 的成员在其启动和运行时成为主要成员。只有当它不可用时，我们才希望另一个成员成为主成员，在这种情况下，我们可以将在 SSD 上运行的成员的优先级设置为大于 1 的值。只要该值大于其余值，则该值实际上并不重要，也就是说，只要其他成员的优先级较低，将其设置为`1.5`或`2`就没有任何区别。

### 隐藏、从机延迟、构建索引配置

副本集节点的术语隐藏来自连接到副本集的应用程序客户端，而不是管理员。对于管理员来说，隐藏的成员同样需要监控，因此它们的状态可以在`rs.status()`响应中看到。隐藏成员也像所有其他成员一样参加选举。

对于`slaveDelay`选项，最常见的用例是确保成员中作为特定时间点的数据落后于主节点规定的秒数，并且可以在发生某些不可预见的错误（例如错误更新某些数据的人为错误）时恢复。请记住，延迟时间越长，恢复时间就越长，但代价可能是陈旧的数据。

当我们有一个使用非生产标准硬件的副本集成员，并且维护索引的成本不值得时，`buildIndexes`选项非常有用。您可以为不执行查询的成员设置此选项。显然，如果您设置此选项，它将永远不会成为主要成员，因此优先级选项将被迫设置为`0`。

## 还有更多…

使用副本集中的标记可以实现一些有趣的事情。这将在后面的配方中讨论，在我们了解配方*构建标记副本集*中的标记之后。

# 从副本集中作为主副本退出

有时，对于工作时间内的某些维护活动，我们希望从副本集中取出服务器，执行维护并将其放回副本集中。如果要处理的服务器是主服务器，我们需要从主成员位置退出，执行重新选举，并确保在给定的最短时间内不会再次当选。一旦退出操作成功，服务器变为辅助服务器后，我们可以将其从副本集中取出，执行维护活动并将其放回副本集中。

## 准备好了吗

参考[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*启动多个实例作为副本集*的一部分，了解副本集基础知识的先决条件。在计算机上设置一个简单的三节点副本集，如配方中所述。

## 怎么做…

假设此时已设置并运行复制副本，请执行以下操作：

1.  从连接到其中一个副本集成员的 shell 执行以下操作，并查看当前哪个实例是主实例：

    ```
    > rs.status()

    ```

2.  从 mongo shell 连接到该主实例，并在 shell 上执行以下操作：

    ```
    > rs.stepDown()

    ```

3.  shell 应该再次重新连接，您应该看到连接到的实例（最初是主实例）现在变成了辅助实例。从 shell 中执行以下命令，以便现在重新选择新的主命令：

    ```
    > rs.status()

    ```

4.  现在，您可以连接到主服务器，修改副本集配置并继续管理服务器。

## 它是如何工作的…

前面提到的步骤非常简单，但我们将看到一些有趣的事情。

我们之前看到的方法，`rs.stepDown()`没有任何参数。该函数实际上可以接受一个数值，即被删除的实例不会参与选举且不会成为主要实例的秒数，默认值为`60`秒。

另一个有趣的尝试是，如果被要求退出的实例比其他实例具有更高的优先级，该怎么办。事实证明，当你下台时，优先权并不重要。无论提供的秒数是多少，已删除的实例都不会成为主要实例。但是，如果为已退出的实例设置了优先级，且优先级高于其他实例，则在给予`stepDown`的时间过后，将发生选举，优先级较高的实例将再次成为主要实例。

# 探索副本集的本地数据库

在此配方中，我们将从副本集的角度探索本地数据库。本地数据库可能包含不特定于副本集的集合，但我们将只关注特定于副本集的集合，并尝试查看其中的内容及其含义。

## 准备好了吗

参考[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*启动多个实例作为副本集*的一部分，了解副本集基础知识的先决条件。继续，在您的计算机上设置一个简单的三节点副本集，如配方中所述。

## 怎么做…

1.  在副本设置并运行之后，我们需要打开一个连接到主副本的 shell。您可以随机连接到任何一个成员；使用`rs.status()`然后确定主要参数。
2.  shell 打开时，首先切换到`local`数据库，然后查看`local`数据库中的集合，如下所示：

    ```
    > use local
    switched to db local
    > show collections

    ```

3.  您应该找到一个名为`me`的集合。查询此集合应向我们显示一个文档，其中包含我们当前连接到的服务器的主机名：

    ```
    >db.me.findOne()

    ```

4.  将有两个字段，主机名和`_id`字段。注意`_id`字段，它很重要。
5.  看看`replset.minvalid`系列。您必须从 shell 连接到辅助成员才能执行以下查询。先切换到`local`数据库：

    ```
    > use local
    switched to db local
    > db.replset.minvalid.find()

    ```

6.  此集合仅包含一个文档，其中包含一个键`ts`和一个值，该值是我们连接到的次文档同步之前的时间戳。记下这一次。
7.  从主目录中的 shell，在任何集合中插入文档。我们将使用数据库作为测试。从主成员的外壳执行以下操作：

    ```
    > use test
    switched to db test
    > db.replTest.insert({i:1})

    ```

8.  再次查询二级，如下：

    ```
    > db.replset.minvalid.find()

    ```

9.  我们应该看到，字段`ts`的时间现在已经增加，与此复制从主复制到次复制的时间相对应。对于从属延迟节点，您将看到这一次仅在延迟时间过后才得到更新。
10.  最后，我们将看到集合`system.replset`。此集合是存储副本集配置的位置。执行以下操作：

    ```
    > db.system.replset.find().pretty()

    ```

11.  实际上，当我们执行`rs.conf()`时，会执行以下查询：

    ```
    db.getSisterDB("local").system.replset.findOne()

    ```

## 它是如何工作的…

本地数据库是一个特殊的（非复制的）数据库，用于保存复制和其中特定于实例的详细信息。尝试在本地数据库中创建自己的集合，并在其中插入一些数据；它不会复制到辅助节点。

该数据库为我们提供了 mongo 存储的供内部使用的数据的一些视图。但是，作为管理员，了解这些集合以及其中的数据类型是件好事。

大多数收藏都非常简单。在二级数据库的 shell 中，在本地数据库中执行查询`db.me.findOne()`，我们应该看到`_id`应该与子集合中存在的文档的`_id`字段相匹配。

我们看到的配置文档给出了我们所引用的辅助实例的主机名。请注意，复制集成员的端口和其他配置选项不在本文档中。最后，`syncedTo`时间告诉我们次实例与主实例同步的时间。我们在次要屏幕上看到了集合`replset.minvalid`，它告诉我们它与主要屏幕同步的时间。主设备上的`syncedTo`时间中的该值将与相应辅助设备上的`replset.minvalid`时间中的值相同。

## 还有更多…

我们还没有看到 oplog，这很有趣。我们将在一个单独的食谱中看一看这个特别的集合，*理解和分析 oplogs*。

# 理解和分析 OPLOG

Oplog 是一个特殊集合，构成了 MongoDB 复制的主干。当在复制集的主服务器上执行任何写入操作或配置更改时，它们将写入主服务器上的 oplog。然后，所有次要成员跟踪此集合以获得要复制的更改。Tailing 与 Unix 中的 tail 命令同义，只能在称为 capped collection 的特殊类型的集合上执行。Capped 集合是固定大小的集合，它像队列一样维护插入顺序。当集合的分配空间变满时，将覆盖最旧的数据。如果您不知道封顶集合以及什么是可裁剪游标，请参阅[第 5 章](05.html "Chapter 5. Advanced Operations")*高级操作*中的*在 MongoDB*中创建和跟踪封顶集合游标。

Oplog 是存在于非复制数据库中的一个有上限的集合，称为**本地**。在我们之前的配方中，我们看到了什么是`local`数据库以及其中存在哪些集合。Oplog 是我们在上一个菜谱中没有讨论的东西，因为它需要更多的解释，并且需要一个专门的菜谱才能做到公正。

## 准备好了吗

参考[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*启动多个实例作为副本集*的一部分，了解副本集基础知识的先决条件。继续，在您的计算机上设置一个简单的三节点副本集，如配方中所述。打开 shell 并连接到副本集的主成员。您需要启动 mongo shell 并连接到主实例。

## 怎么做…

1.  在从 shell 连接到主节点后执行以下步骤，以获取 oplog 中存在的最后一个操作的时间戳。我们将有兴趣在这段时间后查看操作。

    ```
    > use test
    > local = db.getSisterDB('local')
    > var cutoff = local.oplog.rs.find().sort({ts:-1}).limit(1).next().ts

    ```

2.  从 shell 中执行以下命令。将输出保存在 shell 中或将其复制到某个位置。我们稍后会分析：

    ```
    > local.system.namespaces.findOne({name:'local.oplog.rs'})

    ```

3.  插入 10 份文件如下：

    ```
    > for(i = 0; i < 10; i++) db.oplogTest.insert({'i':i})

    ```

4.  执行以下更新，为所有值为`i`大于`5`的文档设置字符串值，在本例中为 6、7、8 和 9。这将是一个多更新操作：

    ```
    > db.oplogTest.update({i:{$gt:5}}, {$set:{val:'str'}}, false, true)

    ```

5.  现在，创建如下索引：

    ```
    > db.oplogTest.ensureIndex({i:1}, {background:1})

    ```

6.  在 oplog 上执行以下查询：

    ```
    > local.oplog.rs.find({ts:{$gt:cutoff}}).pretty()

    ```

## 它是如何工作的…

对于那些了解消息传递及其术语的人来说，Oplog 可以被看作是消息传递世界中的一个主题，一个生产者是主要实例，多个消费者是次要实例。主实例将需要复制的所有内容写入 oplog。因此，副本集上的任何创建、更新和删除操作以及任何重新配置都将写入 oplog，并且辅助实例将跟踪（持续读取添加到其中的 oplog 的内容，类似于 Unix 中带有`-f`选项的 tail 命令）用于获取主用户编写的文档的集合。如果辅助系统配置了`slaveDelay`，则其读取文档的时间不会超过从 oplog 读取文档的最大时间减去`slaveDelay`的时间。

我们首先将本地数据库的一个实例保存在名为`local`的变量中，并确定了一个截止时间，用于从 oplog 查询我们将在此配方中执行的所有操作。

在本地数据库中对`system.namespaces`集合执行查询时，我们会发现该集合是一个大小固定的 capped 集合。出于性能原因，封顶集合在文件系统上分配了连续空间，并且是预先分配的。服务器分配的大小取决于操作系统和 CPU 体系结构。在启动服务器时，可以提供选项`oplogSize`来说明 oplog 的大小。对于大多数情况，默认值通常足够好。但是，出于开发目的，您可以选择覆盖此值以获得较小的值。oplog 是有上限的集合，需要在磁盘上预先分配空间。此预分配不仅在副本集首次初始化时需要时间，而且会占用固定数量的磁盘空间。出于开发目的，我们通常在同一台机器上启动多个 MongoDB 进程作为同一副本集的一部分，并希望它们以最低的资源使用率尽快启动和运行。此外，如果 oplog 的大小很小，那么将整个 oplog 存储在内存中也是可能的。出于所有这些原因，出于开发目的，建议使用较小的 oplog 大小启动本地实例。

我们执行了一些操作，例如插入 10 个文档，使用多重更新更新 4 个文档，并创建索引。如果我们在 oplog 中查询截止后的条目，我们会在前面计算，我们会看到其中每个插入 10 个文档。该文档如下所示：

```
{
        "ts" : Timestamp(1392402144, 1),
        "h" : NumberLong("-4661965417977826137"),
        "v" : 2,        "op" : "i",
        "ns" : "test.oplogTest",
        "o" : {
                "_id" : ObjectId("52fe5edfd473d2f623718f51"),
                "i" : 0
        }
}
```

我们可以看到，我们首先看三个字段：`op`、`ns`和`o`。它们代表操作、要插入数据的集合的完全限定名以及要插入的实际对象。操作`i`代表插入操作。请注意，`o`的值（即要插入的文档）包含在主服务器上生成的`_id`字段。我们应该看到 10 份这样的文件，每插入一份。有趣的是看到的是在多次更新操作中发生的情况。主文档将放置四个文档，每个文档对应一个受更新影响的文档。在这种情况下，值`op`是`u`，用于更新，用于匹配文档的查询与我们在更新函数中给出的不同，但它是一个基于`_id`字段唯一查找文档的查询。由于`_id`字段已有索引（为每个集合自动创建），因此查找要更新的文档的操作并不昂贵。字段`o`的值与我们从 shell 传递给 update 函数的文档相同。oplog 中用于更新的示例文档如下所示：

```
{
    "ts" : Timestamp(1392402620, 1),
    "h" : NumberLong("-7543933489976433166"),
    "v" : 2,
    "op" : "u",
    "ns" : "test.oplogTest",
    "o2" : {
            "_id" : ObjectId("52fe5edfd473d2f623718f57")
    },
    "o" : {
            "$set" : {
                    "val" : "str"
            }
    }
}
```

oplog 中的更新与我们提供的更新相同。这是因为`$set`运算是幂等的，这意味着您可以安全地应用任意次数的运算。

但是，使用`$inc`运算符进行更新不是幂等的。让我们执行以下更新：

```
> db.oplogTest.update({i:9}, {$inc:{i:1}})

```

在这种情况下，oplog 的值为`o`。

```
"o" : {
    "$set" : {
           "i" : 10
     }
}
```

Mongo smartly 将此非幂等运算作为幂等运算放入 oplog，i 的值设置为增量运算一次后的值。因此，在不损坏数据的情况下，可以安全地重放 oplog 任意次数。

最后，我们可以看到索引创建过程作为`system.indexes`集合中的插入操作放在 oplog 中。对于大型集合，索引创建可能需要几个小时，因此 oplog 的大小对于让次集合从索引创建开始后就没有复制过的地方赶上来非常重要。但是，自版本 2.6 以来，在主实例的后台启动的索引创建也将在辅助实例的后台生成。

有关副本集索引创建的更多详细信息，请访问以下 URL:[http://docs.mongodb.org/master/tutorial/build-indexes-on-replica-sets/](http://docs.mongodb.org/master/tutorial/build-indexes-on-replica-sets/) 。

# 构建带标记的副本集

在[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中，我们看到了如何在*中设置一个简单副本，将多个实例作为副本集*的一部分启动，并了解了副本集的用途。我们也对本书[附录](10.html "Appendix A. Concepts for Reference")中的`WriteConcern`是什么以及为什么使用`WriteConcern`做了大量的解释。关于写操作，我们看到的是它为特定的写操作提供了最低级别的保证。然而，有了标记和写关注点的概念，我们可以定义各种规则和条件，在认为写操作成功并向用户发送响应之前必须满足这些规则和条件。

考虑一些常见的用例，例如：

1.  应用程序希望将写入操作传播到其每个数据中心中的至少一台服务器。这可确保在数据中心关闭的情况下，其他数据中心将拥有应用程序写入的数据。
2.  如果没有多个数据中心，则副本集中至少有一个成员保留在不同的机架上。例如，如果机架的电源关闭，副本集仍然可用（不一定用于写入），因为至少有一个成员在不同的机架上运行。在这种情况下，我们希望在成功写回客户机之前，将写操作传播到至少两个机架。
3.  报告应用程序可能会查询副本集的一组辅助副本，以便定期生成一些报告。（这样的辅助设备可能被配置为永远不会成为主设备）。在每次写入之后，我们希望确保在确认写入成功之前将写入操作复制到至少一个报告副本成员。

前面的用例是出现的一些常见用例，没有使用我们前面看到的简单写关注点来解决。我们需要一种不同的机制来满足这些需求，而带标签的副本集正是我们所需要的。

显然，下一个问题是标签到底是什么？让我们以博客为例。博客中的各种帖子都有不同的标签。这些标签使我们能够轻松地搜索、分组和关联帖子。标签是一些用户定义的文本，带有一些附加的含义。如果我们在博客文章和副本集成员之间进行类比，就像我们将标签附加到文章一样，我们可以将标签附加到每个副本集成员。例如，在多个数据中心场景中，数据中心 1（`dc1`中有两个副本集成员，数据中心 2（`dc2`中有一个成员），我们可以将以下标记分配给这些成员。密钥的名称和分配给标签的值是任意的，在应用程序设计期间选择；如果您发现解决您的用例非常有用，您甚至可以选择分配任何标记，如设置服务器的管理员：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

副本集成员

 | 

标签

 |
| --- | --- |
| 副本集成员 1 | `{'datacentre': 'dc1', 'rack': 'rack-dc1-1'}` |
| 副本集成员 2 | `{'datacentre': 'dc1', 'rack': 'rack-dc1-2'}` |
| 副本集成员 3 | `{'datacentre': 'dc2', 'rack': 'rack-dc2-2'}` |

这足以为复制集标签的基础奠定基础。在这个配方中，我们将看到如何将标记分配给副本集成员，更重要的是，如何利用它们来解决我们前面看到的一些示例用例。

## 准备好了吗

有关先决条件和副本集基础知识，请参阅第 1 章“安装和启动服务器”中的“启动多个实例作为副本集的一部分”配方*。继续，在您的计算机上设置一个简单的三节点副本集，如配方中所述。打开 shell 并连接到副本集的主成员。*

如果您需要了解写关注点，请参阅本书[附录](10.html "Appendix A. Concepts for Reference")中的写关注点概述。

为了在数据库中插入文档，我们将使用 Python，因为它为我们提供了一个交互界面，如 mongo shell。请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的*使用 Python 客户端*连接到单个节点的方法，了解如何安装 pymongo。mongoshell 是演示 insert 操作的最理想的候选者，但是在使用 shell 和我们的定制写操作时存在一定的限制。从技术上讲，任何具有 insert 操作配方中提到的 write关注点的编程语言都可以正常工作。

## 怎么做…

1.  在副本集启动后，我们将向其添加标记并按如下方式重新配置它。从 mongo shell 执行以下命令：

    ```
    > var conf = rs.conf()
    > conf.members[0].tags = {'datacentre': 'dc1', 'rack': 'rack-dc1-1'}
    > conf.members[1].tags = {'datacentre': 'dc1', 'rack': 'rack-dc1-2'}
    > conf.members[2].priority = 0
    > conf.members[2].tags = {'datacentre': 'dc2', 'rack': 'rack-dc2-1'}

    ```

2.  有了副本集标记集（不是说我们还没有重新配置副本集），我们需要定义一些自定义写入关注点。首先，我们定义了一个可以确保数据至少复制到每个数据中心的一台服务器上的方法。在 mongo shell 中再次执行以下操作：

    ```
    > conf.settings = {'getLastErrorModes' : {'MultiDC':{datacentre : 2}}}
    > rs.reconfig(conf)

    ```

3.  启动 python shell 并执行以下操作：

    ```
    >>> import pymongo
    >>> client = pymongo.MongoClient('localhost:27000,localhost:27001', replicaSet='replSetTest')
    >>> db = client.test

    ```

4.  我们现在将执行以下插入：

    ```
    >>>db.multiDCTest.insert({'i':1}, w='MultiDC', wtimeout=5000)

    ```

5.  前面的插入成功，打印出`ObjectId`；您可以从 mongoshell 或 pythonshell 查询集合以进行确认。
6.  由于我们的主服务器是数据中心`1`中的一台服务器，我们现在将停止服务器侦听端口`27002`，该端口是优先级为`0`并标记为位于不同数据中心的端口。
7.  一旦服务器停止（您可以使用 mongo shell 中的`rs.status()`helper 函数进行确认），再次执行以下插入，该插入应该会出错：

    ```
    >>>db.multiDCTest.insert({'i':2}, w='MultiDC', wtimeout=5000)

    ```

8.  重新启动停止的 mongo 服务器。
9.  类似地，我们可以通过从 mongo shell 定义如下的新配置来确保写入传播到至少两个机架（在任何数据中心），从而实现机架感知：

    ```
    {'MultiRack':{rack : 2}}

    ```

10.  conf 对象的设置值如下所示。设置完成后，使用 mongo shell 中的`rs.reconfig(conf)`重新配置副本集：

    ```
    {
       'getLastErrorModes' : {
               'MultiDC':{datacentre : 2}, 
               'MultiRack':{rack : 2}
       }
    }
    ```

11.  我们看到`WriteConcern`与副本集标签一起使用，以实现数据中心和机架感知等功能。让我们看看如何在读取操作中使用副本集标记。
12.  我们将了解如何使用具有读取首选项的副本集标记。让我们通过再添加一个标记来重新配置集合，以标记将用于执行每小时统计报告的辅助成员。
13.  执行以下步骤从 mongo shell 重新配置集合：

    ```
    > var conf = rs.conf()
    > conf.members[2].tags.type = 'reports'
    > rs.reconfig(conf)

    ```

14.  这将配置优先级为`0`的同一成员，以及位于不同数据中心的另一个成员，该成员具有一个名为“type with a value reports”的附加标记。
15.  现在我们回到 python shell 并执行以下步骤：

    ```
    >>> curs = db.multiDCTest.find(read_preference=pymongo.ReadPreference.SECONDARY,
     tag_sets=[{'type':'reports'}])
    >>> curs.next()

    ```

16.  前面的执行应该向我们显示集合中的一个文档（正如我们在前面的步骤中在此测试集合中插入的数据）。
17.  停止我们标记为报告的实例，即在端口`27002`上侦听连接的服务器，并在 python shell 上再次执行以下操作：

    ```
    >>> curs = db.multiDCTest.find(read_preference=pymongo.ReadPreference.SECONDARY,
     tag_sets=[{'type':'reports'}])
    >>> curs.next()

    ```

18.  这一次，执行应该失败，并声明找不到具有所需标记集的辅助标记。

## 它是如何工作的…

在这个配方中，我们对标记的副本集进行了大量操作，并了解了它如何影响使用`WriteConcern`的写入操作和使用`ReadPreference`的读取操作。现在让我们详细了解一下。

### 标记副本集中的 WriteConcern

我们设置了一个已启动并正在运行的副本集，并对其进行了重新配置以添加标记。我们标记了数据中心 1 和不同机架中的前两台服务器（运行监听端口`27000`和`27001`进行客户端连接的服务器）和数据中心 2 中的第三台服务器（监听端口`27002`进行客户端连接的服务器）。我们还通过将数据中心 2 中的成员的优先级设置为`0`，确保该成员不会成为主要成员。

我们的第一个目标是确保复制集的写入操作复制到两个数据中心中的至少一个成员。为了确保这一点，我们将写关注点定义如下`{'MultiDC':{datacentre : 2}}`。这里，我们首先将写关注点的名称定义为 MultiDC。作为 JSON 对象的值有一个名为 datacenter 的键，该键与我们附加到复制集的标记所用的键相同，该值是一个数字`2`，它将被视为给定标记的不同值的数量，在写入成功之前应确认写入。

例如，在我们的例子中，当写入数据中心 1 中的服务器 1 时，标记数据中心的不同值的数目是 1。如果写入操作被复制到第二台服务器，则数字仍然保持为 1，因为标记数据中心的值与第一个成员的值相同。只有当第三台服务器确认写入操作时，写入操作才满足将写入复制到副本集中标记*数据中心*的两个不同值的定义条件。请注意，该值只能是一个数字，不能包含类似于`{datacentre : 'dc1'}`的内容。此定义无效，在重新配置副本集时将引发错误。

但是我们需要在服务器的某个地方注册这个写问题。这是在配置的最后一步通过在配置 JSON 中设置设置值来完成的。要设置的值为`getLastErrorModes`。`getLastErrorModes`的值是一个 JSON 文档，其中定义了所有可能的写关注点。稍后，我们为至少传播到两个机架的写入定义了另一个写入关注点。这在概念上与 MultiDC写关注点一致，因此我们在此不再详细讨论。在设置了所有必需的标记和设置之后，我们重新配置副本集以使更改生效。

重新配置后，我们使用 MultiDC 写入关注点执行一些写入操作。当两个不同数据中心中有两个成员可用时，写操作将成功完成。但是，当第二个数据中心中的服务器停机时，写入操作超时，并向启动写入的客户端抛出异常。这表明写操作将根据我们的预期成功或失败。

我们刚刚看到了如何使用这些自定义标记来处理一些有趣的用例，这些用例在写操作方面不受产品的隐式支持。与写操作类似，读操作可以充分利用这些标记来解决某些用例，例如从固定的一组带有特定值标记的辅助成员中读取。

### 标记副本集中的 ReadPreference

我们添加了另一个自定义标记，用于注释用于报告目的的成员，然后启动一个具有读取首选项的查询操作，以查询辅助成员，并提供在将该成员视为读取操作的候选成员之前应查找的标记集。请记住，当使用 primary 作为读取首选项时，我们不能使用标记，这就是我们明确指定了`read_preference`到`SECONDARY`的值的原因。

# 为非分片集合配置默认分片

在[第一章](01.html "Chapter 1. Installing and Starting the Server")中*启动两个碎片的简单碎片环境*中*安装并启动服务器*我们设置了一个简单的两个碎片服务器。在*连接到外壳中的碎片并执行[第 1 章](01.html "Chapter 1. Installing and Starting the Server")中的*操作*安装并启动服务器*中，我们向碎片化的人员集合添加了数据。但是，对于任何未分片的集合，所有文档都会在一个称为主分片的分片上结束。这种情况对于集合数量相对较少的小型数据库是可以接受的。但是，如果数据库大小增加，同时未分片集合的数量增加，我们最终会使用这些未分片集合中的大量数据重载特定分片（这是数据库的主分片）。对于此类未切分集合以及切分中特定范围位于此服务器实例上的集合的所有查询操作都将定向到此 it。在这种情况下，我们可以将数据库的主分片更改为其他实例，以便这些未分片的集合在不同实例之间得到平衡。

在这个配方中，我们将看到如何查看这个主碎片，并在需要时将其更改为其他服务器。

## 准备好了吗

按照[第一章](01.html "Chapter 1. Installing and Starting the Server")中*启动两个碎片*的简单碎片化环境的配方，*安装并启动服务器*设置并启动碎片化环境。从 shell 连接到已启动的 mongos 进程。另外，假设两个碎片服务器正在侦听端口`27000`和`27001`，则从外壳连接到这两个进程。因此，我们总共打开了三个外壳，一个连接到 mongos 进程，两个连接到这些单独的碎片。

我们需要为这个配方使用`test`数据库，并且必须在上面启用切分。如果没有，则需要在连接到 mongos 进程的 shell 上执行以下操作：

```
mongos> use test
mongos> sh.enableSharding('test')

```

## 怎么做…

1.  在连接到 mongos 进程的 shell 中，执行以下两个命令：

    ```
    mongos> db.testCol.insert({i : 1})
    mongos> sh.status()

    ```

2.  In the databases, look out for `test` database and take a note of the `primary`. Suppose the following is a part (showing the part under databases only) of the output of `sh.status()`:

    ```
    databases:
     {  "_id" : "admin",  "partitioned" : false,  "primary" : "config" }
     {  "_id" : "test",  "partitioned" : true,  "primary" : "shard0000" }

    ```

    数据库下的第二个文档显示数据库`test`已启用分片（因为 partitioned 为 true），主分片为`shard0000`。

3.  主要碎片，在我们的例子中是`shard0000`，是监听端口`27000`的 mongod 进程。打开连接到此进程的外壳，并在其中执行以下操作：

    ```
    > db.testCol.find()

    ```

4.  Now, connect to another mongod process listening to port `27001` and again execute the following query:

    ```
    > db.testCol.find()

    ```

    请注意，数据只能在主分片上找到，而不能在其他分片上找到。

5.  从 mongos shell 执行以下命令：

    ```
    mongos> use admin
    mongos> db.runCommand({movePrimary:'test', to:'shard0001'})

    ```

6.  从连接到 mongos 进程的 MongoShell 执行以下命令：

    ```
    mongos> sh.status()

    ```

7.  在连接到端口`27000`和`27001`上运行的 mongos 进程的 shell 中，执行以下查询：

    ```
    > db.testCol.find()

    ```

## 它是如何工作的…

我们启动了一个分片设置，并从 mongos 进程连接到它。我们首先在`testCol`集合中插入一个文档，该文档在测试数据库中没有启用分片，也没有启用分片。在这种情况下，数据位于称为**主分片**的分片上。对于副本集的主副本，请不要误解这一点。这是一个分片（它本身可以是一个副本集），它是默认情况下为所有未启用分片的数据库和集合选择的分片。

当我们将数据添加到非分片集合时，它仅在主分片上显示。执行`sh.status()`告诉我们主碎片。要更改主进程，我们需要从连接到 mongos 进程的 shell 的管理数据库执行一个命令。命令如下：

```
db.runCommand({movePrimary:'<database whose primary shard is to be changed>', to:'<target shard>'})

```

一旦主分片被更改，所有非分片数据库和集合的现有数据将迁移到新的主，所有后续写入非分片集合的数据都将进入该分片。

请谨慎使用此命令，因为它会将所有未分片的集合迁移到新的主集合，这对于大型集合可能需要时间。

# 手动分割和迁移块

虽然 MongoDB 很好地在碎片之间分割和迁移区块，以保持平衡，但在一些情况下，例如少量文档或相对较大数量的小型文档，自动平衡器不会分割集合，管理员可能希望手动拆分和迁移块。在这个配方中，我们将看到如何在碎片之间手动拆分和迁移集合。对于此配方，我们将设置一个简单的碎片，如[第 1 章](01.html "Chapter 1. Installing and Starting the Server")、*安装和启动服务器*中所示。

## 准备好了吗

请参考[第一章](01.html "Chapter 1. Installing and Starting the Server")*安装并启动服务器*中的*启动两个碎片*的简单碎片化环境的配方，设置并启动碎片化环境。最好在没有任何数据的情况下启动一个干净的环境。从 shell 连接到已启动的 mongos 进程。

## 怎么做…

1.  从 mongo shell 连接到 mongos 进程，并在`test`数据库和`splitAndMoveTest`集合上启用分片，如下所示：

    ```
    > sh.enableSharding('test')
    > sh.shardCollection('test.splitAndMoveTest', {_id:1}, false)

    ```

2.  让我们按如下方式加载集合中的数据：

    ```
    > for(i = 1; i <= 10000 ; i++) db.splitAndMoveTest.insert({_id : i})

    ```

3.  Once the data is loaded, execute the following:

    ```
    > db. splitAndMoveTest.find().explain()

    ```

    请注意计划中两个碎片中的文档数。要查找的值位于解释计划结果中 shards 键下的两个文档中。在这两个文档中，要查找的字段是`n`。

4.  执行以下操作以查看集合的拆分：

    ```
    > config = db.getSisterDB('config')
    > config.chunks.find({ns:'test.splitAndMoveTest'}).pretty()

    ```

5.  在`5000`处将区块一分为二，如下所示：

    ```
    > sh.splitAt('test.splitAndMoveTest', {_id:5000})

    ```

6.  拆分它不会将其迁移到第二台服务器。通过再次执行以下查询，查看区块到底发生了什么：

    ```
    > config.chunks.find({ns:'test.splitAndMoveTest'}).pretty()

    ```

7.  我们现在将第二个块移动到第二个碎片：

    ```
    > sh.moveChunk('test.splitAndMoveTest', {_id:5001}, 'shard0001')

    ```

8.  再次执行以下查询并确认迁移：

    ```
    > config.chunks.find({ns:'test.splitAndMoveTest'}).pretty()

    ```

9.  或者，以下解释计划将显示大约 50-50 的分割：

    ```
    > db. splitAndMoveTest.find().explain()

    ```

## 它是如何工作的…

我们通过添加单调递增的数字来模拟一个小数据负载，并通过查看查询计划发现这些数字并没有均匀地分布在两个碎片上。这不是问题，因为在均衡器决定跨碎片迁移块以保持平衡之前，块大小需要达到特定的阈值（默认为 64 MB）。这在现实世界中是非常完美的，当数据量变得巨大时，我们将看到，经过一段时间，碎片最终会很好地平衡。

但是，如果管理部门确实决定拆分和迁移数据块，则可以手动执行。有两个助手函数`sh.splitAt`和`sh.moveChunk`来完成这项工作。让我们看看他们的签名，看看他们做了什么。

函数`sh.splitAt`有两个参数，第一个是名称空间，格式为`<database>.<collection name>`，第二个参数是作为分割点的查询，根据给定文档在区块中的位置将区块分割为两个，可能是两个不均匀的部分。还有另一种方法，`sh.splitFind`，它将尝试将区块分成两个相等的部分。

拆分并不意味着块移动到另一个碎片，它只是将一个大块拆分为两个，但数据保留在同一个碎片上。这是一个涉及更新配置数据库的廉价操作。

接下来，我们执行的是在将块分割成两块后将其迁移到另一块。操作`sh.MoveChunk`就是为了这样做。此函数接受三个参数，第一个参数是格式为`<database>.<collection name>`的集合的名称空间，第二个参数是将要迁移其区块的文档的查询，第三个参数是目标区块。

迁移完成后，查询的计划将向我们显示数据被分为两个块。

# 使用标签的域驱动分片

*启动两个碎片*和*连接到外壳中的碎片的简单碎片环境，并执行[第一章](01.html "Chapter 1. Installing and Starting the Server")中的*操作*安装和启动服务器*解释了如何启动一个简单的双服务器分片，然后在选择分片密钥后在集合中插入数据。分片的数据更具技术性，Mongo 通过将数据块分割成多个块，并跨块迁移数据块，从而将数据块保持在可管理的大小，从而使数据块分布均匀。但是，如果我们希望切分更加面向领域呢？假设我们有一个存储邮政地址的数据库，我们根据邮政编码进行切分，我们知道一个城市的邮政编码范围。我们可以做的是根据城市名称标记碎片服务器，添加碎片范围（邮政编码），并将该范围与标记关联。这样，我们就可以说明哪些服务器可以包含哪些城市的邮政地址。例如，我们知道孟买是人口最多的城市，地址数量将是巨大的，因此我们为孟买添加了两个碎片。另一方面，一块碎片应该足以应付普纳市的交通量。现在我们只标记一个碎片。在这个配方中，我们将看到如何使用标记感知切分来实现这个用例。如果描述令人困惑，不要担心，我们将看到如何实现刚才讨论的内容。

## 准备好了吗

有关如何启动简单碎片的信息，请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的配方*启动两个碎片*的简单碎片环境。然而，对于这个配方，我们将添加一个额外的碎片。现在，我们将启动三台 mongo 服务器，监听端口`27000`、`27001`和`27002`。同样，建议从一个干净的数据库开始。在本配方中，我们将使用集合`userAddress`来存储数据。

## 怎么做…

1.  假设我们有三个切分并正在运行，让我们执行以下命令：

    ```
    mongos> sh.addShardTag('shard0000', 'Mumbai')
    mongos> sh.addShardTag('shard0001', 'Mumbai')
    mongos> sh.addShardTag('shard0002', 'Pune')

    ```

2.  定义了标记后，让我们定义将映射到标记的 pin 码范围：

    ```
    mongos> sh.addTagRange('test.userAddress', {pincode:400001}, {pincode:400999}, 'Mumbai')
    mongos> sh.addTagRange('test.userAddress', {pincode:411001}, {pincode:411999}, 'Pune')

    ```

3.  为测试数据库和`userAddress`集合启用分片，如下所示：

    ```
    mongos> sh.enableSharding('test')
    mongos> sh.shardCollection('test.userAddress', {pincode:1})

    ```

4.  在`userAddress`集合中插入以下文件：

    ```
    mongos> db.userAddress.insert({_id:1, name: 'Varad', city: 'Pune', pincode: 411001})
    mongos> db.userAddress.insert({_id:2, name: 'Rajesh', city: 'Mumbai', pincode: 400067})
    mongos> db.userAddress.insert({_id:3, name: 'Ashish', city: 'Mumbai', pincode: 400101})

    ```

5.  执行以下计划：

    ```
    mongos> db.userAddress.find({city:'Pune'}).explain()
    mongos> db.userAddress.find({city:'Mumbai'}).explain()

    ```

## 它是如何工作的…

假设我们想在一个分片中划分由域驱动的数据，我们可以使用标记感知分片。这是一种非常好的机制，它允许我们标记碎片，然后在由标记标识的碎片之间分割数据范围。我们真的不必担心实际的机器和它们承载碎片的地址。标签作为一种很好的抽象，我们可以用多个标签标记一个碎片，一个标签可以应用于多个碎片。

在我们的例子中，我们有三个碎片，我们使用`sh.addShardTag`方法对每个碎片应用标记。该方法获取 shard ID，我们可以在使用*shard*键的`sh.status`调用中看到。此`sh.addShardTag`方法可用于不断向碎片添加标签。类似地，有一个助手方法`sh.removeShardTag`从碎片中删除标记的分配。这两种方法都有两个参数，第一个是 shard ID，第二个是要删除的标记。

标记完成后，我们将碎片键的值范围指定给标记。方法`sh.addTagRange`用于实现这一点。它接受四个参数，第一个是名称空间，它是集合的完全限定名，第二个和第三个参数是此碎片键范围的起始值和结束值，第四个参数是承载所添加范围的碎片的标记名。例如，调用`sh.addTagRange('test.userAddress', {pincode:400001}, {pincode:400999}, 'Mumbai')`表示我们正在为集合`test.userAddress`将碎片范围`400001`添加到`400999`，该范围将存储在标记为`Mumbai`的碎片中。

完成标记和添加标记范围后，我们在数据库上启用分片，并使用各自的 pin 码收集和添加来自孟买和浦那市的数据。然后，我们查询并解释该计划，以确保数据确实存在于我们为浦那和孟买市标记的碎片上。我们还可以向这个分片设置添加新的分片，并相应地标记新的分片。然后，平衡器将根据标记的值相应地平衡数据。例如，如果 Pune 中的地址增加了对碎片的重载，我们可以添加一个新的碎片，标记为 Pune。然后，Pune 的邮政地址将在这两个服务器实例上分片，以便标记 Pune city。

# 在分片设置中探索配置数据库

配置数据库是 Mongo 中分片设置的主干。它存储碎片设置的所有元数据，并为其运行一个专用的 mongod进程。当 mongos 进程启动时，我们为其提供配置服务器的 URL。在本食谱中，我们将查看配置数据库中的一些集合，并深入了解它们的内容和意义。

## 准备好了吗

我们需要一个切分的设置为这个食谱。有关如何启动简单碎片的信息，请参阅[第 1 章](01.html "Chapter 1. Installing and Starting the Server")*安装和启动服务器*中的配方*启动两个碎片*的简单碎片环境。另外，从 shell 连接到 mongos 进程。

## 怎么做…

1.  从连接到 mongos 进程的控制台，切换到配置数据库并执行以下操作：

    ```
    mongos> use config
    mongos>show collections

    ```

2.  从所有收藏的列表中，我们将访问一些。我们从数据库集合开始。这将跟踪此碎片上的所有数据库。从 shell 执行以下操作：

    ```
    mongos> db.databases.find()

    ```

3.  结果的内容非常简单，`_id`字段的值用于数据库。字段 partitioned 的值告诉我们是否为数据库启用了分片；true 表示已启用，并且 primary 字段提供非分片集合的数据所在的主分片。
4.  Next, we will visit the `collections` collection. Execute the following from the shell:

    ```
    mongos> db.collections.find().pretty()

    ```

    与我们前面看到的数据库集合不同，此集合只包含我们已启用分片的集合。字段`_id`以`<database>.<collection name>`格式给出集合的名称空间，字段键给出分片键，字段唯一，表示分片键是否唯一。这三个字段按此顺序作为`sh.shardCollection`函数的三个参数。

5.  接下来，我们来看看`chunks`系列。在 shell 上执行以下操作。如果我们开始这个配方时数据库是干净的，我们就不会有太多的数据：

    ```
    mongos> db.chunks.find().pretty()

    ```

6.  然后，我们查看标签集合并执行以下查询：

    ```
    mongos> db.tags.find().pretty()

    ```

7.  Let's query the mongos collection as follows.

    ```
    mongos> db.mongos.find().pretty()

    ```

    这是一个简单的集合，提供了连接到碎片的所有 mongos 实例的列表，其中包含了诸如运行 mongos 实例的主机和端口等详细信息，这构成了`_id`字段。版本和数字显示进程启动和运行的时间（秒）。

8.  最后，我们看一下版本集合。执行以下查询。请注意，这与我们执行的其他查询不同：

    ```
    mongos>db.getCollection('version').findOne()

    ```

## 它是如何工作的…

我们在查询时看到了集合和数据库集合，它们非常简单。让我们看看名为`chunks`的收藏。以下是此集合中的示例文档：

```
{
        "_id" : "test.userAddress-pincode_400001.0",
        "lastmod" : Timestamp(1, 3),
        "lastmodEpoch" : ObjectId("53026514c902396300fd4812"),
        "ns" : "test.userAddress",
        "min" : {
                "pincode" : 400001
        },
        "max" : {
                "pincode" : 411001
        },
        "shard" : "shard0000"
}
```

感兴趣的字段是`ns`、`min`、`max`和`shard`，它们分别是集合的名称空间、区块中存在的最小值、区块中存在的最大值以及该区块所在的碎片。默认情况下，区块大小的值为 64 MB。这可以在设置集合中看到。从 shell 中执行`db.settings.find()`并查看字段值的值，该值是块的大小（以 MB 为单位）。如果需要的话，块被限制在如此小的大小，以简化跨碎片的迁移过程。当区块大小超过此阈值时，mongo server 会在现有区块中找到一个合适的点，将其分成两部分，并在此区块集合中添加一个新条目。这种操作称为拆分，因为数据保持在原来的位置，所以成本较低；它只是在逻辑上分为多个块。mongo 上的均衡器试图保持碎片之间的块平衡，一旦发现不平衡，它就会将这些块迁移到不同的碎片。这很昂贵，而且很大程度上取决于网络带宽。如果我们使用`sh.status()`，该实现实际上会查询我们看到的集合，并打印格式良好的结果。