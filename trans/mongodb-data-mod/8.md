# 第 8 章使用 MongoDB 进行日志记录和实时分析

在这本书中，许多你已经知道的概念被呈现给你。您已经学会了如何将它们与 MongoDB 提供给我们的技术和工具结合使用。本章的目的是将这些技术应用于实际示例中。

我们将在本章中开发的实际示例解释了如何使用 MongoDB 作为 web 服务器日志数据的持久存储—更具体地说，是来自 Nginx web 服务器的数据。通过这样做，我们将能够分析 web 应用程序的流量数据。

我们将从分析 Nginx 日志格式开始本章，以定义对我们的实验有用的信息。在此之后，我们将定义要在 MongoDB 中执行的分析类型。最后，我们将设计我们的数据库模式，并使用代码在 MongoDB 中读写数据。

在本章中，我们将考虑生成此事件的每个主机都会使用此信息并将其发送到 MongoDB。我们的重点不会放在应用程序的体系结构上，也不会放在示例中生成的代码上。所以，善良的读者，如果您不同意这里显示的代码片段，请随意修改它们或自己创建一个新的。

尽管如此，本章将涵盖：

*   测井数据分析
*   我们在找什么
*   设计模式

# 测井资料分析

访问日志通常被开发人员、系统管理员或任何在 web 上保留服务的人忽略。但是，当我们需要及时反馈 web 服务器上每个请求发生的情况时，它是一个强大的工具。

访问日志保存有关服务器活动和性能的信息，并告诉我们最终的问题。目前最常见的 web 服务器是 ApacheHTTPD 和 Nginx。默认情况下，这些 web 服务器有两种日志类型：错误日志和访问日志。

## 错误日志

顾名思义，错误日志是 web 服务器存储在处理收到的请求过程中发现的错误的地方。通常，此类日志是可配置的，并将根据预定义的严重性级别写入消息。

## 访问日志

访问日志存储所有接收和处理的请求。这将是我们研究的主要对象。

文件中写入的事件记录在预定义的布局中，该布局可以根据管理服务器的人员的意愿进行格式化。默认情况下，apachehttpd 和 Nginx 都有一种称为**合并**的格式。以这种格式生成的日志示例如下所示：

```js
191.32.254.162 - - [29/Mar/2015:16:04:08 -0400] "GET /admin HTTP/1.1" 200 2529 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.104 Safari/537.36"

```

乍一看，在一行日志中看到太多的信息可能有点可怕。但是，如果我们查看一下为生成此日志而应用的模式，并尝试对其进行检查，我们会发现它并不难理解。

在 Nginx web 服务器上生成该行的模式如下所示：

```js
$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent"

```

我们将描述此模式的每个部分，以便您更好地理解：

*   `$remote_addr`：在 web 服务器上执行请求的客户端的 IP 地址。在我们的示例中，该值对应于 191.32.254.162。
*   `$remote_user`：这是经过身份验证的用户，如果存在的话。当未识别经过身份验证的用户时，此字段将用连字符填充。在我们的示例中，值为`-`。
*   `[$time_local]`：这是在 web 服务器上以格式`[day/month/year:hour:minute:second zone]`接收请求的时间。
*   `"$request"`：这是客户端请求本身。也称为请求行。为了更好地理解，我们将分析示例中的请求行：`"GET /admin HTTP/1.1"`。首先，我们有客户端使用的 HTTP 谓词。在本例中，它是一个`GET`HTTP 动词。在序列中，我们让客户端访问资源。在本例中，访问的资源是`/admin`。最后，我们有客户端使用的协议。在本例中，`HTTP/1.1`。
*   `$status`: This is the HTTP status code replied to the client by the web server. The possible values for this field are defined in RFC 2616\. In our example, the web server returns the status code `200` to the client.

    ### 注

    欲了解更多关于 RFC 2616 的信息，请访问[http://www.w3.org/Protocols/rfc2616/rfc2616.txt](http://www.w3.org/Protocols/rfc2616/rfc2616.txt) 。

*   `$body_bytes_sent`：发送给客户端的响应体的字节长度。当没有正文时，该值将是连字符。我们必须注意，该值不包括请求头。在我们的示例中，值为 2529 字节。
*   `"$http_referer"`：此是客户端请求的头“Referer”中包含的值。此值表示从何处引用请求的资源。直接执行资源访问时，此字段用连字符填充。在我们的示例中，值为`-`。
*   `"$http_user_agent"`：客户端在用户代理头中发送的信息。通常，我们可以在这个标题中识别请求中使用的 web 浏览器。在我们的示例中，此字段的值为`"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.104 Safari/537.36"`。

除此之外，我们还有更多的变量可用于创建新的日志格式。其中，我们强调：

*   `$request_time`：此表示请求处理的总时间
*   `$request_length`：表示客户端响应的总长度，包括头

现在我们已经熟悉了 web 服务器访问日志，我们将定义要分析的内容，以便了解需要记录哪些信息。

# 我们在寻找什么

从 web 服务器访问日志中提取的信息非常丰富，为我们提供了研究无限可能性的好材料。简单而直接，只需计算访问日志的行数，就可以计算我们的 web 服务器接收到的请求数。但是我们可以扩展我们的分析，并尝试测量一段时间内数据流量的平均值（以字节为单位）。

最近，应用最广泛的服务之一是应用程序性能管理系统，也称为**APMs**。如今，这些服务通常以软件即服务的形式提供，其主要目标是让我们了解应用程序的性能和运行状况。

APMs是基于从访问日志中提取的信息进行分析的一个很好的例子，因为 APMs 生成的大部分信息都基于访问日志。

注意我并不是说 APM 仅基于访问日志工作，而是 APM 生成的大部分信息可以从访问日志中提取。可以

### 注

欲了解更多信息，请访问[https://en.wikipedia.org/wiki/Application_performance_management](https://en.wikipedia.org/wiki/Application_performance_management) 。

如本章开头所述，我们无意编码或创建整个系统，但我们将在实践中展示如何保存访问日志信息，以便使用 MongoDB 进行最终分析。

基于 APMs，我们将在分析 web 服务器资源吞吐量的基础上构建我们的示例。只能使用 web 服务器访问日志中包含的信息执行此分析。为此，我们需要访问日志中的哪些数据？我们应该使用组合格式吗？

## 测量 web 服务器上的流量

我们的 web 服务器中的吞吐量将根据给定时间段内的请求数进行估算，即一天、一小时、一分钟或一秒钟内的请求数。每分钟的请求数是实时监视的一个非常合理的度量。

吞吐量是通过计算 web 服务器中处理的请求来计算的。因此，不必使用访问日志中的特定数据。然而，为了能够对数据进行更丰富的进一步分析，我们将创建一种特定的日志格式，用于收集请求信息，如 HTTP 状态代码、请求时间和长度。

ApacheHTTP 和 Nginx 都允许我们自定义访问日志或创建具有自定义格式的新文件。第二种选择似乎是完美的。在开始配置 web 服务器之前，我们将使用前面解释的变量创建日志格式。请记住，我们正在使用 nginxweb 服务器。

```js
$remote_addr [$time_local] "$request" $status $request_time $request_length

```

当我们定义日志格式时，我们可以配置我们的 Nginx web 服务器。为此，让我们执行以下步骤：

1.  首先，要在 Nginx 中定义这个新的格式，我们需要编辑`nginx.conf`文件，在 HTTP 元素中添加一个新的条目，使用新的日志格式：

    ```js
    log_format custom_format '$remote_addr [$time_local] "$request" $status $request_time $request_length';
    ```

2.  现在我们需要在`nginx.conf`文件中添加另一个条目，该条目定义新的自定义日志将写入哪个文件：

    ```js
    access_log /var/log/nginx/custom_access.log custom_format;
    ```

3.  要应用我们的更改，请在终端中执行以下命令重新加载 Nginx web 服务器：

    ```js
    /usr/sbin/nginx reload

    ```

4.  在重新加载 Nginx 服务器之后，我们可以查看我们的新日志文件`/var/log/nginx/custom_access.log`，并检查这些行是否与以下行类似：

    ```js
    191.32.254.162 [29/Mar/2015:18:35:26 -0400] "GET / HTTP/1.1" 200 0.755 802
    ```

配置日志格式，设置 web 服务器；是时候设计我们的模式了。

# 设计方案

在这本书中反复提到的一点是，了解我们的数据及其用途非常重要。现在，在这个实践练习中，我们将一步一步地设计我们的模式，考虑其中涉及的每一个细节。

在上一节中，我们定义了要从 web 服务器访问日志中提取的数据集。下一步是列出与数据库客户机关联的需求。如前所述，一个进程将负责从日志文件中捕获信息并将其写入 MongoDB，另一个进程将读取数据库中已经保存的信息。

在 MongoDB 中编写文档时的性能是一个值得关注的问题，因为确保几乎实时生成信息非常重要。由于我们之前没有对每秒数据量的估计，因此我们将持乐观态度。让我们考虑一下，从 Web 服务器到我们的 MunGDB 实例，我们将一直拥有大量的数据。

考虑到这一要求，我们将担心数据维度会随着时间的推移而增加。更多事件意味着将插入更多文档。这些是我们的系统运行良好的主要要求。

乍一看，我们可以想象这一切都是关于定义文档格式并将其持久化到集合中。但这种想法忽略了众所周知的 MongoDB 模式灵活性。因此，我们将分析吞吐量问题，以定义在何处以及如何持久化信息。

## 捕获事件请求

web服务器吞吐量分析可能是最简单的任务。通过一种简单的方式，事件数量的度量将为我们提供一个表示 web 服务器吞吐量的数字。

因此，如果为每个生成的事件执行一个写文档，说明此操作的时间，这是否意味着我们可以轻松获得吞吐量？对因此，表示 MongoDB 文档并分析吞吐量的最简单方法如下：

```js
{

 "_id" : ObjectId("5518ce5c322fa17f4243f85f"),
 "request_line" : "191.32.254.162 [29/Mar/2015:18:35:26 -0400] \"GET /media/catalog/product/img/2.jpg HTTP/1.1\" 200 0.000 867"

}

```

在文档集合中执行`count`方法时，我们将获得 web 服务器的吞吐量值。假设我们有一个名为`events`的集合，为了了解吞吐量，我们必须在 mongod shell 中执行以下命令：

```js
db.events.find({}).count()

```

此命令返回到目前为止在 web 服务器上生成的事件总数。但是，这是我们想要的号码吗？不。如果不将事件总数放在给定的时间段内，那么确定事件总数是没有意义的。到目前为止，web 服务器处理 10000 个事件，而不知道我们什么时候开始记录这些事件，甚至不知道最后一个事件是什么时候生成的，这有什么用呢？

如果我们想要统计给定时间段内的事件，最简单的方法是包含一个表示事件创建日期的字段。本文件的示例如下所示：

```js
{

 "_id" : ObjectId("5518ce5c322fa17f4243f85f"),
 "request_line" : "191.32.254.162 [29/Mar/2015:18:35:26 -0400] \"GET /media/catalog/product/img/2.jpg HTTP/1.1\" 0.000 867",
 "date_created" : ISODate("2015-03-30T04:17:32.246Z")

}

```

因此，我们可以通过执行查询来检查给定时间段内 web 服务器中的请求总数。执行此查询的最简单方法是使用聚合框架。在 mongod shell 上执行以下命令将返回每分钟的请求总数：

```js
db.events.aggregate(
{
 $group: {
 _id: {
 request_time: {
 month: {
 $month: "$date_created"
 },
 day: {
 $dayOfMonth: "$date_created"
 },
 year: {
 $year: "$date_created"
 },
 hour: {
 $hour: "$date_created"
 },
 min: {
 $minute: "$date_created"
 }
 }
 },
 count: {
 $sum: 1
 }
 }
})

```

### 注

聚合管道有其局限性。如果命令结果返回的单个文档超过 BSON 文档大小，则会产生错误。自从 MongoDB 的 2.6 版本发布以来，`aggregate`命令返回一个游标，因此它可以返回任意大小的结果集。

您可以在[的 MongoDB 参考手册中找到更多关于聚合管道限制的信息 http://docs.mongodb.org/manual/core/aggregation-pipeline-limits/](http://docs.mongodb.org/manual/core/aggregation-pipeline-limits/) 。

在命令管道中，我们定义了`$group`阶段，将文档按天、月、年、小时和分钟进行分组。我们使用`$sum`操作符计算所有内容。从这个`aggregate`命令的执行中，我们将有如下文档作为示例：

```js
{
 "_id": {
 "request_time": {
 "month": 3,
 "day": 30,
 "year": 2015,
 "hour": 4,
 "min": 48
 }
 },
 "count": 50
}
{
 "_id": {
 "request_time": {
 "month": 3,
 "day": 30,
 "year": 2015,
 "hour": 4,
 "min": 38
 }
 },
 "count": 13
}
{
 "_id": {
 "request_time": {
 "month": 3,
 "day": 30,
 "year": 2015,
 "hour": 4,
 "min": 17
 }
 },
 "count": 26
}

```

在这个输出中，可以知道web 服务器在某个时间段内收到了多少请求。这是由于`$group`操作符的行为导致的，该行为获取与查询匹配的文档，然后根据一个或多个字段收集文档组。我们将`$date_created`字段的每个部分，例如月、日、年、小时和分钟，都带到聚合管道的组阶段。

如果您想知道在吞吐量较高的 web 服务器中，哪个资源访问频率最高，那么这些选项都不适合此请求。然而，很容易找到这个问题的快速解决方案。乍一看，最快的方法是解构事件并创建更复杂的文档，如以下示例所示：

```js
{
 "_id" : ObjectId("5519baca82d8285709606ce9"),
 "remote_address" : "191.32.254.162",
 "date_created" : ISODate("2015-03-29T18:35:25Z"),
 "http_method" : "GET",
 "resource" : "/media/catalog/product/cache/1/img/200x267/9df78eab33525d08d6e5fb8d27136e95/2/_/2.jpg",
 "http_version" : "HTTP/1.1",
 "status": 200,
 "request_time" : 0,
 "request_length" : 867
}

```

通过使用此文档设计，可以借助聚合框架了解每分钟的资源吞吐量：

```js
db.events.aggregate([
 {
 $group: {
 _id: "$resource",
 hits: {
 $sum: 1
 }
 }
 },
 {
 $project: {
 _id: 0,
 resource: "$_id",
 throughput: {
 $divide: [
 "$hits",
 1440
 ]
 }
 }
 },
 {
 $sort: {
 throughput: -1
 }
 }
])

```

在前面的管道中，第一步是根据资源进行分组，并计算一天中对该资源的请求发生了多少次。下一步是使用操作符`$project`并与操作符`$divide`一起使用给定资源中的点击数，并通过除以 1440 分钟计算每分钟的平均值，即一天或 24 小时内的总分钟数。最后，我们将结果按降序排列，以查看哪些资源具有更高的吞吐量。

为了保持清楚，我们将一步一步地执行管道，并解释每个步骤的结果。在第一阶段的执行过程中，我们有以下几点：

```js
db.events.aggregate([{$group: {_id: "$resource", hits: {$sum: 1}}}])

```

此执行按字段资源对事件收集文档进行分组，并统计使用值为`1`的运算符`$sum`时字段命中的出现次数。返回的结果如下所示：

```js
{ "_id" : "/", "hits" : 5201 }
{ "_id" : "/legal/faq", "hits" : 1332 }
{ "_id" : "/legal/terms", "hits" : 3512 }

```

在管道的第二阶段，我们使用操作符`$project`，它将为我们提供每分钟点击次数的值：

```js
db.documents.aggregate([
 {
 $group: {
 _id: "$resource",
 hits: {
 $sum: 1
 }
 }
 },
 {
 $project: {
 _id: 0,
 resource: "$_id",
 throughput: {
 $divide: [
 "$hits",
 1440
 ]
 }
 }
 }
])

```

以下是本阶段的结果：

```js
{ "resource" : "/", "throughput" : 3.6118055555555557 }
{ "resource" : "/legal/faq", "throughput" : 0.925 }
{ "resource" : "/legal/terms", "throughput" : 2.438888888888889 }

```

管道的最后一个阶段是按吞吐量降序排列结果：

```js
db.documents.aggregate([
 {
 $group: {
 _id: "$resource",
 hits: {
 $sum: 1
 }
 }
 },
 {
 $project: {
 _id: 0,
 resource: "$_id",
 throughput: {
 $divide: [
 "$hits",
 1440
 ]
 }
 }
 },
 {
 $sort: {
 throughput: -1
 }
 }
])

```

产生的输出如下：

```js
{ "resource" : "/", "throughput" : 3.6118055555555557 }
{ "resource" : "/legal/terms", "throughput" : 2.438888888888889 }
{ "resource" : "/legal/faq", "throughput" : 0.925 }

```

看起来我们成功地为我们的文档获得了一个好的设计。现在我们可以提取所需的分析和其他分析，我们将进一步了解，出于这个原因，我们现在可以停止。错误的我们将审查我们的需求，将它们与我们设计的模型进行比较，并尝试找出它是否是最佳解决方案。

我们希望了解所有 web 服务器资源每分钟吞吐量的度量。在我们设计的模型中，在 web 服务器中为每个事件创建一个文档，通过使用聚合框架，我们可以计算分析所需的信息。

此解决方案可能有什么问题？好吧，如果你认为这是收藏文件的数量，你是对的。根据 web 服务器流量，每个事件一个文档可以生成大量集合。显然，我们可以采用使用碎片的策略，并通过许多主机分发集合。但首先，我们将看到如何利用 MongoDB 中的模式灵活性来减少集合大小和优化查询。

## 单文档解决方案

如果我们认为我们有大量的信息来胡分析，那么每一个事件的一个文档可能是有利的。但在我们试图解决的示例中，为每个 HTTP 请求保存一个文档的成本很高。

我们将利用 MongoDB 中的模式灵活性，这将帮助我们随着时间的推移增加文档。以下建议的主要目标是减少持久化文档的数量，同时优化集合中读写操作的查询。

我们正在寻找的文档应该能够为我们提供所需的所有信息，以便了解每分钟请求的资源吞吐量；因此，我们可以有一个具有以下结构的文档：

*   包含资源的字段
*   带有事件日期的字段
*   包含事件发生的分钟数和总点击数的字段

以下文件实现了上述列表中描述的所有要求：

```js
{
 "_id" : ObjectId("552005f5e2202a2f6001d7b0"),
 "resource" : "/",
 "date" : ISODate("2015-05-02T03:00:00Z"),
 "daily" : 215840,
 "minute" : {
 "0" : 90,

 "1" : 150,
 "2" : 143,
 ...
 "1349": 210
 }
}

```

通过这种文档设计，我们可以检索每分钟在特定资源中发生的事件数。我们还可以通过 daily 字段知道一天中的总请求，并使用它来计算我们想要的任何内容，例如每分钟的请求或每小时的请求。

为了演示我们可以在这个集合上进行的写和读操作，我们将使用 Node.js 平台上运行的 JavaScript 代码。因此，在继续之前，我们必须确保机器上安装了 Node.js。

### 注

如果您需要帮助，您可以在[找到更多信息 http://nodejs.org](http://nodejs.org) 。

我们应该做的第一件事是创建一个应用程序所在的目录。在终端中，执行以下命令：

```js
mkdir throughput_project

```

接下来，我们导航到我们创建的目录并启动项目：

```js
cd throughput_project
npm init

```

回答向导提出的所有问题，以创建新项目的初始结构。目前，我们将有一个基于我们给出的答案的`package.json`文件。

下一步是为我们的项目设置 MongoDB 驱动程序。我们可以通过编辑`package.json`文件（包括其依赖项的驱动程序引用）或执行以下命令来完成此操作：

```js
npm install mongodb --save

```

前面的命令将为我们的项目安装 MongoDB 驱动程序，并将引用保存在`package.json`文件中。我们的文件应该如下所示：

```js
{
  "name": "throughput_project",
  "version": "1.0.0",
  "description": "",
  "main": "app.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "Wilson da Rocha França",
  "license": "ISC",
  "dependencies": {
    "mongodb": "^2.0.25"
  }
}
```

最后一步是使用示例代码创建`app.js`文件。以下是示例代码，它向我们展示了如何计算 web 服务器上的事件并将其记录在我们的集合中：

```js
var fs = require('fs');
var util = require('util');
var mongo = require('mongodb').MongoClient;
var assert = require('assert');

// Connection URL
var url = 'mongodb://127.0.0.1:27017/monitoring;
// Create the date object and set hours, minutes,
// seconds and milliseconds to 00:00:00.000
var today = new Date();
today.setHours(0, 0, 0, 0);

var logDailyHit = function(db, resource, callback){
 // Get the events collection
  var collection = db.collection('events');
 // Update daily stats
  collection.update({resource: resource, date: today},
    {$inc : {daily: 1}}, {upsert: true},
    function(error, result){
      assert.equal(error, null);
      assert.equal(1, result.result.n);
      console.log("Daily Hit logged");
      callback(result);
  });
}

var logMinuteHit = function(db, resource, callback) {
 // Get the events collection
  var collection = db.collection('events');
 // Get current minute to update
  var currentDate = new Date();
  var minute = currentDate.getMinutes();
  var hour = currentDate.getHours();
 // We calculate the minute of the day
  var minuteOfDay = minute + (hour * 60);
  var minuteField = util.format('minute.%s', minuteOfDay);
 // Create a update object
  var update = {};
  var inc = {};
  inc[minuteField] = 1;
  update['$inc'] = inc;

 // Update minute stats
  collection.update({resource: resource, date: today},
    update, {upsert: true}, function(error, result){
      assert.equal(error, null);
      assert.equal(1, result.result.n);
      console.log("Minute Hit logged");
      callback(result);
  });
}

// Connect to MongoDB and log
mongo.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log("Connected to server");
  var resource = "/";
  logDailyHit(db, resource, function() {
    logMinuteHit(db, resource, function(){
      db.close();
      console.log("Disconnected from server")
      });
    });
});
```

前面的示例代码非常简单。其中我们有`logDailyHit`功能，负责记录一个事件并在文档`daily`字段中增加一个单位。第二个功能是`logMinuteHit`功能，它负责记录事件的发生，并递增表示当天当前分钟数的文档`minute`字段。这两个函数都有一个更新查询，如果文档不存在，则该查询的`upsert`选项的值为`true`，在这种情况下，将创建该文档。

当我们执行以下命令时，我们将在资源`"/"`上记录一个事件。要运行代码，只需导航到项目目录并执行以下命令：

```js
node app.js

```

如果一切正常，我们应该在运行命令后看到以下输出：

```js
Connected to server
Daily Hit logged
Minute Hit logged
Disconnected from server

```

为了了解这一点，我们将在 mongod shell 上执行一个`findOne`命令，并观察结果：

```js
db.events.findOne()
{
 "_id" : ObjectId("5520ade00175e1fb3361b860"),
 "resource" : "/",
 "date" : ISODate("2015-04-04T03:00:00Z"),
 "daily" : 383,
 "minute" : {
 "0" : 90,
 "1" : 150,
 "2" : 143
 }
}

```

除了以前的模型能给我们提供的一切之外，这个模型比它们有一些优势。我们注意到的第一件事是，每次我们注册 web 服务器上发生的新事件时，我们只会操作一个文档。第二个优势还在于，在给定特定资源的情况下，我们可以多么容易地找到正在查找的信息，因为我们在一个文档中有一整天的信息，这将导致我们在每个查询中操作的文档更少。

当我们思考报告时，这种模式设计处理时间的方式将给我们带来许多好处。可以从该集合中轻松提取文本和图形表示，以进行历史或实时分析。

然而，与前面的方法一样，我们还必须处理一些限制。正如我们所看到的，当事件文档中的`daily`字段和`minute`字段出现在 web 服务器上时，我们会增加它们。当当天没有报告资源中的事件时，将创建一个新文档，因为我们在更新查询中使用了`upsert`选项。如果资源在给定分钟内第一次发生事件，`$inc`操作员将创建新的`minute`字段并将`"1"`设置为值，同样的情况也会发生。这意味着我们的文档将随着时间的推移而增长，并将超过最初分配给它的 MongoDB 大小。每当分配给文档的空间已满时，MongoDB 都会自动执行重新分配操作。这种整天都在进行的重新分配操作对数据库的性能有直接影响。

我们该怎么办？接受它？不可以。我们可以通过添加一个为文档预先分配空间的进程来减少重新分配操作的影响。总之，我们将让应用程序负责创建一个包含一天中所有分钟数的文档，并使用值 `0`初始化每个字段。通过这样做，我们将避免 MongoDB 在白天进行过多的重新分配操作。

### 注

要了解有关记录分配策略的更多信息，请访问位于[的 MongoDB 参考用户手册 http://docs.mongodb.org/manual/core/storage/#record-分配策略](http://docs.mongodb.org/manual/core/storage/#record-allocation-strategies)。

为了举例说明如何预先分配文档空间，我们可以在`app.js`文件中创建一个新函数：

```js
var fs = require('fs');
var util = require('util');
var mongo = require('mongodb').MongoClient;
var assert = require('assert');

// Connection URL
var url = 'mongodb://127.0.0.1:27017/monitoring';

var preAllocate = function(db, resource, callback){
 // Get the events collection
 var collection = db.collection('events');
 var now = new Date();
 now.setHours(0,0,0,0);
 // Create the minute document
 var minuteDoc = {};
 for(i = 0; i < 1440; i++){
 minuteDoc[i] = 0;
 }
 // Update minute stats
 collection.update(
 {resource: resource,
 date: now,
 daily: 0},
 {$set: {minute: minuteDoc}},
 {upsert: true}, function(error, result){
 assert.equal(error, null);
 assert.equal(1, result.result.n);
 console.log("Pre-allocated successfully!");
 callback(result);
 });
}

// Connect to MongoDB and log
mongo.connect(url, function(err, db) {
 assert.equal(null, err);
 console.log("Connected to server");
 var resource = "/";
 preAllocate(db, resource, function(){
 db.close();
 console.log("Disconnected from server")
 });
});

```

### 提示

**下载示例代码**

您可以从您的账户[下载示例代码文件 http://www.packtpub.com](http://www.packtpub.com) 对于您购买的所有 Packt 出版书籍。如果您在其他地方购买了本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support) 并注册，将文件直接通过电子邮件发送给您。

要将当前日期的空间预分配给`"/"`资源，只需运行以下命令：

```js
node app.js

```

执行的输出如下所示：

```js
Connected to server
Pre-allocated successfully!
Disconnected from server

```

我们可以在 mongod shell 上运行`findOne`命令来检查新文档。创建的文档非常长，因此我们将只显示其中的一部分：

```js
db.events.findOne();
{
 "_id" : ObjectId("551fd893eb6efdc4e71260a0"),
 "daily" : 0,
 "date" : ISODate("2015-04-06T03:00:00Z"),
 "resource" : "/",
 "minute" : {
 "0" : 0,
 "1" : 0,
 "2" : 0,
 "3" : 0,
 ...
 "1439" : 0,
 }
}

```

建议我们在午夜前预先分配文档，以确保应用程序的顺利运行。如果我们计划在适当的安全裕度下创建此文档，那么我们不会在午夜之后为事件事件创建文档。

好的，随着重新分配问题的解决，我们可以回到引发文档重新设计的问题：数据的增长。

即使将集合中的文档数量减少到每天每个事件一个文档，我们仍然可能遇到存储空间问题。当 web 服务器上接收事件的资源太多，并且无法预测应用程序生命周期中将有多少新资源时，就会发生这种情况。为了解决这个问题，我们将使用两种不同的技术：TTL 索引和分片。

## TTL 指标

并非总是需要将所有日志信息永久存储在服务器上。限制存储在磁盘上的文件数量已成为操作人员的标准做法。

通过同样的推理，我们可以限制收藏中需要的文档数量。为了实现这一点，我们可以在`date`字段上创建一个 TTL 索引，指定一个文档在集合中的存在时间。只要记住，一旦我们创建了 TTL 索引，MongoDB 就会自动从集合中删除过期的文档。

假设事件命中信息仅在一年内有用。我们将在`date`字段上创建一个索引，属性为`expireAfterSeconds`，值为`31556926`，对应于以秒为单位的一年。

在 mongod shell 上执行的以下命令在事件集合上创建索引：

```js
db.monitoring.createIndex({date: 1}, {expireAfterSeconds: 31556926})

```

如果索引不存在，则输出应如下所示：

```js
{
 "createdCollectionAutomatically" : false,
 "numIndexesBefore" : 1,
 "numIndexesAfter" : 2,
 "ok" : 1
}

```

完成后，我们的文档将根据日期字段在我们的集合中保留一年，之后 MongoDB 将自动删除它们。

## 切分

如果你是那种拥有无限资源并希望将大量信息存储在磁盘上的人，那么缓解存储空间问题的一个解决方案就是通过对收集的数据进行分片来分发数据。

而且，如前所述，我们在选择碎片密钥时应该加大力度，因为通过碎片密钥，我们将保证读写操作将由碎片平均分配，也就是说，一个查询将针对集群上的单个碎片或几个碎片。

一旦我们完全控制了 web 服务器上有多少资源（或页面）以及这个数字将如何增长或减少，资源名称就成了碎片密钥的好选择。但是，如果我们有一个比其他资源具有更多请求（或事件）的资源，那么我们将有一个将过载的碎片。为了避免这种情况，我们将包含 date 字段来组成 shard 键，这也将在条件中包含该字段的查询执行中提供更好的性能。

记住：我们的目标不是解释分片集群的设置。考虑到您之前创建了切分集群，我们将向您展示切分集合的命令。

要使用我们选择的 shard 键切分事件集合，我们将在 mongos shell 上执行以下命令：

```js
mongos> sh.shardCollection("monitoring.events", {resource: 1, date: 1})

```

预期产出为：

```js
{ "collectionsharded" : "monitoring.events", "ok" : 1 }

```

### 提示

如果我们的 events 集合中有任何文档，那么在对集合进行分片之前，我们需要创建一个索引，其中分片键是前缀。要创建索引，请执行以下命令：

```js
db.monitoring.createIndex({resource: 1, date: 1})
```

通过启用碎片的集合，我们将有更多的容量在事件集合中存储数据，并且随着数据的增长，性能可能会提高。

既然我们已经设计了文档并准备好了收集大量数据的集合，那么让我们执行一些查询吧！

## 报表查询

到目前为止，我们一直致力于将数据存储在数据库中。这并不意味着我们不关心读操作。我们所做的一切都是通过概述我们的应用程序的概要文件，并尝试覆盖所有的需求来准备我们的数据库。

因此，我们现在将说明我们必须查询集合的一些可能性，以便基于存储的数据构建报告。

如果我们需要的是关于资源总点击量的实时信息，我们可以使用 daily 字段来查询数据。使用此字段，我们可以确定一天中特定时间对资源的总点击量，甚至可以根据一天中的分钟数确定每分钟对资源的平均请求数。

为了根据一天中的当前时间查询总点击量，我们将创建一个名为`getCurrentDayhits`的新函数，为了查询一天中每分钟的平均请求量，我们将在`app.js`文件中创建`getCurrentMinuteStats`函数：

```js
var fs = require('fs');
var util = require('util');
var mongo = require('mongodb').MongoClient;
var assert = require('assert');

// Connection URL
var url = 'mongodb://127.0.0.1:27017/monitoring';

var getCurrentDayhitStats = function(db, resource, callback){
 // Get the events collection
  var collection = db.collection('events');
  var now = new Date();
  now.setHours(0,0,0,0);
  collection.findOne({resource: "/", date: now},
    {daily: 1}, function(err, doc) {
    assert.equal(err, null);
    console.log("Document found.");
    console.dir(doc);
    callback(doc);
  });
}

var getCurrentMinuteStats = function(db, resource, callback){
 // Get the events collection
  var collection = db.collection('events');
  var now = new Date();
 // get hours and minutes and hold
  var hour = now.getHours()
  var minute = now.getMinutes();
 // calculate minute of the day to create field name
  var minuteOfDay = minute + (hour * 60);
  var minuteField = util.format('minute.%s', minuteOfDay);
 // set hour to zero to put on criteria
  now.setHours(0, 0, 0, 0);
 // create the project object and set minute of the day value
  var project = {};
  project[minuteField] = 1;
  collection.findOne({resource: "/", date: now},
    project, function(err, doc) {
    assert.equal(err, null);
    console.log("Document found.");
    console.dir(doc);
    callback(doc);
  });
}

// Connect to MongoDB and log
mongo.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log("Connected to server");
  var resource = "/";
  getCurrentDayhitStats(db, resource, function(){
    getCurrentMinuteStats(db, resource, function(){
      db.close();
      console.log("Disconnected from server");
    });
  });
});
```

要看到魔法发生，我们应该在终端中运行以下命令：

```js
node app.js

```

如果一切正常，输出应如下所示：

```js
Connected to server
Document found.
{ _id: 551fdacdeb6efdc4e71260a2, daily: 27450 }
Document found.
{ _id: 551fdacdeb6efdc4e71260a2, minute: { '183': 142 } }
Disconnected from server

```

另一种可能是检索每日信息以计算每分钟资源的平均请求，或者获取两个日期之间的数据集以构建图表或表格。

下面的代码有两个新函数，`getAverageRequestPerMinuteStats`计算资源每分钟的平均请求数，`getBetweenDatesDailyStats`显示如何检索两个日期之间的数据集。让我们看看`app.js`文件是什么样子的：

```js
var fs = require('fs');
var util = require('util');
var mongo = require('mongodb').MongoClient;
var assert = require('assert');

// Connection URL
var url = 'mongodb://127.0.0.1:27017/monitoring';

var getAverageRequestPerMinuteStats = function(db, resource, callback){
 // Get the events collection
  var collection = db.collection('events');
  var now = new Date();
 // get hours and minutes and hold
  var hour = now.getHours()
  var minute = now.getMinutes();
 // calculate minute of the day to get the avg
  var minuteOfDay = minute + (hour * 60);
 // set hour to zero to put on criteria
  now.setHours(0, 0, 0, 0);
 // create the project object and set minute of the day value
  collection.findOne({resource: resource, date: now},
    {daily: 1}, function(err, doc) {
    assert.equal(err, null);
    console.log("The avg rpm is: "+doc.daily / minuteOfDay);
    console.dir(doc);
    callback(doc);
  });
}

var getBetweenDatesDailyStats = function(db, resource, dtFrom, dtTo, callback){
 // Get the events collection
  var collection = db.collection('events');
 // set hours for date parameters
  dtFrom.setHours(0,0,0,0);
  dtTo.setHours(0,0,0,0);
  collection.find({date:{$gte: dtFrom, $lte: dtTo}, resource: resource},
  {date: 1, daily: 1},{sort: [['date', 1]]}).toArray(function(err, docs) {
    assert.equal(err, null);
    console.log("Documents founded.");
    console.dir(docs);
    callback(docs);
  });
}

// Connect to MongoDB and log
mongo.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log("Connected to server");
  var resource = "/";
  getAverageRequestPerMinuteStats(db, resource, function(){
    var now = new Date();
    var yesterday = new Date(now.getTime());
    yesterday.setDate(now.getDate() -1);
    getBetweenDatesDailyStats(db, resource, yesterday, now, function(){
      db.close();
      console.log("Disconnected from server");
    });

  });
});
```

如所示，查询`events`集合中的数据有多种方式。这些都是关于如何提取数据的一些非常简单的例子，但它们是功能性的和可靠的。

# 总结

本章向您展示了一个从头开始设计模式以解决实际问题的过程示例。我们从一个详细的问题及其需求开始，并对模式设计进行了改进，以更好地利用可用资源。基于该问题的示例代码非常简单，但将作为终身学习的基础。伟大的

在最后一章中，我们有机会在短短几页的时间里回顾本书的前几章，并应用沿途介绍的概念。但是，正如您现在已经意识到的，MongoDB 是一个年轻的、充满可能性的数据库。随着每个新版本的发布，它被周围社区（包括您自己的社区）采用的程度越来越大。因此，如果您发现自己面临一个新的挑战，并且您意识到该挑战有不止一个解决方案，那么请执行任何认为必要或有用的测试。同事们也可以帮忙，所以和他们谈谈。永远记住，一个好的设计是一个适合你的需要。