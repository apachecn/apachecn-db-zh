# 监视、备份和安全

在生产环境中部署 MongoDB 之前，监视、备份和安全性不应该是事后考虑的，而应该是一个必要的过程。此外，监控可以（也应该）用于在开发阶段进行故障排除和改进性能。

在本章中，我们将讨论 MongoDB 的操作方面。本章将介绍如何制定能够生成正确且一致的备份的备份策略，以及确保我们的备份策略在需要备份的情况下能够正常工作。最后，我们将从许多不同的方面讨论 MongoDB 的安全性，例如身份验证、授权、网络级安全以及如何审核我们的安全设计。

本章将重点关注以下三个方面：

*   监测
*   备份
*   安全

# 监测

当我们设计一个软件系统时，我们承担了许多显式和隐式的假设。我们总是试图根据自己的知识做出最佳决策，但可能有一些参数我们低估了或没有考虑到。

通过监控，我们可以验证我们的假设，并验证我们的应用程序是否按预期执行和扩展。良好的监控系统对于检测软件缺陷和帮助我们检测早期潜在安全事件也至关重要。

# 我们应该监控什么？

到目前为止，MongoDB 中最重要的监控指标是内存使用情况。MongoDB（以及所有数据库系统）广泛使用系统内存来提高性能。无论我们使用的是 MMAPv1 还是 WiredTiger 存储引擎，使用的内存都是我们应该关注的第一件事。

了解计算机内存的工作原理可以帮助我们评估监控系统的指标。这些是与计算机内存相关的最重要的概念。

# 页面错误

RAM 速度快，但价格昂贵。硬盘驱动器或固态驱动器相对便宜且速度较慢，并且在系统和电源故障的情况下为数据提供耐久性。我们所有的数据都存储在磁盘上，当我们执行查询时，MongoDB 将尝试从内存中获取数据。如果数据不在内存中，则它将从磁盘获取数据并将其复制到内存中。这是一个**页面错误事件**，因为内存中的数据是按页面组织的。

当页面错误发生时，内存会被填满，最终，需要清除一些页面，以便更新的数据进入内存。这称为**页面逐出事件**。除非有一个真正静态的数据集，否则我们无法完全避免页面错误，但我们确实希望尽量减少页面错误。这可以通过将工作集保存在内存中来实现。

# 常驻存储器

**驻留内存**大小是 MongoDB 在 RAM 中拥有的内存总量。这是要监视的基本指标，它应该小于可用内存的 80%。

# 虚拟内存和映射内存

当 MongoDB 请求内存地址时，操作系统将返回一个虚拟地址。这可能是 RAM 中的实际地址，也可能不是，这取决于数据驻留的位置。MongoDB 将使用此虚拟地址请求底层数据。当我们启用了日志记录（几乎总是这样）时，MongoDB 将记录日志数据的另一个地址。虚拟内存是指 MongoDB 请求的所有数据的大小，包括日志记录。

The mapped memory excludes journaling references.

所有这些都意味着，随着时间的推移，我们的映射内存将大致等于我们的工作集，而虚拟内存将是映射内存的两倍左右。

# 工作组

工作集是 MongoDB 使用的数据大小。在事务数据库的情况下，这最终将成为 MongoDB 所拥有的数据大小，但在某些情况下，我们的集合可能根本不被使用，也不会对我们的工作集做出贡献。

# 监视 WiredTiger 中的内存使用情况

理解 MMAPv1 中的内存使用情况相对简单。MMAPv1 使用引擎盖下的`mmap()`系统调用将内存页的责任传递给底层操作系统。这就是为什么当我们使用 MMAPv1 时，内存使用将无限增长，因为操作系统正试图将尽可能多的数据集放入内存中。

另一方面，我们使用 WiredTiger 定义启动时的内部缓存使用情况。默认情况下，内部缓存最多为 RAM 的一半，介于 1GB 或 256MB 之间。

在内部缓存之上，MongoDB 还可以为其他操作分配内存，如维护连接和数据处理（内存排序、MapReduce、聚合等）。

MongoDB 进程还将使用底层操作系统的文件系统缓存，就像在 MMAPv1 中一样。文件系统缓存中的数据被压缩。

我们可以通过 mongo shell 查看 WiredTiger 缓存的设置，如下所示：

```
> db.serverStatus().wiredTiger.cache
```

我们可以使用`storage.wiredTiger.engineConfig.cacheSizeGB`参数来调整其大小。

一般建议将 WiredTiger 内部缓存大小保留为默认值。如果我们的数据具有高压缩比，那么将内部缓存大小减少 10%到 20%可能是值得的，以便为文件系统缓存释放更多内存。

# 跟踪页面错误

页面错误的数量可以保持相当稳定，并且不会显著影响性能。然而，一旦页面错误的数量达到某个阈值，我们的系统将迅速而严重地降级。这一点在硬盘上更为明显，但它也会影响**固态硬盘**（**固态硬盘**）。

确保我们不会遇到关于页面错误的问题的方法是，始终拥有一个与设置中的产品相同的登台环境。此环境可用于压力测试系统可以处理多少页错误，而不会降低性能。将生产系统中的实际页面错误数与我们从登台系统计算的最大页面错误数进行比较，我们可以找出我们还有多少余地。

查看页面错误的另一种方式是通过 shell，查看`serverStatus`输出的`extra_info`字段：

```
> db.adminCommand({"serverStatus" : 1})['extra_info']
{ "note" : "fields vary by platform", "page_faults" : 3465 }
```

正如`note`所述，这些字段可能并不存在于每个平台中。

# 跟踪 B-树未命中

正如您在前一章中所看到的，适当的索引是保持 MongoDB 响应性和性能的最佳方法。B 树未命中是指在尝试访问 B 树索引时发生的页面错误。索引通常被频繁使用，与我们的工作集和可用内存相比，索引相对较小，因此它们应该始终在内存中。

如果 B-tree 未命中的数量或 B-tree 命中率增加，或者 B-tree 未命中的数量减少，这表明我们的索引在大小上有所增长和/或设计得不够理想。B-tree 未命中也可以通过 MongoDB 云管理器或在 shell 中进行监控。

In the shell, we can use collection stats to locate it.

# I/O 等待

**I/O 等待**指操作系统等待 I/O 操作完成的时间。它与页面错误有很强的正相关关系。如果我们看到 I/O 等待时间随着时间的推移而增加，这就强烈地表明页面错误也会随之而来。我们的目标应该是将 I/O 等待时间保持在 60%到 70%之间，以保证集群的正常运行。在负载突然增加的情况下，设定这样的阈值将为我们赢得一些时间进行升级。

# 读写队列

查看 I/O 等待和页面错误的另一种方法是通过读写队列。当出现页面错误和 I/O 等待时，请求将不可避免地开始排队进行读或写操作。队列是结果，而不是根本原因，因此当队列开始建立时，我们知道我们有一个问题要解决。

# 锁定百分比

这在早期版本的 MongoDB 中是一个更大的问题，而在使用 WiredTiger 存储引擎时则不是问题。**锁百分比**显示数据库被锁定的时间百分比，等待使用独占锁释放它的操作。它通常应该很低：最多 10%到 20%。超过 50%意味着这是一个值得关注的问题。

# 背景刷新

默认情况下，MongoDB 会每分钟将数据刷新到磁盘。**后台刷新**是指数据保存到磁盘所需的时间。每 1 分钟不得超过 1 秒。

修改刷新间隔可能有助于背景刷新时间；通过更频繁地写入磁盘，可以减少要写入的数据。在某些情况下，这可能会加快写入速度。

背景刷新时间受到写入负载的影响意味着如果我们的背景刷新时间开始变得太高，我们应该考虑使用数据库来增加写入容量。

# 跟踪自由空间

使用 MMAPv1（WiredTiger 使用频率较低）时的一个常见问题是可用磁盘空间。与内存一样，我们需要跟踪磁盘空间的使用情况，并主动而不是被动地使用它。不断监视磁盘空间使用情况，当磁盘空间占磁盘空间的 40%、60%或 80%时，会发出适当的警报，特别是对于快速增长的数据集。

磁盘空间问题通常是管理员、DevOp 和开发人员最头疼的问题，因为移动数据需要时间。

The `directoryperdb` option can help with data sizing, as we can split our storage into different physically mounted disks.

# 监视复制

副本集使用**操作日志**（**oplog**来保持同步状态。每个操作都在主服务器上应用，然后写入主服务器的 oplog，这是一个有上限的集合。辅助服务器异步读取此 oplog 并逐个应用操作。

如果主服务器过载，则辅助服务器将无法足够快地读取和应用操作，从而产生复制延迟。**复制延迟**被计算为应用于主设备的最后一次操作和应用于辅助设备的最后一次操作之间的时间差，存储在 oplog capped 集合中。

例如，如果时间是下午 4:30:00，而辅助服务器刚刚应用了在下午 4:25:00 应用于主服务器的操作，这意味着辅助服务器落后于主服务器五分钟。

在我们的生产集群中，复制延迟应该接近（或等于）零。

# Oplog 大小

副本大小中的每个成员将在`db.oplog.rs()`中有一个 oplog 副本。原因是，如果主要成员下台，其中一名二级成员将当选，并且需要有最新版本的 oplog，以便新的二级成员跟踪。

oplog 大小是可配置的，我们应该将其设置为尽可能大。oplog 大小不影响内存使用，在出现操作问题时，它可以创建或破坏数据库。

原因是，如果复制延迟随着时间的推移而增加，我们最终会到达这样一个点，即二级服务器将落后到主服务器无法读取主服务器的 oplog，因为主服务器 oplog 中最旧的条目将晚于在二级服务器中应用的最新条目。

一般来说，oplog 至少需要一到两天的运行时间。oplog 应该比初始同步所需的时间长，原因与前面详述的相同。

# 工作集计算

工作集是我们内存需求的最强指标。理想情况下，我们希望将整个数据集存储在内存中，但大多数情况下，这是不可行的。下一个最好的方法是将我们的工作集存储在内存中。工作集可以直接或间接计算。

直接地，我们在`serverStatus`中有`workingSet`标志，我们可以从 shell 调用它，如下所示：

```
> db.adminCommand({"serverStatus" : 1, "workingSet" : 1})
```

不幸的是，这在 3.0 版中被删除，因此我们将重点讨论计算工作集的间接方法。

间接地说，我们的工作集是满足 95%或更多用户请求所需的数据大小。为了计算这一点，我们需要识别用户进行的查询以及他们从日志中使用的数据集。将 30%到 50%添加到索引内存需求中，我们可以得到工作集计算。

另一种间接估算工作大小的方法是通过页面错误的数量。如果我们没有页面错误，那么我们的工作集就适合内存。通过反复试验，我们可以估计页面错误开始发生的时间点，并了解我们的系统可以处理的负载量有多大。

如果我们不能在内存中保存工作集，那么我们至少应该有足够的内存，以便索引可以放在内存中。在上一章中，我们描述了如何计算索引内存需求，以及如何使用此计算相应地调整 RAM 的大小。

# 监测工具

有几种监控选项。在本节中，我们将讨论如何使用 MongoDB 自己的工具或第三方工具进行监控。

# 托管工具

MongoDB，Inc.自己的工具 MongoDB Cloud Manager（前身为 MongoDB 监控服务）是一个强大的工具，用于监控前面描述的所有指标。MongoDB Cloud Manager 有一个有限的免费层和 30 天的试用期。

使用 MongoDB Cloud Manager 的另一个选择是通过 MongoDB Atlas，MongoDB，Inc.的 DBaaS 产品。这也有一个有限的免费层，在所有三大云提供商（亚马逊、谷歌和微软）中都可以使用。

# 开源工具

所有主要的开源工具，如**Nagios**、**Munin**、**Cacti**等，都为 MongoDB 提供了插件支持。虽然这超出了本书的范围，但 operations 和 DevOps 应该熟悉设置和理解前面描述的指标，以便有效地排除 MongoDB 故障，并在问题变得不成比例之前抢先解决问题。

mongo shell 中的`mongotop`和`mongostat`命令和脚本也可用于临时监控。然而，这种手动过程的风险之一是，脚本的任何故障都可能危及我们的数据库。如果您的监控需要有知名且经过测试的工具，请避免编写自己的工具。

# 备份

引用一条著名格言如下：

"Hope for the best, plan for the worst."
                                                                                                       – John Jay (1813)

在为 MongoDB 设计备份策略时，这应该是我们的方法。可能会发生几种不同的故障事件。

备份应该是我们灾难恢复战略的基石，以防发生意外。有些开发人员可能依赖复制进行灾难恢复，因为拥有三个数据拷贝似乎就足够了。我们总是可以从另外两个副本重建集群，以防其中一个副本丢失。

磁盘发生故障时就是这种情况。磁盘故障是生产集群中最常见的故障之一，从统计上讲，一旦磁盘开始达到其**平均无故障时间**（**MTBF**时间），就会发生磁盘故障。

然而，这并不是唯一可能发生的故障事件。安全事故，或纯粹的人为错误，同样可能发生，也应该成为我们计划的一部分。火灾、洪水、地震或不满的员工一次丢失所有副本集成员而导致的灾难性故障是不应导致生产数据丢失的事件。

A useful interim option, in the middle ground between replication and implementing proper backups, could be setting up a delayed replica set member. This member can lag several hours or days behind the primary server so that it will not be affected by malicious changes in the primary. The important detail to take into account is that the oplog needs to be configured so that it can hold several hours of delay. Also, this solution is only an interim, as it doesn't take into account the full range of reasons why we need disaster recovery, but can definitely help with a subset of them.

这称为**灾难恢复**。灾难恢复是一类故障，不仅需要定期进行备份，而且还需要使用一个将备份（从地理位置和访问规则上）与生产数据隔离的过程。

# 备份选项

根据我们的部署策略，我们可以选择不同的备份选项。

# 基于云的解决方案

如果我们使用云 DBaaS 解决方案，则会出现最直接的解决方案。在 MongoDB，Inc.自己的 MongoDB Atlas 示例中，我们可以从 GUI 管理备份。

如果我们在自己的服务器上托管 MongoDB，那么就可以使用 MongoDB，Inc.的 MongoDB 云管理器。Cloud Manager 是一种 SaaS，我们可以指向自己的服务器来监视和备份数据。它使用与复制相同的 oplog，并且可以备份副本集和分片集群。

如果我们不想（或者出于安全原因不能）将服务器指向外部 SaaS 服务，我们可以使用 MongoDB Ops Manager 在本地使用 MongoDB Cloud Manager 的功能。要获得 MongoDB Ops Manager，我们需要为集群获得 MongoDB 企业高级版的订阅。

# 使用文件系统快照进行备份

过去最常见的备份方法，也是目前仍被广泛使用的备份方法，依赖于底层文件系统的时间点快照功能来备份数据。

EC2 上的 EBS，Linux 上的**逻辑卷管理器****LVM**，支持时间点快照。

If we use WiredTiger with the latest version of MongoDB, we can have volume-level backups, even if our data and journal files reside in different volumes.

我们可以按如下方式备份副本集：

*   要备份副本集，我们需要数据库具有一致的状态。这意味着我们将所有的写操作提交到磁盘或日志文件中。
*   如果我们使用 WiredTiger 存储，我们的快照将与最新检查点（即 2GB 数据或最后一分钟备份）保持一致。

Ensure that you store the snapshot in an offsite volume for disaster recovery purposes. You need to have enabled journaling to use point-in-time snapshots. It's a good practice to enable journaling regardless. 

# 对分片群集进行备份

如果我们想备份整个分片集群，我们需要在启动之前停止平衡器。原因是，如果在我们拍摄快照时有数据块在不同的数据块之间迁移，那么我们的数据库将处于不一致的状态，在我们拍摄快照时，数据块不完整或重复。

整个分片群集的备份时间大致相同。如果我们需要时间点精度，我们需要停止数据库中的所有写入操作，这对于生产系统来说通常是不可能的。

首先，我们需要通过 mongo shell 连接到我们的 mongos 来禁用平衡器：

```
> use config
> sh.stopBalancer()
```

然后，如果我们的二级数据库中没有启用日志记录，或者如果我们在不同的卷中有日志和数据文件，那么我们需要锁定所有碎片和配置服务器副本集的二级 mongo 实例。

We also need to have a sufficient oplog size in these servers so that they can catch up to the primaries once we unlock them; otherwise, we will need to resync them from scratch.

考虑到我们不需要锁定辅助服务器，下一步是备份配置服务器。在 Linux 中（并使用 LVM），这类似于执行以下操作：

```
$ lvcreate --size 100M --snapshot --name snap-14082017 /dev/vg0/mongodb
```

然后，我们需要对每个碎片中每个副本集中的单个成员重复相同的过程。

最后，我们需要使用与停止平衡器相同的 mongo shell 重新启动平衡器：

```
> sh.setBalancerState(true)
```

在这里不做太多详细的介绍，很明显，对分片集群进行备份是一个复杂而耗时的过程。它需要事先进行规划和广泛的测试，以确保它不仅能够以最小的中断工作，而且我们的备份是可用的，并且可以恢复回群集。

# 使用 mongodump 进行备份

`mongodump`工具是一个命令行工具，可以备份 MongoDB 集群中的数据。因此，缺点是所有索引都需要在恢复时重新创建，这可能是一个耗时的操作。

`mongodump`工具的主要缺点是，为了将数据写入磁盘，它需要首先将数据从内部 MongoDB 存储带到内存。这意味着，在生产集群在紧张状态下运行的情况下，`mongodump`将使工作集内存中驻留的数据与常规操作下不会驻留在内存中的数据失效。这会降低集群的性能。

另一方面，当我们使用`mongodump`时，我们可以继续在集群中进行写操作，如果我们有副本集，我们可以使用`--oplog`选项将`mongodump`操作期间发生的条目包括在其输出 oplog 中。

如果我们使用该选项，我们需要在使用`mongorestore`工具将数据恢复回 MongoDB 集群时使用`--oplogReplay`。

对于单个服务器部署，OutT0.是一个很好的工具，但是一旦我们得到更大的部署，我们应该考虑使用不同的（和更好的计划）方法来备份我们的数据。

# 通过复制原始文件进行备份

如果我们不想使用前面概述的任何选项，我们最后的办法是使用`cp`/`rsync`或其他等效工具复制原始文件。由于以下原因，通常不建议这样做：

*   在复制文件之前，我们需要停止所有写入操作
*   备份大小将更大，因为我们需要复制索引以及任何底层填充和碎片存储开销
*   我们无法通过对副本集使用此方法实现时间点恢复，并且以一致且可预测的方式从分片集群复制数据非常困难

Making a backup by copying raw files should be avoided, unless no other option really exists.

# 使用队列进行备份

在实践中使用的另一种策略是利用排队系统，拦截我们的数据库和前端软件系统。在数据库中的 INSERT/updates/DELETE 之前有一个类似 ActiveMQ 的队列意味着我们可以安全地将数据发送到不同的接收器，这些接收器是 MongoDB 服务器或单独存储库中的日志文件。与延迟副本集方法一样，此方法对于一类备份问题很有用，但对于其他一些问题可能会失败。

This is a useful interim solution, but it should not be used as a permanent one.

# EC2 备份和恢复

MongoDB Cloud Manager 可以自动从 EC2 卷进行备份；而且，既然我们的数据在云中，为什么不使用云管理器呢？

如果出于某种原因无法使用它，我们可以编写一个脚本，通过执行以下步骤进行备份：

1.  假设我们已经启用了日志记录（我们确实应该这样做），并且我们已经将包含数据和日志文件的`dbpath`映射到单个 EBS 卷，我们首先需要使用`ec2-describe-instances`找到与正在运行的实例关联的 EBS 块实例。
2.  下一步是使用`lvdisplay`查找 MongoDB 数据库`dbpath`映射到的逻辑卷。
3.  一旦我们从逻辑卷中识别出了逻辑设备，我们就可以使用`ec2-create-snapshot`创建新的快照。我们需要包括映射到`dbpath`目录的每个逻辑设备。

为了验证备份是否有效，我们需要基于快照创建新卷，并在那里装载新卷。最后，`mongod`进程应该能够开始装载新数据，我们应该使用 MongoDB 进行连接以验证这些数据。

# 增量备份

对于某些部署，每次进行完整备份可能是可行的，但当大小达到某个阈值时，完整备份会占用太多的时间和空间。

此时，我们希望每隔一段时间（例如，可能每月一次）进行一次完整备份，并在这段时间（例如，每晚）进行增量备份。

Ops Manager 和 Cloud Manager 都支持增量备份，如果我们达到这个规模，最好使用一个工具进行备份，而不是推出自己的备份。

如果我们不想（或不能）使用这些工具，我们可以选择通过 oplog 进行恢复，如下所示：

1.  使用前面描述的任何方法进行完全备份
2.  在副本集的辅助服务器上锁定写入
3.  注意 oplog 中的最新条目
4.  在 oplog 中最新条目之后导出 oplog 中的条目：

```
> mongodump --host <secondary> -d local -c oplog.rs -o /mnt/mongo-oldway_backup
 --query '{ "ts" : { $gt :  Timestamp(1467999203, 391) } }'
```

5.  解锁辅助服务器上的写入

要恢复，我们可以使用刚刚导出的`oplog.rs`文件，并使用`mongorestore`和`--oplogReplay`选项：

```
> mongorestore -h <primary> --port <port> --oplogReplay <data_file_position>
```

This method requires locking writes, and may not work in future versions.

更好的解决方案是使用带有增量备份的**L****逻辑卷管理（LVM）**文件系统，但这取决于底层 LVM 实现，我们可能无法调整。

# 安全

在 MongoDB 集群中，安全是一个多方面的目标。在本章的其余部分，我们将研究不同的攻击向量，以及如何防范它们。除了这些最佳实践之外，开发人员和管理员必须始终使用常识，以便安全性干扰只与操作目标所需的干扰一样大。

# 认证

**认证**是指验证客户端的身份。这可以防止为了访问某人的数据而对其进行模拟。

最简单的身份验证方法是使用`username`和`password`对。这可以通过外壳通过两种方式完成，第一种方式如下：

```
> db.auth( <username>, <password> )
```

传入以逗号分隔的`username`和`password`将采用其余字段的默认值：

```
> db.auth( {
 user: <username>,
 pwd: <password>,
 mechanism: <authentication mechanism>,
 digestPassword: <boolean>
} )
```

如果我们传递一个文档对象，我们可以定义比`username`/`password`更多的参数。

（authentication）`mechanism`参数可以取多个不同的值，默认为`SCRAM-SHA-1`。参数值`MONGODB-CR`用于向后兼容 3.0 之前的版本。

MONGODB-x.509 用于 TLS/SSL 身份验证。用户和内部副本集服务器可以使用 SSL 证书进行身份验证，SSL 证书是自行生成和签名的，或者来自可信的第三方机构。

要为副本集成员的内部身份验证配置 x.509，我们需要提供以下参数之一。

以下内容适用于配置文件：

```
security.clusterAuthMode / net.ssl.clusterFile
```

以下命令用于命令行：

```
--clusterAuthMode and --sslClusterFile
> mongod --replSet <name> --sslMode requireSSL --clusterAuthMode x509 --sslClusterFile <path to membership certificate and key PEM file> --sslPEMKeyFile <path to SSL certificate and key PEM file> --sslCAFile <path to root CA PEM file>
```

MongoDB，Inc.的付费产品 MongoDB Enterprise Edition 增加了两个认证选项，如下所示：

*   添加的第一个选项是**通用安全服务应用程序接口**（**GSSAPI**）Kerberos。Kerberos 是一个成熟而健壮的身份验证系统，可用于基于 Windows 的 Active Directory 部署等。
*   第二个添加的选项是普通（LDAP SASL）。LDAP 就像 Kerberos：一种成熟而健壮的身份验证机制。当使用普通身份验证机制时，主要考虑的是凭证通过有线以纯文本传输。这意味着我们应该通过 VPN 或 TSL/SSL 连接来确保客户端和服务器之间的路径，以避免中间人窃取我们的凭据。

# 批准

在我们配置了身份验证以验证用户在连接到我们的 MongoDB 服务器时所声称的身份之后，我们需要配置每个用户在我们的数据库中拥有的权限。

这是权限的**授权**方面。MongoDB 使用基于角色的访问控制来控制不同用户类的权限。

每个角色都有对资源执行某些操作的权限。

资源可以是集合或数据库。

该命令的格式如下：

```
{ db: <database>, collection: <collection> }
```

如果我们为`db`或`collection`指定`""`（空字符串），则表示任何`db`或`collection`。这方面的一个例子如下：

```
{ db: "mongo_books", collection: "" }
```

这将在`mongo_books`数据库中的每个`collection`中应用我们的操作。

If the database is not the `admin` database, this will not include the system collections. System collections, such as `<db>.system.profile`, `<db>.system.js`, `admin.system.users`, and `admin.system.roles`, need to be defined explicitly.

与前面的选项类似，我们可以定义以下内容：

```
{ db: "", collection: "" }
```

我们定义它是为了将规则应用于所有数据库中的所有集合，当然，系统集合除外。

我们还可以在整个集群中应用规则，如下所示：

```
{ resource: { cluster : true }, actions: [ "addShard" ] }
```

前面的示例为整个集群中的`addShard`操作（向系统添加新的碎片）授予特权。群集资源只能用于影响整个群集的操作，而不能用于集合或数据库（例如，`shutdown`、`replSetReconfig`、`appendOplogNote`、`resync`、`closeAllDatabases`和`addShard`）。

下面是集群特定操作的广泛列表，以及一些最广泛使用的操作。

最广泛使用的行动清单如下：

*   `find`
*   `insert`
*   `remove`
*   `update`
*   `bypassDocumentValidation`
*   `viewRole`/`viewUser`
*   `createRole`/`dropRole`
*   `createUser`/`dropUser`
*   `inprog`
*   `killop`
*   `replSetGetConfig`/`replSetConfigure`/`replSetStateChange`/`resync`
*   `getShardMap`/`getShardVersion`/`listShards`/`moveChunk`/`removeShard`/`addShard`
*   `dropDatabase`/`dropIndex`/`fsync`/`repairDatabase`/`shutDown`
*   `serverStatus`/`top`/`validate`

群集特定的操作如下所示：

*   `unlock`
*   `authSchemaUpgrade`
*   `cleanupOrphaned`
*   `cpuProfiler`
*   `inprog`
*   `invalidateUserCache`
*   `killop`
*   `appendOplogNote`
*   `replSetConfigure`
*   `replSetGetConfig`
*   `replSetGetStatus`
*   `replSetHeartbeat`
*   `replSetStateChange`
*   `resync`
*   `addShard`
*   `flushRouterConfig`
*   `getShardMap`
*   `listShards`
*   `removeShard`
*   `shardingState`
*   `applicationMessage`
*   `closeAllDatabases`
*   `connPoolSync`
*   `fsync`
*   `getParameter`
*   `hostInfo`
*   `logRotate`
*   `setParameter`
*   `shutdown`
*   `touch`
*   `connPoolStats`
*   `cursorInfo`
*   `diagLogging`
*   `getCmdLineOpts`
*   `getLog`
*   `listDatabases`
*   `netstat`
*   `serverStatus`
*   `top`

如果这听起来太复杂，那是因为它太复杂了！MongoDB 允许在资源上配置不同操作的灵活性意味着我们需要研究和理解广泛的列表，如前所述。

谢天谢地，一些最常见的操作和资源捆绑在内置角色中。

我们可以使用这些内置角色来建立我们将授予用户的权限基线，然后根据广泛的列表对这些权限进行细化。

# 用户角色

我们可以指定两种不同的通用用户角色，如下所示：

*   `read`：跨非系统集合和以下系统集合的只读角色：`system.indexes`、`system.js`和`system.namespaces`集合
*   `readWrite`：跨非系统集合和`system.js`集合的读取和修改角色

# 数据库管理角色

有三个特定于数据库的管理角色，如下所示：

*   `dbAdmin`：可以执行架构相关任务、索引和收集统计信息的基本管理员用户角色。`dbAdmin`无法执行用户和角色管理。
*   `userAdmin`：创建和修改角色和用户。这是对`dbAdmin`角色的补充。

A `userAdmin` can modify itself to become a superuser in the database, or, if scoped to the `admin` database, the MongoDB cluster.

*   `dbOwner`：结合`readWrite`、`dbAdmin`和`userAdmin`角色，这是最强大的管理员用户角色。

# 群集管理角色

以下是可用的群集范围的管理角色：

*   `hostManager`：监控和管理集群中的服务器。
*   `clusterManager`：提供集群上的管理和监控操作。具有此角色的用户可以访问配置数据库和本地数据库，这两个数据库分别用于分片和复制。
*   `clusterMonitor`：MongoDB 提供的监控工具只读访问，如 MongoDB 云管理器、Ops Manager 代理等。
*   `clusterAdmin`：提供最大的集群管理访问权限。此角色结合了`clusterManager`、`clusterMonitor`和`hostManager`角色授予的权限。此外，该角色还提供了`dropDatabase`操作。

# 备份和恢复角色

基于角色的授权角色也可以在备份和恢复粒度级别定义：

*   `backup`：提供备份数据所需的权限。此角色提供足够的权限来使用 MongoDB Cloud Manager 备份代理、Ops Manager 备份代理或`mongodump`。
*   `restore`：提供使用`mongorestore`恢复数据所需的权限，不使用`--oplogReplay`选项或`system.profile`采集数据。

# 跨所有数据库的角色

类似地，以下是跨所有数据库的可用角色集：

*   `readAnyDatabase`：提供与`read`相同的只读权限，但它适用于集群中除本地和配置数据库之外的所有数据库。该角色还提供集群整体上的`listDatabases`操作。
*   `readWriteAnyDatabase`：提供与`readWrite`相同的读写权限，只是它适用于集群中除本地和配置数据库之外的所有数据库。该角色还提供集群整体上的`listDatabases`操作。
*   `userAdminAnyDatabase`：提供与`userAdmin`相同的对用户管理操作的访问权限，但它适用于集群中除本地和配置数据库之外的所有数据库。由于`userAdminAnyDatabase`角色允许用户向任何用户（包括他们自己）授予任何特权，因此该角色还间接提供超级用户访问。
*   `dbAdminAnyDatabase`：提供与`dbAdmin`相同的对数据库管理操作的访问权限，但它适用于集群中除本地和配置数据库之外的所有数据库。该角色还提供集群整体上的`listDatabases`操作。

# 超级用户

最后，以下是可用的超级用户角色：

*   `root`：提供对`readWriteAnyDatabase`、`dbAdminAnyDatabase`、`userAdminAnyDatabase`、`clusterAdmin`、`restore`和`backup`组合的操作和所有资源的访问
*   `__internal`：与 root 用户类似，任何`__internal`用户都可以对服务器上的任何对象执行任何操作

Superuser roles should be avoided, as they can have potentially destructive permissions across all of the databases on our server.

# 网络级安全

除了 MongoDB 特定的安全措施外，还为网络级安全制定了一些最佳实践：

*   仅允许服务器之间的通信，并且仅打开用于服务器之间通信的端口。
*   始终使用 TLS/SSL 进行服务器之间的通信。这可以防止中间人攻击模仿客户端。
*   始终使用不同的开发、登台和生产环境以及安全凭据集。理想情况下，为每个环境创建不同的帐户，并在登台和生产环境中启用双因素身份验证。

# 审计安全性

无论我们如何计划我们的安全措施，来自公司外部的第二双或第三双眼睛都可以对我们的安全措施给出不同的看法，并发现我们可能低估或忽略的问题。请毫不犹豫地让安全专家和白帽黑客参与进来，在您的服务器上进行渗透测试。

# 特例

出于数据隐私的原因，医疗或金融应用程序需要增加安全级别。

如果我们在医疗领域构建应用程序，访问用户的个人身份信息，我们可能需要获得 HIPAA 认证。

如果我们正在构建一个与支付交互并管理持卡人信息的应用程序，我们可能需要符合 PCI/DSS。

The specifics of each certification are outside the scope of this book, but it is important to know that MongoDB has use cases in these fields that fulfill the requirements, and, as such, it can be the right tool with proper design beforehand.

# 概述

总结涉及安全的最佳实践建议，我们有以下几点：

*   **强制认证**：始终在生产环境中启用认证。
*   **启用访问控制**：首先创建一个系统管理员，然后使用该管理员创建更多受限用户。为每个用户角色提供尽可能少的权限。
*   **在访问控制**中定义细粒度角色：不要为每个用户提供超出需要的权限。
*   **加密客户端和服务器之间的通信**：在生产环境中，客户端和服务器之间的通信始终使用 TLS/SSL。始终使用 TLS/SSL 在`mongod`和`mongos`或配置服务器之间进行通信。
*   **静态加密数据**：MongoDB Enterprise Edition 提供了在存储数据时使用 WiredTiger 静态加密对数据进行加密的功能。

Alternatively, we can encrypt data using filesystem, device, or physical encryption. In the cloud, we often get the option for encryption, as well (for example, with EBS on Amazon EC2).

*   **限制网络曝光**：MongoDB 服务器只应连接到应用服务器以及操作所需的任何其他服务器。除了我们为 MongoDB 通信设置的端口之外，其他端口不应对外开放。如果我们想调试 MongoDB 的使用情况，设置一个具有受控访问权限的代理服务器以与数据库通信非常重要。
*   **异常活动审计服务器**：MongoDB 企业版提供了审计实用程序。通过使用它，我们可以将事件输出到控制台、JSON 文件、BSON 文件或系统日志。在任何情况下，确保审计事件存储在系统用户不可用的分区中都很重要。
*   使用专用操作系统用户运行 MongoDB。确保专用操作系统用户可以访问 MongoDB，但没有不必要的权限。
*   如果不需要 JavaScript 服务器端脚本，请禁用它们。

MongoDB 可以通过以下命令将 JavaScript 用于服务器端脚本：`mapReduce()`、`group()`和`$where`。如果我们不需要这些命令，我们应该使用命令行上的`--noscripting`选项禁用服务器端脚本。

# 总结

在本章中，您了解了 MongoDB 的三个操作方面：监视、备份和安全。

我们讨论了在 MongoDB 中应该监控的指标，以及如何监控它们。接下来，我们讨论了如何进行备份并确保可以使用它们来恢复数据。最后，您了解了身份验证和授权概念的安全性，以及网络级别的安全性和如何对其进行审核。

与根据需要设计、构建和扩展我们的应用程序一样重要的是，确保我们在操作过程中心平气和，并免受意外事件（如人为错误和内部或外部恶意用户）的保护。

在下一章中，您将了解可插拔存储引擎，这是 MongoDB 3.0 版中引入的一个新概念。可插拔存储引擎允许提供不同的用例，特别是在对数据处理和隐私有特定和严格要求的应用程序域中。